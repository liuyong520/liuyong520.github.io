<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>跛足的登山者</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.liuyong520.cn/"/>
  <updated>2019-06-11T09:37:16.621Z</updated>
  <id>http://www.liuyong520.cn/</id>
  
  <author>
    <name>xxydliuy</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>基于docker的mysql主从同步</title>
    <link href="http://www.liuyong520.cn/2019/06/11/mysql-master-slaver/"/>
    <id>http://www.liuyong520.cn/2019/06/11/mysql-master-slaver/</id>
    <published>2019-06-11T08:21:46.000Z</published>
    <updated>2019-06-11T09:37:16.621Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><h1 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h1><p>docker环境，mysql:5.7的镜像</p><p>#1.创建挂载目录<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--mysql</span><br><span class="line">   --master</span><br><span class="line">      --data  </span><br><span class="line">      --conf</span><br><span class="line">         --my.cnf     </span><br><span class="line">   --slaver</span><br><span class="line">      --data  </span><br><span class="line">      --conf</span><br><span class="line">         --my.cnf</span><br></pre></td></tr></table></figure><p></p><h1 id="2、主从配置文件"><a href="#2、主从配置文件" class="headerlink" title="2、主从配置文件"></a>2、主从配置文件</h1><p>Master: my.cnf<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">server_id=1</span><br><span class="line">log-bin= mysql-bin</span><br><span class="line">binlog_format=ROW</span><br><span class="line">relay-log=mysql-relay-log</span><br><span class="line">replicate-ignore-db=mysql</span><br><span class="line">replicate-ignore-db=sys</span><br><span class="line">replicate-ignore-db=information_schema</span><br><span class="line">replicate-ignore-db=performance_schema</span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/conf.d/</span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/mysql.conf.d/</span><br></pre></td></tr></table></figure><p></p><p>Slaver: my.cnf<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">server_id=1</span><br><span class="line">log-bin= mysql-bin</span><br><span class="line">binlog_format=ROW</span><br><span class="line">relay-log=mysql-relay-log</span><br><span class="line">replicate-ignore-db=mysql</span><br><span class="line">replicate-ignore-db=sys</span><br><span class="line">replicate-ignore-db=information_schema</span><br><span class="line">replicate-ignore-db=performance_schema</span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/conf.d/</span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/mysql.conf.d/</span><br></pre></td></tr></table></figure><p></p><p>说明： log-bin ：需要启用二进制日志 server_id : 用于标识不同的数据库服务器，而且唯一</p><p>binlog-do-db : 需要记录到二进制日志的数据库 binlog-ignore-db : 忽略记录二进制日志的数据库 auto-increment-offset :该服务器自增列的初始值 auto-increment-increment :该服务器自增列增量</p><p>replicate-do-db ：指定复制的数据库 replicate-ignore-db ：不复制的数据库 relay_log ：从库的中继日志，主库日志写到中继日志，中继日志再重做到从库 log-slave-updates ：该从库是否写入二进制日志，如果需要成为多主则可启用。只读可以不需要</p><p>如果为多主的话注意设置 auto-increment-offset 和 auto-increment-increment 如上面为双主的设置： 服务器 152 自增列显示为：1,3,5,7,……（offset=1，increment=2） 服务器 153 自增列显示为：2,4,6,8,……（offset=2，increment=2）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">//获取基础镜像</span><br><span class="line"></span><br><span class="line">docker pull mysql</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">//创建并启动主从容器;</span><br><span class="line"></span><br><span class="line">//master</span><br><span class="line"></span><br><span class="line">docker run --name mastermysql -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=anech -v d:/docker/mysql/master/data:/var/lib/mysql -v d:/docker/mysql/master/conf/my.cnf:/etc/mysql/my.cnf  mysql</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">//slaver</span><br><span class="line"></span><br><span class="line">docker run --name slavermysql -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=anech -v d:/docker/mysql/slaver/data:/var/lib/mysql -v d:/docker/mysql/slaver/conf/my.cnf:/etc/mysql/my.cnf  mysql</span><br></pre></td></tr></table></figure><p>这里为了方便查看数据，把Docker的端口都与本机进行了映射,对应的本地master/data文件夹和slaver/data文件夹下也能看到同步的数据库文件</p><h1 id="3、Master和Slaver设置"><a href="#3、Master和Slaver设置" class="headerlink" title="3、Master和Slaver设置"></a>3、Master和Slaver设置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">//进入master容器</span><br><span class="line"></span><br><span class="line">docker exec -it mastermysql bash</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">//启动mysql命令，刚在创建窗口时我们把密码设置为：anech</span><br><span class="line"></span><br><span class="line">mysql -u root -p</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">//创建一个用户来同步数据</span><br><span class="line"></span><br><span class="line">GRANT REPLICATION SLAVE ON *.* to &apos;backup&apos;@&apos;%&apos; identified by &apos;123456&apos;;</span><br><span class="line"></span><br><span class="line">//这里表示创建一个slaver同步账号backup，允许访问的IP地址为%，%表示通配符</span><br><span class="line"></span><br><span class="line">//例如：192.168.0.%表示192.168.0.0-192.168.0.255的slaver都可以用backup用户登陆到master上</span><br><span class="line"></span><br><span class="line">//刷新一下权限</span><br><span class="line">flush privileges；</span><br><span class="line"></span><br><span class="line">//查看状态，记住File、Position的值，在Slaver中将用到</span><br><span class="line"></span><br><span class="line">show master status;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//进入slaver容器</span><br><span class="line">docker exec -it slavermysql bash</span><br><span class="line"></span><br><span class="line">//启动mysql命令，刚在创建窗口时我们把密码设置为：anech</span><br><span class="line">mysql -u root -p</span><br><span class="line"></span><br><span class="line">//设置主库链接</span><br><span class="line">change master to master_host=&apos;172.17.0.2&apos;,master_user=&apos;backup&apos;,master_password=&apos;123456&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=0,master_port=3306;</span><br><span class="line"></span><br><span class="line">//启动从库同步</span><br><span class="line">start slave;</span><br><span class="line"></span><br><span class="line">//查看状态</span><br><span class="line">show slave status\G;</span><br></pre></td></tr></table></figure><p>说明：</p><p>master_host：主库地址</p><p>master_user：主库创建的同步账号</p><p>master_password：主库创建的同步密码</p><p>master_log_file：主库产生的日志</p><p>master_log_pos：主库日志记录偏移量</p><p>master_port：主库使用的端口，默认为3306</p><h1 id="4-主从同步异常解决办法："><a href="#4-主从同步异常解决办法：" class="headerlink" title="4 主从同步异常解决办法："></a>4 主从同步异常解决办法：<img src="https://blog.csdn.net/z13615480737/article/details/71159262" alt="链接"></h1><p>经常遇到主从同步因为异常导致同步点被破坏，解决方案最常见的两种解决办法是：一种是跳过异常，继续同步，第二种就是将主库数据进行备份导出，然后到从库进行导入，然后重新构造同步点。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;环境要求&quot;&gt;&lt;a href=&quot;#环境要求&quot; class=&quot;headerlink&quot; title=&quot;环境要求&quot;&gt;&lt;/a&gt;环境要求&lt;/h1&gt;
      
    
    </summary>
    
      <category term="mysql" scheme="http://www.liuyong520.cn/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://www.liuyong520.cn/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>基于docker的mysql主主同步</title>
    <link href="http://www.liuyong520.cn/2019/06/11/mysql-master-master/"/>
    <id>http://www.liuyong520.cn/2019/06/11/mysql-master-master/</id>
    <published>2019-06-11T08:21:46.000Z</published>
    <updated>2019-06-11T09:37:15.540Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h1 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h1><p>docker环境，mysql:5.7的镜像</p><p>#1.创建挂载目录<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">--mysql</span><br><span class="line">   --mone</span><br><span class="line">      --data  </span><br><span class="line">      --conf</span><br><span class="line">         --my.cnf     </span><br><span class="line">   --mtwo</span><br><span class="line">      --data  </span><br><span class="line">      --conf</span><br><span class="line">         --my.cnf</span><br></pre></td></tr></table></figure><p></p><h1 id="2、主主配置"><a href="#2、主主配置" class="headerlink" title="2、主主配置"></a>2、主主配置</h1><p>Mone: my.cnf<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">server_id = 1</span><br><span class="line">log-bin= mysql-bin</span><br><span class="line"></span><br><span class="line">replicate-ignore-db=mysql</span><br><span class="line">replicate-ignore-db=sys</span><br><span class="line">replicate-ignore-db=information_schema</span><br><span class="line">replicate-ignore-db=performance_schema</span><br><span class="line"></span><br><span class="line">read-only=0</span><br><span class="line">relay_log=mysql-relay-bin</span><br><span class="line">log-slave-updates=on</span><br><span class="line">auto-increment-offset=1</span><br><span class="line">auto-increment-increment=2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/conf.d/</span><br><span class="line">!includedir /etc/mysql/mysql.conf.d/</span><br></pre></td></tr></table></figure><p></p><p>Mtwo: my.cnf<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">server_id = 2</span><br><span class="line">log-bin= mysql-bin</span><br><span class="line"></span><br><span class="line">replicate-ignore-db=mysql</span><br><span class="line">replicate-ignore-db=sys</span><br><span class="line">replicate-ignore-db=information_schema</span><br><span class="line">replicate-ignore-db=performance_schema</span><br><span class="line"></span><br><span class="line">read-only=0</span><br><span class="line">relay_log=mysql-relay-bin</span><br><span class="line">log-slave-updates=on</span><br><span class="line">auto-increment-offset=2</span><br><span class="line">auto-increment-increment=2</span><br><span class="line"></span><br><span class="line">!includedir /etc/mysql/conf.d/</span><br><span class="line">!includedir /etc/mysql/mysql.conf.d/</span><br></pre></td></tr></table></figure><p></p><p>说明： log-bin ：需要启用二进制日志 server_id : 用于标识不同的数据库服务器，而且唯一</p><p>binlog-do-db : 需要记录到二进制日志的数据库 binlog-ignore-db : 忽略记录二进制日志的数据库 auto-increment-offset :该服务器自增列的初始值 auto-increment-increment :该服务器自增列增量</p><p>replicate-do-db ：指定复制的数据库 replicate-ignore-db ：不复制的数据库 relay_log ：从库的中继日志，主库日志写到中继日志，中继日志再重做到从库 log-slave-updates ：该从库是否写入二进制日志，如果需要成为多主则可启用。只读可以不需要</p><p>如果为多主的话注意设置 auto-increment-offset 和 auto-increment-increment 如上面为双主的设置： 服务器 152 自增列显示为：1,3,5,7,……（offset=1，increment=2） 服务器 153 自增列显示为：2,4,6,8,……（offset=2，increment=2）<br>3.启动容器<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">//创建并启动主从容器;</span><br><span class="line">//mone</span><br><span class="line">docker run --name monemysql -d -p 3317:3306 -e MYSQL_ROOT_PASSWORD=root -v ~/test/mysql_test1/mone/data:/var/lib/mysql -v ~/test/mysql_test1/mone/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7</span><br><span class="line"></span><br><span class="line">//mtwo</span><br><span class="line">docker run --name mtwomysql -d -p 3318:3306 -e MYSQL_ROOT_PASSWORD=root -v ~/test/mysql_test1/mtwo/data:/var/lib/mysql -v ~/test/mysql_test1/mtwo/conf/my.cnf:/etc/mysql/my.cnf mysql:5.7</span><br></pre></td></tr></table></figure><p></p><p>4.双主配置<br>mone-&gt;mtwo<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">//进入mone容器</span><br><span class="line">docker exec -it monemysql mysql -u root -p</span><br><span class="line"> </span><br><span class="line">//启动mysql命令，刚在创建窗口时我们把密码设置为：root</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">//创建一个用户来同步数据</span><br><span class="line">//这里表示创建一个slave同步账号slave，允许访问的IP地址为%，%表示通配符</span><br><span class="line">GRANT REPLICATION SLAVE ON *.* to &apos;slave&apos;@&apos;%&apos; identified by &apos;123456&apos;;</span><br><span class="line"></span><br><span class="line">//刷新权限</span><br><span class="line">flush privileges；</span><br><span class="line"></span><br><span class="line">//查看状态，记住File、Position的值，在mtwo中将用到</span><br><span class="line">show master status;</span><br></pre></td></tr></table></figure><p></p><p>5.查看容器IP<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; monemysql</span><br><span class="line"></span><br><span class="line">我这里查到是172.17.0.2</span><br></pre></td></tr></table></figure><p></p><p>6.进入mtwo<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">//进入mtwo容器</span><br><span class="line">docker exec -it mtwomysql mysql -u root -p</span><br><span class="line"> </span><br><span class="line">//启动mysql命令，刚在创建窗口时我们把密码设置为：root</span><br><span class="line"></span><br><span class="line">//设置主库链接，master_host即为容器IP，master_log_file和master_log_pos即为在mone容器中，通过show master status查出来的值；</span><br><span class="line">change master to master_host=&apos;172.17.0.2&apos;,master_user=&apos;slave&apos;,master_password=&apos;123456&apos;,master_log_file=&apos;mysql-bin.000004&apos;,master_log_pos=154,master_port=3306;</span><br><span class="line"></span><br><span class="line">//启动同步</span><br><span class="line">start slave ;</span><br><span class="line"> </span><br><span class="line">//查看状态</span><br><span class="line">show slave status\G;</span><br></pre></td></tr></table></figure><p></p><p>到此 mone-&gt;mtwo 的同步已经完成<br>7.配置mtwo-&gt;mone的同步<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//进入mtwo容器</span><br><span class="line">docker exec -it mtwomysql mysql -u root -p</span><br><span class="line"> </span><br><span class="line">//启动mysql命令，刚在创建窗口时我们把密码设置为：root</span><br><span class="line"></span><br><span class="line">//创建一个用户来同步数据</span><br><span class="line">//这里表示创建一个slave同步账号slave，允许访问的IP地址为%，%表示通配符</span><br><span class="line">GRANT REPLICATION SLAVE ON *.* to &apos;slave&apos;@&apos;%&apos; identified by &apos;123456&apos;;</span><br><span class="line"></span><br><span class="line">//刷新权限</span><br><span class="line">flush privileges；</span><br><span class="line"> </span><br><span class="line">//查看状态</span><br><span class="line">show master status;</span><br></pre></td></tr></table></figure><p></p><p>8.查看mtwo的ip<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; mtwomysql</span><br><span class="line">我这里是172.17.0.3</span><br></pre></td></tr></table></figure><p></p><p>9.进入mone中<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/进入mone容器</span><br><span class="line">docker exec -it monemysql mysql -u root -p</span><br><span class="line"> </span><br><span class="line">//启动mysql命令，刚在创建窗口时我们把密码设置为：root</span><br><span class="line"></span><br><span class="line">//设置主库链接，master_host即为容器IP，master_log_file和master_log_pos即为在mone容器中，通过show master status查出来的值；</span><br><span class="line">change master to master_host=&apos;172.17.0.3&apos;,master_user=&apos;slave&apos;,master_password=&apos;123456&apos;,master_log_file=&apos;mysql-bin.000004&apos;,master_log_pos=154,master_port=3306;</span><br><span class="line"></span><br><span class="line">//启动同步</span><br><span class="line">start slave ;</span><br><span class="line"> </span><br><span class="line">//查看状态</span><br><span class="line">show slave status\G;</span><br></pre></td></tr></table></figure><p></p><p>到此mtwo-&gt;mone的同步就配置完了</p><p>总结：其实主主同步其实就是做了两次主从同步而已。A主B从，B主A从</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;环境要求&quot;&gt;&lt;a href=&quot;#环境要求&quot; class=&quot;headerlink&quot; title=&quot;环境要求&quot;&gt;&lt;/a&gt;环境要求&lt;/h1&gt;
      
    
    </summary>
    
      <category term="mysql" scheme="http://www.liuyong520.cn/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://www.liuyong520.cn/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>基于docker的mysql主主同步的跨服务器迁移</title>
    <link href="http://www.liuyong520.cn/2019/06/11/mysql-qianyi/"/>
    <id>http://www.liuyong520.cn/2019/06/11/mysql-qianyi/</id>
    <published>2019-06-11T08:21:46.000Z</published>
    <updated>2019-06-11T12:02:34.991Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h1 id="为什么要做迁移？"><a href="#为什么要做迁移？" class="headerlink" title="为什么要做迁移？"></a>为什么要做迁移？</h1><p>1.当前服务器性能瓶颈。<br>2.其他服务器也有同样的数据要求</p><h1 id="如何迁移？"><a href="#如何迁移？" class="headerlink" title="如何迁移？"></a>如何迁移？</h1><p>1.导出docker容器<br>查看当前容器状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES</span><br><span class="line">f8fcf4acacd0        mysql:5.7           &quot;docker-entrypoint.s…&quot;   5 hours ago         Up 5 hours          33060/tcp, 0.0.0.0:3307-&gt;3306/tcp   mysqlmaster</span><br><span class="line">bd7a5f734bfb        mysql:5.7           &quot;docker-entrypoint.s…&quot;   5 hours ago         Up 5 hours          33060/tcp, 0.0.0.0:3308-&gt;3306/tcp   mysqlslaver</span><br></pre></td></tr></table></figure><p>然后导出到本地</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker export bd7a5f734bfb &gt;/home/mysql/mysqlslaver.tar</span><br><span class="line">docker export f8fcf4acacd0 &gt;/home/mysql/mysqlmaster.tar</span><br></pre></td></tr></table></figure><p>2.同步文件到其他服务器，可以手动上传，也可以使用sync同步命令。</p><p>我这里的mysql的容器会挂载如下的目录<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">/data/docker/</span><br><span class="line">└── mysql</span><br><span class="line">    ├── master</span><br><span class="line">    │   ├── conf</span><br><span class="line">    │   │   └── my.cnf</span><br><span class="line">    │   └── data</span><br><span class="line">    |-- slaver</span><br><span class="line">        |-- conf</span><br><span class="line">        |   |__my.cnf</span><br><span class="line">        |__ data</span><br></pre></td></tr></table></figure><p></p><p>所以我这里也会拷贝这些数据挂载目录。</p><p>3.import 容器<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /home/mysql/mysqlmaster | docker import - mysqlmaster</span><br><span class="line">cat /home/mysql/mysqlslaver | docker import - mysqlslaver</span><br></pre></td></tr></table></figure><p></p><p>查看镜像<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure><p></p><p>启动容器<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">//启动从库</span><br><span class="line">docker run --name mysqlslaver -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /data/docker/mysql/slaver/data:/var/lib/mysql -v /data/docker/mysql/slaver/conf/my.cnf:/etc/mysql/my.cnf mysqlslaver /entrypoint.sh mysqld</span><br><span class="line"></span><br><span class="line">//启动主库</span><br><span class="line">docker run --name mysqlmaster -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 -v /data/docker/mysql/master/data:/var/lib/mysql -v /data/docker/mysql/master/conf/my.cnf:/etc/mysql/my.cnf mysqlmaster /entrypoint.sh mysqld</span><br></pre></td></tr></table></figure><p></p><p>然后查看一下<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">30cf2e504186        mysqlmaster         &quot;/entrypoint.sh mysq…&quot;   30 minutes ago      Up 30 minutes       0.0.0.0:3307-&gt;3306/tcp   mysqlmaster</span><br><span class="line">46fac352e00e        mysqlslaver         &quot;/entrypoint.sh mysq…&quot;   31 minutes ago      Up 31 minutes       0.0.0.0:3308-&gt;3306/tcp   mysqlslaver</span><br></pre></td></tr></table></figure><p></p><p>验证一下<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//进入容器</span><br><span class="line">docker exec -it mysqlmaster bash</span><br><span class="line"></span><br><span class="line">//进入mysql</span><br><span class="line">mysql -uroot -p123456</span><br><span class="line">//因为有主从看一下同步是否正常</span><br><span class="line">show slave status\G</span><br></pre></td></tr></table></figure><p></p><p>这样就把数据库容器和数据迁移到了另外一台服务器上了。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;为什么要做迁移？&quot;&gt;&lt;a href=&quot;#为什么要做迁移？&quot; class=&quot;headerlink&quot; title=&quot;为什么要做迁移？&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="mysql" scheme="http://www.liuyong520.cn/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://www.liuyong520.cn/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>JVM的相关知识</title>
    <link href="http://www.liuyong520.cn/2019/06/07/jvm/"/>
    <id>http://www.liuyong520.cn/2019/06/07/jvm/</id>
    <published>2019-06-07T10:13:05.000Z</published>
    <updated>2019-06-11T09:37:16.564Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:48 GMT+0800 (GMT+08:00) --><p>关于JVM介绍网上有很多资料，我这里写的仅仅是我对JVM的理解。</p><h1 id="是不是只有java编译器才能编译成字节码-class文件"><a href="#是不是只有java编译器才能编译成字节码-class文件" class="headerlink" title="是不是只有java编译器才能编译成字节码.class文件?"></a>是不是只有java编译器才能编译成字节码.class文件?</h1><p>明显是不是的，jruby/scale/groovy/都能编译成.class 文件。</p><h1 id="Class文件的结构"><a href="#Class文件的结构" class="headerlink" title="Class文件的结构"></a>Class文件的结构</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.climber.jvm;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Helloword</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> num = <span class="number">3</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Helloword helloword = <span class="keyword">new</span> Helloword();</span><br><span class="line">        num ++;</span><br><span class="line">        helloword.sum(num,<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>编译运行得到class文件<br>如图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559970155642.png" alt="enter description here"></p><p>使用<br>javap -verbose Helloword.class &gt; ./data.txt<br>打开 data.txt<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line">Classfile /Users/xxydliuyss/IdeaProjects/jvm/target/classes/com/climber/jvm/Helloword.class</span><br><span class="line">  Last modified 2019-6-8; size 660 bytes</span><br><span class="line">  MD5 checksum 3e8014d1d19cb974b06673e17c922039</span><br><span class="line">  Compiled from &quot;Helloword.java&quot;</span><br><span class="line">public class com.climber.jvm.Helloword</span><br><span class="line">  minor version: 0</span><br><span class="line">  major version: 49</span><br><span class="line">  flags: ACC_PUBLIC, ACC_SUPER</span><br><span class="line">Constant pool:</span><br><span class="line">   #1 = Methodref          #6.#28         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">   #2 = Class              #29            // com/climber/jvm/Helloword</span><br><span class="line">   #3 = Methodref          #2.#28         // com/climber/jvm/Helloword.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">   #4 = Fieldref           #2.#30         // com/climber/jvm/Helloword.num:I</span><br><span class="line">   #5 = Methodref          #2.#31         // com/climber/jvm/Helloword.sum:(II)I</span><br><span class="line">   #6 = Class              #32            // java/lang/Object</span><br><span class="line">   #7 = Utf8               num</span><br><span class="line">   #8 = Utf8               I</span><br><span class="line">   #9 = Utf8               &lt;init&gt;</span><br><span class="line">  #10 = Utf8               ()V</span><br><span class="line">  #11 = Utf8               Code</span><br><span class="line">  #12 = Utf8               LineNumberTable</span><br><span class="line">  #13 = Utf8               LocalVariableTable</span><br><span class="line">  #14 = Utf8               this</span><br><span class="line">  #15 = Utf8               Lcom/climber/jvm/Helloword;</span><br><span class="line">  #16 = Utf8               main</span><br><span class="line">  #17 = Utf8               ([Ljava/lang/String;)V</span><br><span class="line">  #18 = Utf8               args</span><br><span class="line">  #19 = Utf8               [Ljava/lang/String;</span><br><span class="line">  #20 = Utf8               helloword</span><br><span class="line">  #21 = Utf8               sum</span><br><span class="line">  #22 = Utf8               (II)I</span><br><span class="line">  #23 = Utf8               a</span><br><span class="line">  #24 = Utf8               b</span><br><span class="line">  #25 = Utf8               &lt;clinit&gt;</span><br><span class="line">  #26 = Utf8               SourceFile</span><br><span class="line">  #27 = Utf8               Helloword.java</span><br><span class="line">  #28 = NameAndType        #9:#10         // &quot;&lt;init&gt;&quot;:()V</span><br><span class="line">  #29 = Utf8               com/climber/jvm/Helloword</span><br><span class="line">  #30 = NameAndType        #7:#8          // num:I</span><br><span class="line">  #31 = NameAndType        #21:#22        // sum:(II)I</span><br><span class="line">  #32 = Utf8               java/lang/Object</span><br><span class="line">&#123;</span><br><span class="line">  public static int num;</span><br><span class="line">    descriptor: I</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line"></span><br><span class="line">  public com.climber.jvm.Helloword();</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=1, locals=1, args_size=1</span><br><span class="line">         0: aload_0</span><br><span class="line">         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span><br><span class="line">         4: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 12: 0</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">            0       5     0  this   Lcom/climber/jvm/Helloword;</span><br><span class="line"></span><br><span class="line">  public static void main(java.lang.String[]);</span><br><span class="line">    descriptor: ([Ljava/lang/String;)V</span><br><span class="line">    flags: ACC_PUBLIC, ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=3, locals=2, args_size=1</span><br><span class="line">         0: new           #2                  // class com/climber/jvm/Helloword</span><br><span class="line">         3: dup</span><br><span class="line">         4: invokespecial #3                  // Method &quot;&lt;init&gt;&quot;:()V</span><br><span class="line">         7: astore_1</span><br><span class="line">         8: getstatic     #4                  // Field num:I</span><br><span class="line">        11: iconst_1</span><br><span class="line">        12: iadd</span><br><span class="line">        13: putstatic     #4                  // Field num:I</span><br><span class="line">        16: aload_1</span><br><span class="line">        17: getstatic     #4                  // Field num:I</span><br><span class="line">        20: iconst_1</span><br><span class="line">        21: invokevirtual #5                  // Method sum:(II)I</span><br><span class="line">        24: pop</span><br><span class="line">        25: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 15: 0</span><br><span class="line">        line 16: 8</span><br><span class="line">        line 17: 16</span><br><span class="line">        line 18: 25</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">            0      26     0  args   [Ljava/lang/String;</span><br><span class="line">            8      18     1 helloword   Lcom/climber/jvm/Helloword;</span><br><span class="line"></span><br><span class="line">  public int sum(int, int);</span><br><span class="line">    descriptor: (II)I</span><br><span class="line">    flags: ACC_PUBLIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=2, locals=3, args_size=3</span><br><span class="line">         0: iload_1</span><br><span class="line">         1: iload_2</span><br><span class="line">         2: iadd</span><br><span class="line">         3: ireturn</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 20: 0</span><br><span class="line">      LocalVariableTable:</span><br><span class="line">        Start  Length  Slot  Name   Signature</span><br><span class="line">            0       4     0  this   Lcom/climber/jvm/Helloword;</span><br><span class="line">            0       4     1     a   I</span><br><span class="line">            0       4     2     b   I</span><br><span class="line"></span><br><span class="line">  static &#123;&#125;;</span><br><span class="line">    descriptor: ()V</span><br><span class="line">    flags: ACC_STATIC</span><br><span class="line">    Code:</span><br><span class="line">      stack=1, locals=0, args_size=0</span><br><span class="line">         0: iconst_3</span><br><span class="line">         1: putstatic     #4                  // Field num:I</span><br><span class="line">         4: return</span><br><span class="line">      LineNumberTable:</span><br><span class="line">        line 13: 0</span><br><span class="line">&#125;</span><br><span class="line">SourceFile: &quot;Helloword.java&quot;</span><br></pre></td></tr></table></figure><p></p><h1 id="Class文件格式"><a href="#Class文件格式" class="headerlink" title="Class文件格式"></a>Class文件格式</h1><table><thead><tr><th>类型</th><th>名称</th><th>数量</th><th>描述</th></tr></thead><tbody><tr><td>u4</td><td>magic</td><td>1</td><td>魔数</td></tr><tr><td>u2</td><td>minor_version</td><td>1</td><td>次版本号</td></tr><tr><td>u2</td><td>major_version</td><td>1</td><td>主版本号</td></tr><tr><td>u2</td><td>constant_pool_count</td><td>1</td><td>常量池容量</td></tr><tr><td>cp_info</td><td>constant_pool</td><td>costant_pool_count-1</td><td>常量池</td></tr><tr><td>u2</td><td>access_flags</td><td>1</td><td>访问标志</td></tr><tr><td>u2</td><td>this_class</td><td>1</td><td>当前类常量索引</td></tr><tr><td>u2</td><td>super_class</td><td>1</td><td>超类常量索引</td></tr><tr><td>u2</td><td>interfaces_count</td><td>1</td><td>接口数量</td></tr><tr><td>u2</td><td>interfaces</td><td>interfaces_count</td><td>接口常量索引</td></tr><tr><td>u2</td><td>fields_count</td><td>1</td><td>字段数量</td></tr><tr><td>field_info</td><td>fields</td><td>fields_count</td><td>字段信息</td></tr><tr><td>u2</td><td>methods_count</td><td>1</td><td>方法数量</td></tr><tr><td>method_info</td><td>methods</td><td>methods_count</td><td>方法信息</td></tr><tr><td>u2</td><td>attributes_count</td><td>1</td><td>属性数量</td></tr><tr><td>attribute_info</td><td>attributes</td><td>attributes_count</td><td>属性信息</td></tr></tbody></table><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:48 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;关于JVM介绍网上有很多资料，我这里写的仅仅是我对JVM的理解。&lt;/p&gt;&lt;h1 id=&quot;是不是只有java编译器才能编译成字节码-class文件
      
    
    </summary>
    
      <category term="JVM" scheme="http://www.liuyong520.cn/categories/JVM/"/>
    
    
      <category term="JVM" scheme="http://www.liuyong520.cn/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>storm 的分组策略深入理解（二）</title>
    <link href="http://www.liuyong520.cn/2019/05/12/storm-grouping2/"/>
    <id>http://www.liuyong520.cn/2019/05/12/storm-grouping2/</id>
    <published>2019-05-12T12:10:40.000Z</published>
    <updated>2019-06-11T09:37:15.529Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><p>上一篇博客提出了一个问题：</p><blockquote><p>如果执行<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar strom-study-1.0-SNAPSHOT-jar-with-dependencies.jar com.sonly.storm.demo1.grouppings.fieldgrouping.FeildGroupingToplogy FieldGrouping3 FieldGrouping3 4 1 1 4 4</span><br></pre></td></tr></table></figure><p></p></blockquote><p>bolt 的分配情况是什么样子？</p><p>这个答案是，只会有两个bolt里面有数据，其他bolt里面是没有数据的。<br>下面接着讲分组策略</p><h1 id="All-grouping"><a href="#All-grouping" class="headerlink" title="All grouping"></a>All grouping</h1><p>这个分组策略其实没什么好说的。<br>spout-&gt;bolt，和bolt-&gt;bolt之间都是全量的。</p><h1 id="local-or-sheffle-grouping"><a href="#local-or-sheffle-grouping" class="headerlink" title="local or sheffle grouping"></a>local or sheffle grouping</h1><p>这个分组策略和sheffle grouping策略是一样的结果，可以完全替代，sheffle grouping<br>这个只有一点不一样就是，当一个work上执行两个同样的task任务时，那么这两个任务间不会再通过RPC远程通信，直接随机分配数据。从而减少了，由于RPC远程通信带来的性能损耗。提高了效率。</p><h1 id="global-grouping"><a href="#global-grouping" class="headerlink" title="global grouping"></a>global grouping</h1><p>直接上代码：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.globalgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:55&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GlobalGroupingToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(GlobalGroupingToplogy.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">        String topology = <span class="string">"GlobalGroupingToplogy"</span>;</span><br><span class="line">        builder.setSpout(<span class="string">"NumberGeneratorSpout"</span>, <span class="keyword">new</span> NumberGeneratorSpout(), <span class="number">1</span>);</span><br><span class="line">        builder.setBolt(<span class="string">"GlobalGrouppingBolt1"</span>, <span class="keyword">new</span> GlobalGrouppingBolt1(), <span class="number">2</span>).globalGrouping(<span class="string">"NumberGeneratorSpout"</span>);</span><br><span class="line">        builder.setBolt(<span class="string">"GlobalGroupingBolt"</span>, <span class="keyword">new</span> GlobalGroupingBolt(), <span class="number">2</span>).globalGrouping(<span class="string">"NumberGeneratorSpout"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            StormSubmitter.submitTopologyWithProgressBar(topology, conf, builder.createTopology());</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>, topology);</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.globalgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1.grouppings.directgrouping&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-12 23:33&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NumberGeneratorSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    SpoutOutputCollector collector;</span><br><span class="line">    TopologyContext context;</span><br><span class="line">    AtomicInteger atomicInteger;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext context, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.collector = collector;</span><br><span class="line">        <span class="keyword">this</span>.context = context;</span><br><span class="line">        atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(atomicInteger.get()&lt;<span class="number">10</span>)&#123;</span><br><span class="line">            collector.emit(<span class="keyword">new</span> Values(atomicInteger.incrementAndGet()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"i"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.globalgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:19&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GlobalGroupingBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(GlobalGroupingBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Integer&gt; counts = <span class="keyword">new</span> HashMap(<span class="number">16</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"GlobalGroupingBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Integer i = tuple.getIntegerByField(<span class="string">"i"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"GlobalGroupingBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),i);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(i * <span class="number">2</span>));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"double"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.globalgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:29&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GlobalGrouppingBolt1</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(GlobalGrouppingBolt1.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"GlobalGrouppingBolt1-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        Integer i = tuple.getIntegerByField(<span class="string">"i"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"GlobalGrouppingBolt1-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),i);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(i*i));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"square"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>两个bolt组件对接一个spout，按照global分组，<br>实际上的日志情况是，taskId为1的bolt1，和taskId为3的bolt收到了消息。<br><strong>总结：</strong><br><strong>golbal分组会把消息发给同一个bolt中taskId较小的那个，且spout-&gt;bolt之间也是全量发送的，只是只会发往同一个bolt组件中的taskID最小的那个</strong></p><h1 id="direct-groupping"><a href="#direct-groupping" class="headerlink" title="direct groupping"></a>direct groupping</h1><p>重点分析一下这个grouping<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.directgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Collections;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1.grouppings.directgrouping&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-12 23:33&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NumberGeneratorSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    SpoutOutputCollector collector;</span><br><span class="line">    TopologyContext context;</span><br><span class="line">    Integer taskId;</span><br><span class="line">    AtomicInteger atomicInteger;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext context, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.collector = collector;</span><br><span class="line">        <span class="keyword">this</span>.context = context;</span><br><span class="line">        List&lt;Integer&gt; taskIds = context.getComponentTasks(<span class="string">"DirectGroupingBolt"</span>);</span><br><span class="line">        <span class="comment">//拿到DirectGroupingBolt这个组件的最大taskID</span></span><br><span class="line">        taskId = taskIds.stream().mapToInt(Integer::intValue).max().getAsInt();</span><br><span class="line">        atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(atomicInteger.get()&lt;<span class="number">10</span>)&#123;</span><br><span class="line">            <span class="comment">//直接发往最大的taskId的DirectGroupingBolt的task中</span></span><br><span class="line">            collector.emitDirect(taskId,<span class="keyword">new</span> Values(atomicInteger.incrementAndGet()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"i"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.directgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:19&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DirectGroupingBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(DirectGroupingBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Integer&gt; counts = <span class="keyword">new</span> HashMap(<span class="number">16</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"DirectGroupingBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Integer i = tuple.getIntegerByField(<span class="string">"i"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"DirectGroupingBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),i);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(i * <span class="number">2</span>));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"double"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.directgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:29&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DirectGrouppingBolt1</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(DirectGrouppingBolt1.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"DirectGrouppingBolt1-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        Integer i = tuple.getIntegerByField(<span class="string">"i"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"DirectGrouppingBolt1-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),i);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(i*i));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"square"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.directgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.sonly.storm.demo1.grouppings.spout.WordSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:55&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DirectGroupingToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(DirectGroupingToplogy.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">        String topology = <span class="string">"DirectGroupingToplogy"</span>;</span><br><span class="line">        builder.setSpout(<span class="string">"NumberGeneratorSpout"</span>, <span class="keyword">new</span> NumberGeneratorSpout(), <span class="number">1</span>);</span><br><span class="line">        builder.setBolt(<span class="string">"DirectGrouppingBolt1"</span>, <span class="keyword">new</span> DirectGrouppingBolt1(), <span class="number">2</span>).directGrouping(<span class="string">"NumberGeneratorSpout"</span>);</span><br><span class="line">        builder.setBolt(<span class="string">"DirectGroupingBolt"</span>, <span class="keyword">new</span> DirectGroupingBolt(), <span class="number">2</span>).directGrouping(<span class="string">"NumberGeneratorSpout"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            StormSubmitter.submitTopologyWithProgressBar(topology, conf, builder.createTopology());</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>, topology);</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同样是spout-&gt;bolt 看看这个消息的分布情况<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar strom-study-1.0-SNAPSHOT-jar-with-dependencies.jar com.sonly.storm.demo1.grouppings.directgrouping.DirectGroupingToplogy</span><br></pre></td></tr></table></figure><p></p><p>如图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557721804952.png" alt="enter description here"><br>检查每个节点的日志 发现只有DirectGroupingBolt taskId为2的bolt接收到了消息，其他都没有接收到消息。<br><strong>总结：</strong><br><strong>direct grouping 能够指定bolt发送数据，能够用direct grouping来实现global grouping的功能。</strong></p><h1 id="custorm-grouping"><a href="#custorm-grouping" class="headerlink" title="custorm grouping"></a>custorm grouping</h1><p>这个就是自定义分组的意思，<br>只要继承实现接口 <strong>CustomStreamGrouping</strong> 就可以对分组自定义了。<br>这里实现一个简单的分组<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.customgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.GlobalStreamId;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.grouping.CustomStreamGrouping;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.shade.com.google.common.base.Splitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.shade.com.google.common.collect.ImmutableMap;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.WorkerTopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.util.concurrent.ThreadLocalRandom.current;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:19&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CategoriesGrouping</span> <span class="keyword">implements</span> <span class="title">CustomStreamGrouping</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(CategoriesGrouping.class);</span><br><span class="line">    List&lt;Integer&gt; taskIds;</span><br><span class="line">    Map&lt;String,Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(WorkerTopologyContext context, GlobalStreamId stream, List&lt;Integer&gt; targetTasks)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.taskIds = targetTasks;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> List&lt;Integer&gt; <span class="title">chooseTasks</span><span class="params">(<span class="keyword">int</span> taskId, List&lt;Object&gt; values)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (Object value : values) &#123;</span><br><span class="line">            List&lt;String&gt; strings = Splitter.on(<span class="string">","</span>).splitToList(value.toString());</span><br><span class="line">            <span class="keyword">if</span>(map.containsKey(strings.get(<span class="number">0</span>)))&#123;</span><br><span class="line">                Integer integer = map.get(strings.get(<span class="number">0</span>));</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(integer);</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">int</span> i = current().nextInt(<span class="keyword">this</span>.taskIds.size());</span><br><span class="line">                map.put(strings.get(<span class="number">0</span>),<span class="keyword">this</span>.taskIds.get(i));</span><br><span class="line">                <span class="keyword">return</span> Arrays.asList(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.taskIds;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.customgrouping;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:55&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomGroupingToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(CustomGroupingToplogy.class);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">        String topology = <span class="string">"GlobalGroupingToplogy"</span>;</span><br><span class="line">        builder.setSpout(<span class="string">"NumberGeneratorSpout"</span>, <span class="keyword">new</span> NumberGeneratorSpout(), <span class="number">1</span>);</span><br><span class="line">        builder.setBolt(<span class="string">"GlobalGrouppingBolt1"</span>, <span class="keyword">new</span> CustomGrouppingBolt(), <span class="number">2</span>).customGrouping(<span class="string">"NumberGeneratorSpout"</span>,<span class="keyword">new</span> CategoriesGrouping());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            StormSubmitter.submitTopologyWithProgressBar(topology, conf, builder.createTopology());</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>, topology);</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里有一张图帮助我们理解分组策略：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557658795261.png" alt="enter description here"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;上一篇博客提出了一个问题：&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;如果执行&lt;br&gt;&lt;/p&gt;&lt;figure class=&quot;highlight pla
      
    
    </summary>
    
      <category term="storm" scheme="http://www.liuyong520.cn/categories/storm/"/>
    
    
      <category term="storm" scheme="http://www.liuyong520.cn/tags/storm/"/>
    
  </entry>
  
  <entry>
    <title>dubbo rpc 手把手实现</title>
    <link href="http://www.liuyong520.cn/2019/05/12/duboo-rpc/"/>
    <id>http://www.liuyong520.cn/2019/05/12/duboo-rpc/</id>
    <published>2019-05-12T04:15:31.000Z</published>
    <updated>2019-06-11T09:37:16.562Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><h1 id="dubbo-简单介绍"><a href="#dubbo-简单介绍" class="headerlink" title="dubbo 简单介绍"></a>dubbo 简单介绍</h1><p>dubbo 是阿里巴巴开源的一款分布式rpc框架。</p><h2 id="为什么手写实现一下bubbo？"><a href="#为什么手写实现一下bubbo？" class="headerlink" title="为什么手写实现一下bubbo？"></a>为什么手写实现一下bubbo？</h2><p>很简单，最近从公司离职了，为了复习一下dubbo原理相关的知识，决定自己手写实现一个tony的dubbo，然后再结合dubbo的源码已达到复习的目的。</p><h2 id="什么是RPC？"><a href="#什么是RPC？" class="headerlink" title="什么是RPC？"></a>什么是RPC？</h2><p>rpc 简单的说就是远程调用，以API的方式调用远程的服务器上的方法，像调本地方法一样！</p><p>创建一个api的包模块，供服务端和消费者端共同使用。</p><h2 id="接口抽象"><a href="#接口抽象" class="headerlink" title="接口抽象"></a>接口抽象</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.api;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">HelloService</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 接口服务</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> name</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">String <span class="title">sayHello</span><span class="params">(String name)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="服务端实现"><a href="#服务端实现" class="headerlink" title="服务端实现"></a>服务端实现</h2><p>服务端server端要实现这个接口。同时要发布这个接口，何谓发布这个接口？其实就是要像注册中心注册一下这个服务。这样，消费者在远程调用的时候可以通过注册中心注册的信息能够感知到服务。<br>服务的实现：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.server.provide;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.api.HelloService;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloServiceImpl</span> <span class="keyword">implements</span> <span class="title">HelloService</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">sayHello</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"hello,"</span> + name);</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"hello "</span> + name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>服务端抽象：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">package com.nnk.rpc.server.protocl;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 服务端server</span><br><span class="line"> */</span><br><span class="line">public interface RpcServer &#123;</span><br><span class="line">    /**</span><br><span class="line">     * 开启服务 监听hostName：port</span><br><span class="line">     * @param hostName</span><br><span class="line">     * @param port</span><br><span class="line">     */</span><br><span class="line">    public void start(String hostName,int port);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>http协议的RPCServer实现<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.server.protocl.http;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.server.protocl.RpcServer;</span><br><span class="line"><span class="keyword">import</span> org.apache.catalina.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.catalina.connector.Connector;</span><br><span class="line"><span class="keyword">import</span> org.apache.catalina.core.StandardContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.catalina.core.StandardEngine;</span><br><span class="line"><span class="keyword">import</span> org.apache.catalina.core.StandardHost;</span><br><span class="line"><span class="keyword">import</span> org.apache.catalina.startup.Tomcat;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpServer</span> <span class="keyword">implements</span> <span class="title">RpcServer</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">(String hostName,<span class="keyword">int</span> port)</span></span>&#123;</span><br><span class="line">        Tomcat tomcat = <span class="keyword">new</span> Tomcat();</span><br><span class="line">        Server server = tomcat.getServer();</span><br><span class="line">        Service service = server.findService(<span class="string">"Tomcat"</span>);</span><br><span class="line">        Connector connector = <span class="keyword">new</span> Connector();</span><br><span class="line">        connector.setPort(port);</span><br><span class="line">        Engine engine = <span class="keyword">new</span> StandardEngine();</span><br><span class="line">        engine.setDefaultHost(hostName);</span><br><span class="line"></span><br><span class="line">        Host host = <span class="keyword">new</span> StandardHost();</span><br><span class="line">        host.setName(hostName);</span><br><span class="line">        <span class="comment">//设置上下文</span></span><br><span class="line">        String contextPath=<span class="string">""</span>;</span><br><span class="line">        Context context = <span class="keyword">new</span> StandardContext();</span><br><span class="line">        context.setPath(contextPath);</span><br><span class="line">        context.addLifecycleListener(<span class="keyword">new</span> Tomcat.FixContextListener());</span><br><span class="line"></span><br><span class="line">        host.addChild(context);</span><br><span class="line">        engine.addChild(host);</span><br><span class="line"></span><br><span class="line">        service.setContainer(engine);</span><br><span class="line">        service.addConnector(connector);</span><br><span class="line">        <span class="comment">//设置拦截servlet</span></span><br><span class="line">        tomcat.addServlet(contextPath,<span class="string">"dispather"</span>,<span class="keyword">new</span> DispatcherServlet());</span><br><span class="line">        context.addServletMappingDecoded(<span class="string">"/*"</span>,<span class="string">"dispather"</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//启动tomcat</span></span><br><span class="line">            tomcat.start();</span><br><span class="line">            tomcat.getServer().await();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (LifecycleException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>启动了tomcat并用到DispatcherServlet来拦截我们的请求。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.server.protocl.http;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> javax.servlet.ServletException;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServlet;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletRequest;</span><br><span class="line"><span class="keyword">import</span> javax.servlet.http.HttpServletResponse;</span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 这个代码大家应该很熟悉吧，这个是sevlet的基本知识。</span></span><br><span class="line"><span class="comment"> * 任何请求被进来都会被这个sevlet处理</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DispatcherServlet</span> <span class="keyword">extends</span> <span class="title">HttpServlet</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">service</span><span class="params">(HttpServletRequest req, HttpServletResponse resp)</span> <span class="keyword">throws</span> ServletException, IOException </span>&#123;</span><br><span class="line">        <span class="comment">//把所有的请求交给HttpHandler接口处理</span></span><br><span class="line">        <span class="keyword">new</span> HttpHandler().handler(req,resp);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>再看一下HttpHandler类：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">package com.nnk.rpc.server.protocl.http;</span><br><span class="line"></span><br><span class="line">import com.nnk.rpc.api.entity.Invocation;</span><br><span class="line"></span><br><span class="line">import com.nnk.rpc.register.RegisterType;</span><br><span class="line">import com.nnk.rpc.register.factory.LocalRegisterFactory;</span><br><span class="line">import org.apache.commons.io.IOUtils;</span><br><span class="line"></span><br><span class="line">import javax.servlet.http.HttpServletRequest;</span><br><span class="line">import javax.servlet.http.HttpServletResponse;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.InputStream;</span><br><span class="line">import java.io.ObjectInputStream;</span><br><span class="line">import java.lang.reflect.InvocationTargetException;</span><br><span class="line">import java.lang.reflect.Method;</span><br><span class="line"></span><br><span class="line">public class HttpHandler &#123;</span><br><span class="line"></span><br><span class="line">    public void handler(HttpServletRequest req, HttpServletResponse resp)&#123;</span><br><span class="line">        // 获取对象</span><br><span class="line">        try &#123;</span><br><span class="line">            //从流里面获取数据</span><br><span class="line">            InputStream is = req.getInputStream();</span><br><span class="line">            ObjectInputStream objectInputStream = new ObjectInputStream(is);</span><br><span class="line">            //从流中读取数据反序列话成实体类。</span><br><span class="line">            Invocation invocation = (Invocation) objectInputStream.readObject();</span><br><span class="line">            //拿到服务的名字</span><br><span class="line">            String interfaceName = invocation.getInterfaceName();</span><br><span class="line">            //从注册中心里面拿到接口的实现类</span><br><span class="line">            Class interfaceImplClass = LocalRegisterFactory.getLocalRegister(RegisterType.LOCAL).get(interfaceName);</span><br><span class="line">            //获取类的方法</span><br><span class="line">            Method method = interfaceImplClass.getMethod(invocation.getMethodName(),invocation.getParamtypes());</span><br><span class="line">            //反射调用方法</span><br><span class="line">            String result = (String) method.invoke(interfaceImplClass.newInstance(),invocation.getObjects());</span><br><span class="line">            //把结果返回给调用者</span><br><span class="line">            IOUtils.write(result,resp.getOutputStream());</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (NoSuchMethodException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (IllegalAccessException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (InstantiationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; catch (InvocationTargetException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>我们看看Invocation的实现：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.api.entity;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.Serializable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Invocation</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String interfaceName;</span><br><span class="line">    <span class="keyword">private</span> String methodName;</span><br><span class="line">    <span class="keyword">private</span> Class[] paramtypes;</span><br><span class="line">    <span class="keyword">private</span> Object[] objects;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> interfaceName 接口名字</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> methodName 方法名字</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> paramtypes 参数类型列表</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> objects 参数列表</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Invocation</span><span class="params">(String interfaceName, String methodName, Class[] paramtypes, Object[] objects)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.interfaceName = interfaceName;</span><br><span class="line">        <span class="keyword">this</span>.methodName = methodName;</span><br><span class="line">        <span class="keyword">this</span>.paramtypes = paramtypes;</span><br><span class="line">        <span class="keyword">this</span>.objects = objects;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   .... get set 方法省略掉</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>到这里服务端先告一段落下面实现一下注册中心</p><h2 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h2><p>接口抽象：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.register;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">LocalRegister</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> interfaceName 接口名称</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> interfaceImplClass 接口实现类</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">register</span><span class="params">(String interfaceName,Class interfaceImplClass)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取实现类</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> interfaceName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">Class <span class="title">get</span><span class="params">(String interfaceName)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>LocalRegister 这个主要是供服务端自己在反射调用的时候根据服务名称找到对应的实现。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.register;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.api.entity.URL;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">RemoteRegister</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 注册到远程注册中心</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> interfaceName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> host</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">register</span><span class="params">(String interfaceName, URL host)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 根据服务名称获取调用者的地址信息</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> interfaceName</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function">URL <span class="title">getRadomURL</span><span class="params">(String interfaceName)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>这个主要是供消费者端根据服务名字找对应的地址发起远程调用用的。</p><p>我们分别来看看这两个接口的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.nnk.rpc.register.local;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.register.LocalRegister;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LocalMapRegister</span> <span class="keyword">implements</span> <span class="title">LocalRegister</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Class&gt; registerMap = <span class="keyword">new</span> HashMap&lt;String,Class&gt;(<span class="number">1024</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(String interfaceName, Class interfaceImplClass)</span> </span>&#123;</span><br><span class="line">        registerMap.put(interfaceName,interfaceImplClass);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Class <span class="title">get</span><span class="params">(String interfaceName)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> registerMap.get(interfaceName);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>很简单就是写在缓存里，map存储。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.register.local;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.api.entity.URL;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.register.RemoteRegister;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RemoterMapRegister</span> <span class="keyword">implements</span> <span class="title">RemoteRegister</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, List&lt;URL&gt;&gt; registerMap = <span class="keyword">new</span> HashMap&lt;String,List&lt;URL&gt;&gt;(<span class="number">1024</span>);</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String path = <span class="string">"/data/register"</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(String interfaceName, URL host)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(registerMap.containsKey(interfaceName))&#123;</span><br><span class="line">            List&lt;URL&gt; list = registerMap.get(interfaceName);</span><br><span class="line">            list.add(host);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            List&lt;URL&gt; list = <span class="keyword">new</span> LinkedList&lt;URL&gt;();</span><br><span class="line">            list.add(host);</span><br><span class="line">            registerMap.put(interfaceName,list);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            saveFile(path,registerMap);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> URL <span class="title">getRadomURL</span><span class="params">(String interfaceName)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            registerMap = (Map&lt;String, List&lt;URL&gt;&gt;) readFile(path);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (ClassNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        List&lt;URL&gt; list = registerMap.get(interfaceName);</span><br><span class="line">        Random random = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">int</span> i = random.nextInt(list.size());</span><br><span class="line">        <span class="keyword">return</span> list.get(i);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 写入文件</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> path</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> object</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">saveFile</span><span class="params">(String path,Object object)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        FileOutputStream fileOutputStream = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(path));</span><br><span class="line">        ObjectOutputStream objectOutputStream =<span class="keyword">new</span> ObjectOutputStream(fileOutputStream);</span><br><span class="line">        objectOutputStream.writeObject(object);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从文件中读取</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> path</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> IOException</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> ClassNotFoundException</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Object <span class="title">readFile</span><span class="params">(String path)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">        FileInputStream fileInputStream = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(path));</span><br><span class="line">        ObjectInputStream inputStream = <span class="keyword">new</span> ObjectInputStream(fileInputStream);</span><br><span class="line">        <span class="keyword">return</span> inputStream.readObject();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>这里为什么要写入文件呢？这是因为如果只存在内存中话，消费者和服务者不是同一个程序，消费者不额能感知到服务者程序内存的变化的。所以只能服务端写入文件，消费者从文件里取才能取得到。<br>dubbo注册中心怎么干的呢，dubbo只是把这些信息写到了zookeeper，或者redis.或者其他地方。<br>这里我就不再实现zookeeper的注册中心了。</p><p>接下来我们开启服务<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">package com.nnk.rpc.server.provide;</span><br><span class="line"></span><br><span class="line">import com.nnk.rpc.api.HelloService;</span><br><span class="line">import com.nnk.rpc.api.entity.URL;</span><br><span class="line">import com.nnk.rpc.register.LocalRegister;</span><br><span class="line">import com.nnk.rpc.register.RegisterType;</span><br><span class="line">import com.nnk.rpc.register.RemoteRegister;</span><br><span class="line">import com.nnk.rpc.register.factory.LocalRegisterFactory;</span><br><span class="line">import com.nnk.rpc.register.factory.RemoteRegisterFactory;</span><br><span class="line">import com.nnk.rpc.server.protocl.Protocl;</span><br><span class="line">import com.nnk.rpc.server.protocl.ProtoclFactory;</span><br><span class="line">import com.nnk.rpc.server.protocl.ProtoclType;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public class Provider &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">            URL url = new URL(&quot;localhost&quot;,8021);</span><br><span class="line">            //远程服务注册地址</span><br><span class="line">            RemoteRegister register = RemoteRegisterFactory.getRemoteRegister(RegisterType.ZOOKEEPER);</span><br><span class="line">            register.register(HelloService.class.getName(),url);</span><br><span class="line"></span><br><span class="line">            //本地注册服务的实现类</span><br><span class="line">            LocalRegister localRegister = LocalRegisterFactory.getLocalRegister(RegisterType.LOCAL);</span><br><span class="line">            localRegister.register(HelloService.class.getName(),HelloServiceImpl.class);</span><br><span class="line">            //这里我又封装了一层协议层，我们都知道dubbo有基于netty的dubbo协议，有基于http的http协议，还有基于redis的redis协议等等。    </span><br><span class="line">            Protocl protocl = ProtoclFactory.getProtocl(ProtoclType.HTTP);</span><br><span class="line">            protocl.start(url);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="消费者端："><a href="#消费者端：" class="headerlink" title="消费者端："></a>消费者端：</h2><p>消费者端其实很简单，就是根据注册中心里的信息远程调用对应服务器上的方法。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> com.nnk.rpc.client.comsummer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.api.HelloService;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.client.proxy.ProxyFactory;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.register.RegisterType;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.server.protocl.ProtoclType;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        HelloService helloService = ProxyFactory.getProxy(ProtoclType.HTTP, RegisterType.ZOOKEEPER,HelloService.class);</span><br><span class="line">        String result = helloService.sayHello(<span class="string">"liuy"</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.nnk.rpc.client.proxy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.api.entity.Invocation;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.api.entity.URL;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.register.RegisterType;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.register.RemoteRegister;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.register.factory.RemoteRegisterFactory;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.server.protocl.Protocl;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.server.protocl.ProtoclFactory;</span><br><span class="line"><span class="keyword">import</span> com.nnk.rpc.server.protocl.ProtoclType;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.InvocationHandler;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Method;</span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Proxy;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProxyFactory</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">T <span class="title">getProxy</span><span class="params">(<span class="keyword">final</span> ProtoclType protoclType ,<span class="keyword">final</span> RegisterType registerType, <span class="keyword">final</span> Class interfaceClass)</span></span>&#123;</span><br><span class="line">       <span class="keyword">return</span> (T) Proxy.newProxyInstance(interfaceClass.getClassLoader(), <span class="keyword">new</span> Class[]&#123;interfaceClass&#125;, <span class="keyword">new</span> InvocationHandler() &#123;</span><br><span class="line">           <span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">               Protocl protocl = ProtoclFactory.getProtocl(protoclType);</span><br><span class="line">               Invocation invocation = <span class="keyword">new</span> Invocation(interfaceClass.getName(),method.getName(),method.getParameterTypes(),args);</span><br><span class="line">               RemoteRegister remoteRegister = RemoteRegisterFactory.getRemoteRegister(registerType);</span><br><span class="line">               URL radomURL = remoteRegister.getRadomURL(interfaceClass.getName());</span><br><span class="line">               System.out.println(<span class="string">"调用地址host:"</span>+ radomURL.getHost()+ <span class="string">",port:"</span>+radomURL.getPort());</span><br><span class="line">               <span class="keyword">return</span> protocl.invokeProtocl(radomURL,invocation);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此Dubbo的RPC调用核心框架就已经基本实现了。<br>涉及到的东西其实挺多的，有tomcat的知识（http协议实现），协议的序列化和反序列化（远程调用消息的传递），netty的知识（dubbo协议的实现），动态代理的知识（消费者端实现）。反射（远程调用的核心）。再深入点就是负载均衡算法（在远程获取服务者的地址时可以抽象）。</p><p>更完整的代码请去我的github上下载 <a href="https://github.com/liuyong520/myRPC" target="_blank" rel="noopener">Dubbo-tony</a><br>如果有什么不清楚的地方，欢迎大家留言，咱们可以一起交流讨论。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;dubbo-简单介绍&quot;&gt;&lt;a href=&quot;#dubbo-简单介绍&quot; class=&quot;headerlink&quot; title=&quot;dubbo 简
      
    
    </summary>
    
    
      <category term="duboo" scheme="http://www.liuyong520.cn/tags/duboo/"/>
    
      <category term="rpc" scheme="http://www.liuyong520.cn/tags/rpc/"/>
    
  </entry>
  
  <entry>
    <title>storm 的分组策略深入理解（-）</title>
    <link href="http://www.liuyong520.cn/2019/05/11/storm-groupping/"/>
    <id>http://www.liuyong520.cn/2019/05/11/storm-groupping/</id>
    <published>2019-05-11T12:10:40.000Z</published>
    <updated>2019-06-11T09:37:15.537Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><h1 id="storm的分组策略"><a href="#storm的分组策略" class="headerlink" title="storm的分组策略"></a>storm的分组策略</h1><ul><li><p>洗牌分组(Shuffle grouping): 随机分配元组到Bolt的某个任务上，这样保证同一个Bolt的每个任务都能够得到相同数量的元组。</p></li><li><p>字段分组(Fields grouping): 按照指定的分组字段来进行流的分组。例如，流是用字段“user-id”来分组的，那有着相同“user-id”的元组就会分到同一个任务里，但是有不同“user-id”的元组就会分到不同的任务里。这是一种非常重要的分组方式，通过这种流分组方式，我们就可以做到让Storm产出的消息在这个”user-id”级别是严格有序的，这对一些对时序敏感的应用(例如，计费系统)是非常重要的。</p></li><li><p>Partial Key grouping: 跟字段分组一样，流也是用指定的分组字段进行分组的，但是在多个下游Bolt之间是有负载均衡的，这样当输入数据有倾斜时可以更好的利用资源。这篇论文很好的解释了这是如何工作的，有哪些优势。</p></li><li><p>All grouping: 流会复制给Bolt的所有任务。小心使用这种分组方式。在拓扑中，如果希望某类元祖发送到所有的下游消费者，就可以使用这种All grouping的流分组策略。</p></li><li><p>Global grouping: 整个流会分配给Bolt的一个任务。具体一点，会分配给有最小ID的任务。<br>不分组(None grouping): 说明不关心流是如何分组的。目前，None grouping等价于洗牌分组。</p></li><li><p>Direct grouping：一种特殊的分组。对于这样分组的流，元组的生产者决定消费者的哪个任务会接收处理这个元组。只能在声明做直连的流(direct streams)上声明Direct groupings分组方式。只能通过使用emitDirect系列函数来吐元组给直连流。一个Bolt可以通过提供的TopologyContext来获得消费者的任务ID，也可以通过OutputCollector对象的emit函数(会返回元组被发送到的任务的ID)来跟踪消费者的任务ID。在ack的实现中，Spout有两个直连输入流，ack和ackFail，使用了这种直连分组的方式。</p></li><li><p>Local or shuffle grouping：如果目标Bolt在同一个worker进程里有一个或多个任务，元组就会通过洗牌的方式分配到这些同一个进程内的任务里。否则，就跟普通的洗牌分组一样。这种方式的好处是可以提高拓扑的处理效率，因为worker内部通信就是进程内部通信了，相比拓扑间的进程间通信要高效的多。worker进程间通信是通过使用Netty来进行网络通信的。</p></li></ul><h1 id="根据实例来分析分组策略"><a href="#根据实例来分析分组策略" class="headerlink" title="根据实例来分析分组策略"></a>根据实例来分析分组策略</h1><h2 id="common配置："><a href="#common配置：" class="headerlink" title="common配置："></a>common配置：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;com.sonly.strom&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;strom-study&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;source&gt;7&lt;/source&gt;</span><br><span class="line">                    &lt;target&gt;7&lt;/target&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;descriptorRefs&gt;</span><br><span class="line">                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;</span><br><span class="line">                    &lt;/descriptorRefs&gt;</span><br><span class="line">                    &lt;archive&gt;</span><br><span class="line">                        &lt;manifest&gt;</span><br><span class="line">                            &lt;mainClass&gt;com.sonly.storm.demo1.HelloToplogy&lt;/mainClass&gt;</span><br><span class="line">                        &lt;/manifest&gt;</span><br><span class="line">                    &lt;/archive&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">                &lt;executions&gt;</span><br><span class="line">                    &lt;execution&gt;</span><br><span class="line">                        &lt;id&gt;make-assembly&lt;/id&gt;</span><br><span class="line">                        &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">                        &lt;goals&gt;</span><br><span class="line">                            &lt;goal&gt;single&lt;/goal&gt;</span><br><span class="line">                        &lt;/goals&gt;</span><br><span class="line">                    &lt;/execution&gt;</span><br><span class="line">                &lt;/executions&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.storm&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;storm-core&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.2&lt;/version&gt;</span><br><span class="line">            &lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><h1 id="Shuffle-grouping"><a href="#Shuffle-grouping" class="headerlink" title="Shuffle grouping"></a>Shuffle grouping</h1><h2 id="shuffle-grouping的实例代码"><a href="#shuffle-grouping的实例代码" class="headerlink" title="shuffle grouping的实例代码"></a>shuffle grouping的实例代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings.spout;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.atomic.AtomicInteger;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 20:27&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(WordSpout.class);</span><br><span class="line">    <span class="comment">//拓扑上下文</span></span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map config;</span><br><span class="line">    <span class="keyword">private</span> AtomicInteger atomicInteger = <span class="keyword">new</span> AtomicInteger(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext topologyContext, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.config = conf;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = collector;</span><br><span class="line">        LOGGER.warn(<span class="string">"WordSpout-&gt;open:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>, <span class="keyword">this</span>.hashCode(), Thread.currentThread().getId(), context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String[] sentences = <span class="keyword">new</span> String[]&#123;<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"zhangsan"</span>,<span class="string">"lisi"</span>,<span class="string">"lisi"</span>&#125;;</span><br><span class="line">        <span class="keyword">int</span> i = atomicInteger.get();</span><br><span class="line">        <span class="keyword">if</span>(i&lt;<span class="number">10</span>)&#123;</span><br><span class="line">            atomicInteger.incrementAndGet();</span><br><span class="line">            <span class="keyword">final</span> String sentence = sentences[i];</span><br><span class="line">            collector.emit(<span class="keyword">new</span> Values(sentence));</span><br><span class="line">            LOGGER.warn(<span class="string">"WordSpout-&gt;nextTuple:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,Values:&#123;&#125;"</span>, <span class="keyword">this</span>.hashCode(), Thread.currentThread().getId(), context.getThisTaskId(), sentence);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"sentence"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>bolt1<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:19&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SheffleGroupingBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(SheffleGroupingBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Integer&gt; counts = <span class="keyword">new</span> HashMap(<span class="number">16</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"SheffleGroupingBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        String word = tuple.getString(<span class="number">0</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"SheffleGroupingBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),word);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"bolt1"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>bolt<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:29&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SheffleGrouppingBolt1</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(SheffleGrouppingBolt1.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"SheffleGrouppingBolt1-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        String word = tuple.getStringByField(<span class="string">"sentence"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"SheffleGroupingBolt1-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),word);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"bolt"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>topology<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1.grouppings;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.sonly.storm.demo1.grouppings.spout.WordSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.LocalCluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:55&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShuffleGroupingToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(ShuffleGroupingToplogy.class);</span><br><span class="line">    <span class="comment">//Topology Name</span></span><br><span class="line">    <span class="comment">//component prefix</span></span><br><span class="line">    <span class="comment">//workers</span></span><br><span class="line">    <span class="comment">//spout executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//spout task size</span></span><br><span class="line">    <span class="comment">//bolt executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//bolt task size</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">if</span> (args==<span class="keyword">null</span> || args.length &lt; <span class="number">7</span>) &#123;</span><br><span class="line">            conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">            builder.setSpout(<span class="string">"spout"</span>, <span class="keyword">new</span> WordSpout(), <span class="number">4</span>).setNumTasks(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">            builder.setBolt(<span class="string">"split-bolt"</span>, <span class="keyword">new</span> SheffleGrouppingBolt1(),  <span class="number">4</span>).shuffleGrouping(<span class="string">"spout"</span>).setNumTasks(<span class="number">8</span>);</span><br><span class="line">            builder.setBolt(<span class="string">"count-bolt"</span>, <span class="keyword">new</span> SheffleGroupingBolt(), <span class="number">8</span>).fieldsGrouping(<span class="string">"split-bolt"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>)).setNumTasks(<span class="number">8</span>);</span><br><span class="line">            LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">            cluster.submitTopology(<span class="string">"word-count"</span>, conf, builder.createTopology());</span><br><span class="line"></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            cluster.killTopology(<span class="string">"word-count"</span>);</span><br><span class="line">            cluster.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            Options options = Options.builder(args);</span><br><span class="line">            LOGGER.warn(<span class="string">"The Topology Options &#123;&#125; is Submited "</span>,options.toString());</span><br><span class="line">            conf.setNumWorkers(options.getWorkers());</span><br><span class="line">            builder.setSpout(options.getPrefix()+<span class="string">"-spout"</span>, <span class="keyword">new</span> WordSpout(), options.getSpoutParallelismHint()).setNumTasks(options.getSpoutTaskSize());</span><br><span class="line"></span><br><span class="line">            builder.setBolt(<span class="string">"bolt1"</span>, <span class="keyword">new</span> SheffleGrouppingBolt1(),  options.getBoltParallelismHint()).shuffleGrouping(options.getPrefix()+<span class="string">"-spout"</span>).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            builder.setBolt(<span class="string">"bolt"</span>, <span class="keyword">new</span> SheffleGroupingBolt(), options.getBoltParallelismHint()).shuffleGrouping(options.getPrefix()+<span class="string">"-spout"</span>).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                StormSubmitter.submitTopologyWithProgressBar(options.getTopologyName(), conf, builder.createTopology());</span><br><span class="line">                LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">                LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>,options.getTopologyName());</span><br><span class="line">                LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Options</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String topologyName;</span><br><span class="line">        <span class="keyword">private</span> String prefix;</span><br><span class="line">        <span class="keyword">private</span> Integer workers;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutTaskSize;</span><br><span class="line">        <span class="keyword">private</span> Integer boltParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer boltTaskSize;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Options</span><span class="params">(String topologyName, String prefix, Integer workers, Integer spoutParallelismHint, Integer spoutTaskSize, Integer boltParallelismHint, Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Options <span class="title">builder</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Options(args[<span class="number">0</span>],args[<span class="number">1</span>],Integer.parseInt(args[<span class="number">2</span>])</span><br><span class="line">            ,Integer.parseInt(args[<span class="number">3</span>]),Integer.parseInt(args[<span class="number">4</span>]),Integer.parseInt(args[<span class="number">5</span>]),Integer.parseInt(args[<span class="number">6</span>])</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getTopologyName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTopologyName</span><span class="params">(String topologyName)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getPrefix</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrefix</span><span class="params">(String prefix)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getWorkers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWorkers</span><span class="params">(Integer workers)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutParallelismHint</span><span class="params">(Integer spoutParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutTaskSize</span><span class="params">(Integer spoutTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltParallelismHint</span><span class="params">(Integer boltParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltTaskSize</span><span class="params">(Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"Options&#123;"</span> +</span><br><span class="line">                    <span class="string">"topologyName='"</span> + topologyName + <span class="string">'\''</span> +</span><br><span class="line">                    <span class="string">", prefix='"</span> + prefix + <span class="string">'\''</span> +</span><br><span class="line">                    <span class="string">", workers="</span> + workers +</span><br><span class="line">                    <span class="string">", spoutParallelismHint="</span> + spoutParallelismHint +</span><br><span class="line">                    <span class="string">", spoutTaskSize="</span> + spoutTaskSize +</span><br><span class="line">                    <span class="string">", boltParallelismHint="</span> + boltParallelismHint +</span><br><span class="line">                    <span class="string">", boltTaskSize="</span> + boltTaskSize +</span><br><span class="line">                    <span class="string">'&#125;'</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>mvn package 打包，上传到storm服务器</p><h2 id="ShuffleGrouping-样例分析"><a href="#ShuffleGrouping-样例分析" class="headerlink" title="ShuffleGrouping 样例分析"></a>ShuffleGrouping 样例分析</h2><p><strong>1)样例1</strong></p><p>1.执行：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar strom-study-1.0-SNAPSHOT-jar-with-dependencies.jar com.sonly.storm.demo1.grouppings.ShuffleGroupingToplogy ShuffleGrouping ShuffleGrouping 1 2 1 2 1</span><br></pre></td></tr></table></figure><p></p><p>2.参数：</p><p>topologyName=’ShuffleGrouping’, prefix=’ShuffleGrouping’, workers=1, spoutParallelismHint=2, spoutTaskSize=1, boltParallelismHint=2, boltTaskSize=1<br>3.拓扑图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557542411480.png" alt="enter description here"><br>一个spout接了两个bolt<br>4.查看一下这个bolt分布情况：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557542590072.png" alt="enter description here"><br>5.进入服务器去看每一个bolt的日志<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2019-05-07 18:09:13.109 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.110 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.110 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.111 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.112 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.115 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.116 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.117 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 18:09:13.118 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:lisi</span><br><span class="line">2019-05-07 18:09:13.119 c.s.s.d.g.SheffleGrouppingBolt1 Thread-11-bolt1-executor[5 5] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:1393282516-&gt;ThreadId:45,TaskId:5,value:lisi</span><br></pre></td></tr></table></figure><p></p><p>6.进入另外一个bolt的日志 10条信息被处理了<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2019-05-07 18:09:00.791 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.793 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.794 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.795 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.795 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.796 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.797 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.805 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:zhangsan</span><br><span class="line">2019-05-07 18:09:00.805 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:lisi</span><br><span class="line">2019-05-07 18:09:00.806 c.s.s.d.g.SheffleGroupingBolt Thread-9-bolt-executor[4 4] [WARN] SheffleGroupingBolt-&gt;execute:hashcode:1430296959-&gt;ThreadId:43,TaskId:4,value:lisi</span><br></pre></td></tr></table></figure><p></p><p>也是一样10条被处理了<br><strong>总结：</strong><br><strong>对于spout直接对接两个bolt，sheffgrouping 分组不会随机给两个bolt分配消息，而是全量发给两个BOlT</strong></p><p><strong>2）样例2</strong></p><p>1.修改一下参数看一下：<br>topologyName=’ShuffleGrouping1’, prefix=’ShuffleGrouping1’, workers=2, spoutParallelismHint=1, spoutTaskSize=2, boltParallelismHint=2, boltTaskSize=2<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557544178946.png" alt="enter description here"><br>总共4个bolt，两个spout，总共发送了40条消息，spout产生消息20条。transfer了40次。<br>看看4个bolt的消息分配的情况。<br>因为只有两个worker所以会有两个bolt在同一个work上，日志会打在一起，但是从名字可以可以区分开来，同样每个bolt都是10条。</p><p>2.修改拓扑结构为：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557547693509.png" alt="enter description here"><br>3.修改代码：<br>bolt<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String word = tuple.getStringByField(<span class="string">"bolt"</span>);</span><br></pre></td></tr></table></figure><p></p><p>topoloy：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> builder.setBolt(<span class="string">"bolt1"</span>, <span class="keyword">new</span> SheffleGrouppingBolt1(), <span class="number">1</span>).shuffleGrouping(options.getPrefix()+<span class="string">"-spout"</span>);</span><br><span class="line">builder.setBolt(<span class="string">"bolt"</span>, <span class="keyword">new</span> SheffleGroupingBolt(), options.getBoltParallelismHint()).shuffleGrouping(<span class="string">"bolt1"</span>).setNumTasks(options.getBoltTaskSize());</span><br></pre></td></tr></table></figure><p></p><p>4.参数：<br>topologyName=’ShuffleGrouping2’, prefix=’ShuffleGrouping2’, workers=2, spoutParallelismHint=1, spoutTaskSize=1, boltParallelismHint=2, boltTaskSize=2<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557547737355.png" alt="enter description here"><br>5.查看日志：k8s-n2 这个节点只有bolt bolt1这个节点在k8s-n3上<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n2 6706]# grep &quot;SheffleGroupingBolt-&gt;execute&quot; worker.log |wc -l</span><br><span class="line">3</span><br><span class="line">[root@k8s-n2 6706]# grep &quot;SheffleGroupingBolt1-&gt;execute&quot; worker.log |wc -l</span><br><span class="line">0</span><br><span class="line">[root@k8s-n3 6706]#  grep &quot;SheffleGroupingBolt-&gt;execute&quot; worker.log |wc -l</span><br><span class="line">7</span><br><span class="line">[root@k8s-n3 6706]#  grep &quot;SheffleGroupingBolt1-&gt;execute&quot; worker.log |wc -l</span><br><span class="line">10</span><br></pre></td></tr></table></figure><p></p><p>可以看出来bolt1-&gt;bolt这条线上的数据被随机分配了一个三条一个两条。<br><strong>总结：</strong><br><strong>对于bolt 连接bolt的shuffingGrouping，消息是随机分配到多个bolt上面的</strong></p><h1 id="Fields-grouping"><a href="#Fields-grouping" class="headerlink" title="Fields grouping"></a>Fields grouping</h1><h2 id="Fields-grouping-的实例"><a href="#Fields-grouping-的实例" class="headerlink" title="Fields grouping 的实例"></a>Fields grouping 的实例</h2><p>代码:<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FeildGroupingToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(FeildGroupingToplogy.class);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//Topology Name</span></span><br><span class="line">    <span class="comment">//component prefix</span></span><br><span class="line">    <span class="comment">//workers</span></span><br><span class="line">    <span class="comment">//spout executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//spout task size</span></span><br><span class="line">    <span class="comment">//bolt executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//bolt task size</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        Options options = Options.builder(args);</span><br><span class="line">        LOGGER.warn(<span class="string">"The Topology Options &#123;&#125; is Submited "</span>, options.toString());</span><br><span class="line">        conf.setNumWorkers(options.getWorkers());</span><br><span class="line">        String spoutName = options.getPrefix() + <span class="string">"-spout"</span>;</span><br><span class="line">        builder.setSpout(spoutName, <span class="keyword">new</span> WordSpout(), options.getSpoutParallelismHint()).setNumTasks(options.getSpoutTaskSize());</span><br><span class="line">         builder.setBolt(options.getPrefix() + <span class="string">"bolt1"</span>, <span class="keyword">new</span> FieldGrouppingBolt1(), options.getBoltParallelismHint()).fieldsGrouping(spoutName, <span class="keyword">new</span> Fields(<span class="string">"sentence"</span>)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">        builder.setBolt(options.getPrefix() + <span class="string">"bolt"</span>, <span class="keyword">new</span> FieldGroupingBolt(), options.getBoltParallelismHint()).fieldsGrouping(spoutName, <span class="keyword">new</span> Fields(<span class="string">"sentence"</span>)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line"><span class="comment">//            builder.setBolt("bolt1", new FieldGrouppingBolt1(), 1).shuffleGrouping(options.getPrefix()+"-spout");</span></span><br><span class="line"><span class="comment">//            builder.setBolt("bolt", new FieldGroupingBolt(), options.getBoltParallelismHint()).fieldsGrouping("bolt1",new Fields("bolt")).setNumTasks(options.getBoltTaskSize());</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            StormSubmitter.submitTopologyWithProgressBar(options.getTopologyName(), conf, builder.createTopology());</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>, options.getTopologyName());</span><br><span class="line">            LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Options</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String topologyName;</span><br><span class="line">        <span class="keyword">private</span> String prefix;</span><br><span class="line">        <span class="keyword">private</span> Integer workers;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutTaskSize;</span><br><span class="line">        <span class="keyword">private</span> Integer boltParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer boltTaskSize;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Options</span><span class="params">(String topologyName, String prefix, Integer workers, Integer spoutParallelismHint, Integer spoutTaskSize, Integer boltParallelismHint, Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Options <span class="title">builder</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Options(args[<span class="number">0</span>], args[<span class="number">1</span>], Integer.parseInt(args[<span class="number">2</span>])</span><br><span class="line">                    , Integer.parseInt(args[<span class="number">3</span>]), Integer.parseInt(args[<span class="number">4</span>]), Integer.parseInt(args[<span class="number">5</span>]), Integer.parseInt(args[<span class="number">6</span>])</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getTopologyName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTopologyName</span><span class="params">(String topologyName)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getPrefix</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrefix</span><span class="params">(String prefix)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getWorkers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWorkers</span><span class="params">(Integer workers)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutParallelismHint</span><span class="params">(Integer spoutParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutTaskSize</span><span class="params">(Integer spoutTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltParallelismHint</span><span class="params">(Integer boltParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltTaskSize</span><span class="params">(Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="string">"Options&#123;"</span> +</span><br><span class="line">                    <span class="string">"topologyName='"</span> + topologyName + <span class="string">'\''</span> +</span><br><span class="line">                    <span class="string">", prefix='"</span> + prefix + <span class="string">'\''</span> +</span><br><span class="line">                    <span class="string">", workers="</span> + workers +</span><br><span class="line">                    <span class="string">", spoutParallelismHint="</span> + spoutParallelismHint +</span><br><span class="line">                    <span class="string">", spoutTaskSize="</span> + spoutTaskSize +</span><br><span class="line">                    <span class="string">", boltParallelismHint="</span> + boltParallelismHint +</span><br><span class="line">                    <span class="string">", boltTaskSize="</span> + boltTaskSize +</span><br><span class="line">                    <span class="string">'&#125;'</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FieldGroupingBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(FieldGroupingBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Integer&gt; counts = <span class="keyword">new</span> HashMap(<span class="number">16</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"FieldGroupingBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        String word = tuple.getStringByField(<span class="string">"bolt"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"FieldGroupingBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),word);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"bolt1"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FieldGrouppingBolt1</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(FieldGrouppingBolt1.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"FieldGrouppingBolt1-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        String word = tuple.getStringByField(<span class="string">"sentence"</span>);</span><br><span class="line">        LOGGER.warn(<span class="string">"SheffleGroupingBolt1-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,value:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),word);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"bolt"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>2.打包上传到服务器<br>3.执行：<br></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar strom-study-1.0-SNAPSHOT-jar-with-dependencies.jar com.sonly.storm.demo1.grouppings.fieldgrouping.FeildGroupingToplogy FieldGrouping1 FieldGrouping1 2 1 1 2 2</span><br></pre></td></tr></table></figure><p></p><p>4.参数<br>topologyName=’FieldGrouping1’, prefix=’FieldGrouping1’, workers=2, spoutParallelismHint=1, spoutTaskSize=1, boltParallelismHint=2, boltTaskSize=2<br>5。拓扑图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557580946479.png" alt="enter description here"><br>6.并发度以及组件分布图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557581055667.png" alt="enter description here"><br>同样看图可以看到消息被发送了20次，但是被transfer40次。这是因为spout对bolt，对消息进行了复制，全量发送到了每个bolt，所以每个bolt都会有10条消息。<br><strong>总结：</strong><br><strong>和sheffleGrouping 一样，spout-&gt;bolt是全量广播发送，每个bolt都会spout的全量消息。</strong></p><p><strong>样例2</strong><br>1.修改拓扑的代码<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">        TopologyBuilder builder = new TopologyBuilder();</span><br><span class="line">        Config conf = new Config();</span><br><span class="line">        conf.setDebug(true);</span><br><span class="line"></span><br><span class="line">        Options options = Options.builder(args);</span><br><span class="line">        LOGGER.warn(&quot;The Topology Options &#123;&#125; is Submited &quot;, options.toString());</span><br><span class="line">        conf.setNumWorkers(options.getWorkers());</span><br><span class="line">        String spoutName = options.getPrefix() + &quot;-spout&quot;;</span><br><span class="line">        builder.setSpout(spoutName, new WordSpout(), options.getSpoutParallelismHint()).setNumTasks(options.getSpoutTaskSize());</span><br><span class="line">//        builder.setBolt(options.getPrefix() + &quot;bolt1&quot;, new FieldGrouppingBolt1(), options.getBoltParallelismHint()).fieldsGrouping(spoutName, new Fields(&quot;sentence&quot;)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">//        builder.setBolt(options.getPrefix() + &quot;bolt&quot;, new FieldGroupingBolt(), options.getBoltParallelismHint()).fieldsGrouping(spoutName, new Fields(&quot;sentence&quot;)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            builder.setBolt(&quot;bolt1&quot;, new FieldGrouppingBolt1(), 1).fieldsGrouping(spoutName, new Fields(&quot;sentence&quot;));</span><br><span class="line">            builder.setBolt(&quot;bolt&quot;, new FieldGroupingBolt(), options.getBoltParallelismHint()).fieldsGrouping(&quot;bolt1&quot;,new Fields(&quot;bolt&quot;)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">        try &#123;</span><br><span class="line">            StormSubmitter.submitTopologyWithProgressBar(options.getTopologyName(), conf, builder.createTopology());</span><br><span class="line">            LOGGER.warn(&quot;===========================================================&quot;);</span><br><span class="line">            LOGGER.warn(&quot;The Topology &#123;&#125; is Submited &quot;, options.getTopologyName());</span><br><span class="line">            LOGGER.warn(&quot;===========================================================&quot;);</span><br><span class="line">        &#125; catch (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p></p><h2 id="FieldGrouping-样例分析"><a href="#FieldGrouping-样例分析" class="headerlink" title="FieldGrouping 样例分析"></a>FieldGrouping 样例分析</h2><p><strong>1）样例1</strong></p><p>2.将上面代码打包上传服务器执行命令<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar strom-study-1.0-SNAPSHOT-jar-with-dependencies.jar com.sonly.storm.demo1.grouppings.fieldgrouping.FeildGroupingToplogy FieldGrouping2 FieldGrouping2 2 1 1 2 2</span><br></pre></td></tr></table></figure><p></p><p>3.参数<br>topologyName=’FieldGrouping2’, prefix=’FieldGrouping2’, workers=2, spoutParallelismHint=1, spoutTaskSize=1, boltParallelismHint=2, boltTaskSize=<br>4.拓扑图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557583229548.png" alt="enter description here"><br>6.并发度以及组件分布图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557583288457.png" alt="enter description here"><br>7.根据分布情况检查各个work的日志查看消息的发送情况<br>k8s-n3节点上：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n3 6701]# grep &quot;SheffleGroupingBolt1-&gt;execute&quot; worker.log|wc -l</span><br><span class="line">10</span><br><span class="line">[root@k8s-n3 6701]# grep &quot;FieldGroupingBolt-&gt;execute&quot; worker.log|wc -l</span><br><span class="line">2</span><br></pre></td></tr></table></figure><p></p><p>k8s-n2节点：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n2 6701]# grep &quot;SheffleGroupingBolt1-&gt;execute&quot; worker.log|wc -l</span><br><span class="line">0</span><br><span class="line">[root@k8s-n2 6701]# grep &quot;FieldGroupingBolt-&gt;execute&quot; worker.log|wc -l</span><br><span class="line">8</span><br></pre></td></tr></table></figure><p></p><p>再看一下详情如何<br>k8s-n3：bolt1有10条消息应为bolt只有一个所以Fied分组是不会生效的。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n3 6701]# grep &quot;SheffleGroupingBolt1-&gt;execute&quot; worker.log</span><br><span class="line">2019-05-07 21:59:35.805 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.810 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.810 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.811 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.811 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.812 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.813 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.814 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:zhangsan</span><br><span class="line">2019-05-07 21:59:35.815 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:lisi</span><br><span class="line">2019-05-07 21:59:35.838 c.s.s.d.g.f.FieldGrouppingBolt1 Thread-7-bolt1-executor[6 6] [WARN] SheffleGroupingBolt1-&gt;execute:hashcode:107880849-&gt;ThreadId:41,TaskId:6,value:lisi</span><br></pre></td></tr></table></figure><p></p><p>k8s-n3:bolt 有两个实例，按照field分组。里面有两条消息。都是lisi<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n3 6701]# grep &quot;FieldGroupingBolt-&gt;execute&quot; worker.log</span><br><span class="line">2019-05-07 21:59:35.855 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[4 4] [WARN] FieldGroupingBolt-&gt;execute:hashcode:281792799-&gt;ThreadId:45,TaskId:4,value:lisi</span><br><span class="line">2019-05-07 21:59:35.856 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[4 4] [WARN] FieldGroupingBolt-&gt;execute:hashcode:281792799-&gt;ThreadId:45,TaskId:4,value:lisi</span><br></pre></td></tr></table></figure><p></p><p>k8s-n2: bolt 应该就是8条消息，验证一下<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n2 6701]# grep &quot;FieldGroupingBolt-&gt;execute&quot; worker.log</span><br><span class="line">2019-05-07 21:59:48.315 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.317 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.317 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.318 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.318 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.319 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.319 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br><span class="line">2019-05-07 21:59:48.320 c.s.s.d.g.f.FieldGroupingBolt Thread-11-bolt-executor[5 5] [WARN] FieldGroupingBolt-&gt;execute:hashcode:1858735164-&gt;ThreadId:45,TaskId:5,value:zhangsan</span><br></pre></td></tr></table></figure><p></p><p><strong>总结：</strong><br><strong>bolt-&gt;bolt节点时，feild分组会按照field字段的key值进行分组，key相同的会被分配到一个bolt里面。</strong><br>如果执行<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar strom-study-1.0-SNAPSHOT-jar-with-dependencies.jar com.sonly.storm.demo1.grouppings.fieldgrouping.FeildGroupingToplogy FieldGrouping3 FieldGrouping3 4 1 1 4 4</span><br></pre></td></tr></table></figure><p></p><p>bolt 的分配情况是什么样子？这个留给大家去思考一下。例子中按照field分组后只有两种数据，但是这两种数据要分配给4个bolt，那这个是怎么分配的？我将在下一篇博客里揭晓答案！</p><p>下一篇我会继续分析这个分组策略，我会把我在学习这个storm的时候当时的自己思考的一个过程展现给大家，如果有什么错误的，或者没有讲清楚的地方，欢迎大家给我留言，咱们可以一起交流讨论。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;storm的分组策略&quot;&gt;&lt;a href=&quot;#storm的分组策略&quot; class=&quot;headerlink&quot; title=&quot;storm的分
      
    
    </summary>
    
      <category term="storm" scheme="http://www.liuyong520.cn/categories/storm/"/>
    
    
      <category term="storm" scheme="http://www.liuyong520.cn/tags/storm/"/>
    
  </entry>
  
  <entry>
    <title>理解storm并发度</title>
    <link href="http://www.liuyong520.cn/2019/05/10/storm-parallelism/"/>
    <id>http://www.liuyong520.cn/2019/05/10/storm-parallelism/</id>
    <published>2019-05-10T03:46:25.000Z</published>
    <updated>2019-06-11T09:37:15.349Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h1 id="什么是storm的并发度"><a href="#什么是storm的并发度" class="headerlink" title="什么是storm的并发度"></a>什么是storm的并发度</h1><p>一个topology（拓扑）在storm集群上最总是以executor和task的形式运行在suppervisor管理的worker节点上。而worker进程都是运行在jvm虚拟机上面的，每个拓扑都会被拆开多个组件分布式的运行在worker节点上。<br>1.worker<br>2.executor<br>3.task<br>这三个简单关系图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557460241883.png" alt="官方图"></p><p>一个worker工作进程运行一个拓扑的子集（其实就是拓扑的组件），每个组件的都会以executor（线程）在worker进程上执行，一个worker进程可以同时运行多个拓扑的组件也就是线程。</p><p>一个executor线程可以运行同一个组件的一个或者多个tasks</p><p>task是实际处理数据的执行者，每一个spout或者bolt会在集群上执行很多个task。在拓扑的生命周期内拓扑结构相同的拓扑的组件任务task数量总是相同的。但是每个组件的执行的线程（executor）数是可以变化的。这就意味着以下条件总是成立的：#threads ≤ #tasks 也就是task的数量总是大于线程数，一般情况下，任务task的数量往往设置成和线程（executor）的数量一致，这样，每个线程执行一个task。</p><p>在storm拓扑的并发度其实就是集群上拓扑组件在集群上运行的executor（线程）的数量。</p><h1 id="如何设置拓扑的并发度"><a href="#如何设置拓扑的并发度" class="headerlink" title="如何设置拓扑的并发度"></a>如何设置拓扑的并发度</h1><p>“并行度”如何配置？其实不仅仅是设置executor线程的数量,同时也要从worker工作进程和task任务的数量的方面考虑。<br>可以用以下几种方式配置并发度：<br>1.通过storm的配置文件配置。storm配置文件的加载优先级是：defaults.yaml &lt; storm.yaml &lt; topology-specific configuration &lt; internal component-specific configuration &lt; external component-specific configuration.<br>工作进程数<br>描述：为群集中的计算机上的拓扑创建多少个工作进程。<br>配置选项：TOPOLOGY_WORKERS<br>如何设置代码（示例）：<br>配置＃setNumWorkers<br>执行者数（线程数）<br>描述：每个组件生成多少个执行程序。<br>配置选项：无（将parallelism_hint参数传递给setSpout或setBolt）<br>如何设置代码（示例）：<br>TopologyBuilder＃setSpout（）<br>TopologyBuilder＃setBolt（）<br>请注意，从Storm 0.8开始，parallelism_hint参数现在指定该螺栓的执行者的初始数量（不是任务！）。<br>任务数量<br>描述：每个组件创建多少个任务。<br>配置选项：TOPOLOGY_TASKS<br>如何设置代码（示例）：<br>ComponentConfigurationDeclarer＃setNumTasks（）<br>以下是在实践中显示这些设置的示例代码段：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">topologyBuilder.setBolt(<span class="string">"green-bolt"</span>, <span class="keyword">new</span> GreenBolt(), <span class="number">2</span>)</span><br><span class="line">               .setNumTasks(<span class="number">4</span>)</span><br><span class="line">               .shuffleGrouping(<span class="string">"blue-spout"</span>);</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">在上面的代码中，我们配置了Storm来运行GreenBolt带有初始数量为两个执行器和四个相关任务的bolt 。Storm将为每个执行程序（线程）运行两个任务。如果您没有明确配置任务数，Storm将默认运行每个执行程序一个任务。</span><br><span class="line"></span><br><span class="line">#官方例子</span><br><span class="line">下图显示了简单拓扑在操作中的外观。拓扑结构由三个部分组成：一个叫做spout BlueSpout，两个叫做GreenBolt和YellowBolt。组件被链接，以便BlueSpout将其输出发送到GreenBolt，然后将其自己的输出发送到YellowBolt。</span><br><span class="line">![官方图](https:<span class="comment">//www.github.com/liuyong520/pic/raw/master/小书匠/1557460241883.png)</span></span><br><span class="line">在GreenBolt被配置为每代码段以上而BlueSpout和YellowBolt仅设置并行提示（执行人数）。这是相关代码：</span><br><span class="line">```java</span><br><span class="line">Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">conf.setNumWorkers(<span class="number">2</span>); <span class="comment">// use two worker processes</span></span><br><span class="line"></span><br><span class="line">topologyBuilder.setSpout(<span class="string">"blue-spout"</span>, <span class="keyword">new</span> BlueSpout(), <span class="number">2</span>); <span class="comment">// set parallelism hint to 2</span></span><br><span class="line"></span><br><span class="line">topologyBuilder.setBolt(<span class="string">"green-bolt"</span>, <span class="keyword">new</span> GreenBolt(), <span class="number">2</span>)</span><br><span class="line">               .setNumTasks(<span class="number">4</span>)</span><br><span class="line">               .shuffleGrouping(<span class="string">"blue-spout"</span>);</span><br><span class="line"></span><br><span class="line">topologyBuilder.setBolt(<span class="string">"yellow-bolt"</span>, <span class="keyword">new</span> YellowBolt(), <span class="number">6</span>)</span><br><span class="line">               .shuffleGrouping(<span class="string">"green-bolt"</span>);</span><br><span class="line"></span><br><span class="line">StormSubmitter.submitTopology(</span><br><span class="line">        <span class="string">"mytopology"</span>,</span><br><span class="line">        conf,</span><br><span class="line">        topologyBuilder.createTopology()</span><br><span class="line">    );</span><br></pre></td></tr></table></figure><p>当然，Storm附带了额外的配置设置来控制拓扑的并行性，包括：</p><p>TOPOLOGY_MAX_TASK_PARALLELISM：此设置为可以为单个组件生成的执行程序数量设置上限。它通常在测试期间用于限制在本地模式下运行拓扑时产生的线程数。您可以通过例如Config＃setMaxTaskParallelism（）设置此选项。</p><h1 id="从实际运行的拓扑的角度理解storm的并发度"><a href="#从实际运行的拓扑的角度理解storm的并发度" class="headerlink" title="从实际运行的拓扑的角度理解storm的并发度"></a>从实际运行的拓扑的角度理解storm的并发度</h1><h2 id="自己写一个拓扑"><a href="#自己写一个拓扑" class="headerlink" title="自己写一个拓扑"></a>自己写一个拓扑</h2><p>实现一个可以设置worker数量，设置spout 、bolt 的Parallelism Hint的拓扑然后打包上传到storm集群运行。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.LocalCluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)HelloToplogy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:55&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(HelloToplogy.class);</span><br><span class="line">    <span class="comment">//Topology Name</span></span><br><span class="line">    <span class="comment">//component prefix</span></span><br><span class="line">    <span class="comment">//workers</span></span><br><span class="line">    <span class="comment">//spout executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//spout task size</span></span><br><span class="line">    <span class="comment">//bolt executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//bolt task size</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">if</span> (args==<span class="keyword">null</span> || args.length &lt; <span class="number">7</span>) &#123;</span><br><span class="line">            conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">            builder.setSpout(<span class="string">"spout"</span>, <span class="keyword">new</span> HellowordSpout(), <span class="number">4</span>).setNumTasks(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">            builder.setBolt(<span class="string">"split-bolt"</span>, <span class="keyword">new</span> SplitBolt(),  <span class="number">4</span>).shuffleGrouping(<span class="string">"spout"</span>).setNumTasks(<span class="number">8</span>);</span><br><span class="line">            builder.setBolt(<span class="string">"count-bolt"</span>, <span class="keyword">new</span> HellowordBolt(), <span class="number">8</span>).fieldsGrouping(<span class="string">"split-bolt"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>)).setNumTasks(<span class="number">8</span>);</span><br><span class="line">            LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">            cluster.submitTopology(<span class="string">"word-count"</span>, conf, builder.createTopology());</span><br><span class="line"></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            cluster.killTopology(<span class="string">"word-count"</span>);</span><br><span class="line">            cluster.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            Options options = Options.builder(args);</span><br><span class="line">            conf.setNumWorkers(options.getWorkers());</span><br><span class="line">            builder.setSpout(options.getPrefix()+<span class="string">"-spout"</span>, <span class="keyword">new</span> HellowordSpout(), options.getSpoutParallelismHint()).setNumTasks(options.getSpoutTaskSize());</span><br><span class="line"></span><br><span class="line">            builder.setBolt(options.getPrefix()+<span class="string">"-split-bolt"</span>, <span class="keyword">new</span> SplitBolt(),  options.getBoltParallelismHint()).shuffleGrouping(options.getPrefix()+<span class="string">"-spout"</span>).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            builder.setBolt(options.getPrefix()+<span class="string">"-count-bolt"</span>, <span class="keyword">new</span> HellowordBolt(), options.getBoltParallelismHint()).fieldsGrouping(options.getPrefix()+<span class="string">"-split-bolt"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                StormSubmitter.submitTopologyWithProgressBar(options.getTopologyName(), conf, builder.createTopology());</span><br><span class="line">                LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">                LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>,options.getTopologyName());</span><br><span class="line">                LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Options</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String topologyName;</span><br><span class="line">        <span class="keyword">private</span> String prefix;</span><br><span class="line">        <span class="keyword">private</span> Integer workers;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutTaskSize;</span><br><span class="line">        <span class="keyword">private</span> Integer boltParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer boltTaskSize;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Options</span><span class="params">(String topologyName, String prefix, Integer workers, Integer spoutParallelismHint, Integer spoutTaskSize, Integer boltParallelismHint, Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Options <span class="title">builder</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Options(args[<span class="number">0</span>],args[<span class="number">1</span>],Integer.parseInt(args[<span class="number">2</span>])</span><br><span class="line">            ,Integer.parseInt(args[<span class="number">3</span>]),Integer.parseInt(args[<span class="number">4</span>]),Integer.parseInt(args[<span class="number">5</span>]),Integer.parseInt(args[<span class="number">6</span>])</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getTopologyName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTopologyName</span><span class="params">(String topologyName)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getPrefix</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrefix</span><span class="params">(String prefix)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getWorkers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWorkers</span><span class="params">(Integer workers)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutParallelismHint</span><span class="params">(Integer spoutParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutTaskSize</span><span class="params">(Integer spoutTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltParallelismHint</span><span class="params">(Integer boltParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltTaskSize</span><span class="params">(Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>spout 类：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Currency;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;HellowordSpout&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 20:27&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HellowordSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(HellowordSpout.class);</span><br><span class="line">    <span class="comment">//拓扑上下文</span></span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map config;</span><br><span class="line">    <span class="keyword">private</span> Random random;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext topologyContext, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.config = conf;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = collector;</span><br><span class="line">        <span class="keyword">this</span>.random = <span class="keyword">new</span> Random();</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordSpout-&gt;open:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String[] sentences = <span class="keyword">new</span> String[]&#123;<span class="string">"hello world !"</span>, <span class="string">"hello Storm !"</span>,</span><br><span class="line">                <span class="string">"hello apache flink !"</span>, <span class="string">"hello apache kafka stream !"</span>, <span class="string">"hello apache spark !"</span>&#125;;</span><br><span class="line">        <span class="keyword">final</span> String sentence = sentences[random.nextInt(sentences.length)];</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(sentence));</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordSpout-&gt;nextTuple:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,Values:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),sentence);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"sentence"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordSpout-&gt;close:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>实现两个bolt一个用来统计单词出现个数，一个用来拆分语句。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:19&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HellowordBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(HellowordBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Integer&gt; counts = <span class="keyword">new</span> HashMap(<span class="number">16</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">        String word = tuple.getString(<span class="number">0</span>);</span><br><span class="line">        Integer count = counts.get(word);</span><br><span class="line">        <span class="keyword">if</span> (count == <span class="keyword">null</span>)</span><br><span class="line">            count = <span class="number">0</span>;</span><br><span class="line">        count++;</span><br><span class="line">        counts.put(word, count);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(word, count));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>, <span class="string">"count"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:29&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(SplitBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"SplitBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        String words = tuple.getStringByField(<span class="string">"sentence"</span>);</span><br><span class="line">        String[] contents = words.split(<span class="string">" +"</span>);</span><br><span class="line">        <span class="keyword">for</span> (String content : contents) &#123;</span><br><span class="line">            collector.emit(<span class="keyword">new</span> Values(content));</span><br><span class="line">            collector.ack(tuple);</span><br><span class="line">        &#125;</span><br><span class="line">        LOGGER.warn(<span class="string">"SplitBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>local模式启动运行<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557417096146.png" alt="enter description here"></p><p>在pom文件中添加打包插件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;descriptorRefs&gt;</span><br><span class="line">            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;</span><br><span class="line">        &lt;/descriptorRefs&gt;</span><br><span class="line">        &lt;archive&gt;</span><br><span class="line">            &lt;manifest&gt;</span><br><span class="line">                &lt;mainClass&gt;com.sonly.storm.demo1.HelloToplogy&lt;/mainClass&gt;</span><br><span class="line">            &lt;/manifest&gt;</span><br><span class="line">        &lt;/archive&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">    &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">            &lt;id&gt;make-assembly&lt;/id&gt;</span><br><span class="line">            &lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">            &lt;goals&gt;</span><br><span class="line">                &lt;goal&gt;single&lt;/goal&gt;</span><br><span class="line">            &lt;/goals&gt;</span><br><span class="line">        &lt;/execution&gt;</span><br><span class="line">    &lt;/executions&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p>同时修改dependency 的scope为provide<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;scope&gt;provide&lt;/scope&gt;</span><br></pre></td></tr></table></figure><p></p><p>原因是服务器上storm相关包都已经存在了，防止重复打包导致冲突。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//Topology Name</span><br><span class="line">//component prefix</span><br><span class="line">//workers</span><br><span class="line">//spout executor (parallelism_hint)</span><br><span class="line">//spout task size</span><br><span class="line">//bolt executor (parallelism_hint)</span><br><span class="line">//bolt task size</span><br></pre></td></tr></table></figure><p></p><h2 id="在storm集群提交拓扑"><a href="#在storm集群提交拓扑" class="headerlink" title="在storm集群提交拓扑"></a>在storm集群提交拓扑</h2><h3 id="修改日志级别"><a href="#修改日志级别" class="headerlink" title="修改日志级别"></a>修改日志级别</h3><p>修改worker的工作进程的日志级别，修改成只输出warn日志，避免其他日志对我的干扰。进入${your_storm_path}/log4j2/目录修改worker.xml文件。先把worker.xml备份把Info级别改成warn<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ cp worker.xml worker.xml.bak</span><br></pre></td></tr></table></figure><p></p><p>修改成：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&lt;loggers&gt;</span><br><span class="line">    &lt;root level=&quot;warn&quot;&gt; &lt;!-- We log everything --&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;A1&quot;/&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;syslog&quot;/&gt;</span><br><span class="line">    &lt;/root&gt;</span><br><span class="line">    &lt;Logger name=&quot;org.apache.storm.metric.LoggingMetricsConsumer&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;METRICS&quot;/&gt;</span><br><span class="line">    &lt;/Logger&gt;</span><br><span class="line">    &lt;Logger name=&quot;STDERR&quot; level=&quot;INFO&quot;&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;STDERR&quot;/&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;syslog&quot;/&gt;</span><br><span class="line">    &lt;/Logger&gt;</span><br><span class="line">    &lt;Logger name=&quot;STDOUT&quot; level=&quot;INFO&quot;&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;STDOUT&quot;/&gt;</span><br><span class="line">        &lt;appender-ref ref=&quot;syslog&quot;/&gt;</span><br><span class="line">    &lt;/Logger&gt;</span><br><span class="line">&lt;/loggers&gt;</span><br></pre></td></tr></table></figure><p></p><p>同步到另外两台supervisor的工作节点服务器。<br>为了跟清晰的理解并发度，我会通过这个demo 拓扑，修改参数观察stormUI的exector数量和tasks数量。</p><h3 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">// topologyName=&apos;count&apos; ## Topology Name 拓扑的名字</span><br><span class="line">// prefix=&apos;tp1&apos; ## component prefix 即为每个spout，bolt的前缀名称</span><br><span class="line">// workers=1  ## worker number 即为工作进程jvm数量</span><br><span class="line">// spoutParallelismHint=2  ## spout executor (parallelism_hint) 即spout的线程数量</span><br><span class="line">// spoutTaskSize=1 ## spout task size 即spout的运行实例数</span><br><span class="line">// boltParallelismHint=2  ## bolt executor (parallelism_hint) 即bolt的线程数量</span><br><span class="line">// boltTaskSize=1  ##bolt task size 即bolt的运行实例数</span><br></pre></td></tr></table></figure><h2 id="根据样例分析理解storm的并发度"><a href="#根据样例分析理解storm的并发度" class="headerlink" title="根据样例分析理解storm的并发度"></a>根据样例分析理解storm的并发度</h2><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><p>执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar storm-demo1.jar com.sonly.storm.demo1.HelloToplogy tp1 tp1 1 2 0 2 0</span><br></pre></td></tr></table></figure><p>参数详情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;topologyName=&apos;tp1&apos;, prefix=&apos;tp1&apos;, workers=1, spoutParallelismHint=2, spoutTaskSize=0, boltParallelismHint=2, boltTaskSize=0&#125;</span><br></pre></td></tr></table></figure><p>这时候task都被设置成0了。如下图：excutors为1，task为1。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557487851467.png" alt="tp1"><br>接着往下看：此时我们的bolt的task都被设置0了，所以我们是没有创建spout，bolt的，但是你会发现一个_acker的bolt，这是storm的acker机制，storm自己给我们创建的bolt，并且每一个worker都会必须有一个_acker的bolt，如果我们没有取消ack机制的话。所以worker上只用了一个excutor来跑这个_acker的bolt。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557488029568.png" alt="tp1组件图"></p><h3 id="例子2"><a href="#例子2" class="headerlink" title="例子2"></a>例子2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar storm-demo1.jar com.sonly.storm.demo1.HelloToplogy tp2 tp2 1 2 1 2 1</span><br></pre></td></tr></table></figure><p>参数详情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;topologyName=&apos;tp2&apos;, prefix=&apos;tp2&apos;, workers=1, spoutParallelismHint=2, spoutTaskSize=1, boltParallelismHint=2, boltTaskSize=1&#125;</span><br></pre></td></tr></table></figure><p>此时 task的值都被设置成1了。如下图：excutors为4，task为4。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557488644015.png" alt="tp2"><br>接着看一下spout，bolt 以及组件的分布情况见下图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557488808341.png" alt="tp2组件"><br>此时已经我们的有tp2-spout 一个spout，除了系统的acker 还有我们自己创建的两个bolt。因为只有一个worker所以全部分布在一个worker里面。<br>尽管我们设置了spout的线程数为2，bolt的线程数为2，但是task都被设置成1，只有一个任务需要被两个excutor执行，所以有一个线程实际上是没有任务执行的。所以线程数，就是这几个task的值的和，<br>一个spout，两个自己的创建的bolt以及acker的task数量的和。</p><h3 id="例子3"><a href="#例子3" class="headerlink" title="例子3"></a>例子3</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar storm-demo1.jar com.sonly.storm.demo1.HelloToplogy tp3 tp3 2 2 1 2 1</span><br></pre></td></tr></table></figure><p>参数详情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;topologyName=&apos;tp3&apos;, prefix=&apos;tp3&apos;, workers=2, spoutParallelismHint=2, spoutTaskSize=1, boltParallelismHint=2, boltTaskSize=1&#125;</span><br></pre></td></tr></table></figure><p>此时worker已经被设置成2了，如下图：executor为5，task为5.<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557491206007.png" alt="tp3"><br>接着看一下spout，bolt以及组件的分布情况如下图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557491303432.png" alt="tp3组件"></p><p>此时，task任务数依然是1，spout和bolt都是1份，acker每个worker都必须有一份的，所以，executor的数就是task实例数也就是：一个spout 两个系统acker bolt，和两个我们自己的bolt。也就是5.这个5个task不均匀的分配到了两个worker进程上。</p><h3 id="例子4"><a href="#例子4" class="headerlink" title="例子4"></a>例子4</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar storm-demo1.jar com.sonly.storm.demo1.HelloToplogy tp4 tp4 2 2 2 2 2</span><br></pre></td></tr></table></figure><p>参数详情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;topologyName=&apos;tp4&apos;, prefix=&apos;tp4&apos;, workers=2, spoutParallelismHint=2, spoutTaskSize=2, boltParallelismHint=2, boltTaskSize=2&#125;</span><br></pre></td></tr></table></figure><p>此时参数已经taks 数量被设置成2了，如下图：executor为8，task为8.<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557491922132.png" alt="tp4"><br>再看一下spout，bolt的分布情况：如下图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557492028989.png" alt="tp4组件图"><br>此时，我们task都被设置成了2，那spout实例和bolt的实例都是2，也就是2+2+2=6 这个是我们自己的创建的task，再加上acker两个task，所以task参数就是8.而这里设置时executor也是8个 被均分到两个worker上面。</p><h3 id="例子5"><a href="#例子5" class="headerlink" title="例子5"></a>例子5</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm jar storm-demo1.jar com.sonly.storm.demo1.HelloToplogy tp5 tp5 2 2 4 2 4</span><br></pre></td></tr></table></figure><p>参数详情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;topologyName=&apos;tp5&apos;, prefix=&apos;tp5&apos;, workers=2, spoutParallelismHint=2, spoutTaskSize=4, boltParallelismHint=2, boltTaskSize=4&#125;</span><br></pre></td></tr></table></figure><p>此时task设置成4，excutor设置成2，那这样的话，一个excutor会跑两个task ，executor=8,task=14 如下图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557492553004.png" alt="tp5"><br>继续看一下spout和bolt的分布情况：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557492702803.png" alt="tp5组件图"><br>此时task设置成4，executor是2，那就是bolt和spout实例就是 4+4+4=12 再加上两个worker的Acker就是14个task。exector 是bolt的设置的值2+2+2=6个再加上两个acker的值，就是8个。同时，一个executor执行了两个task。8个executor平均分配到两个worker上面了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>exector和task的值，和拓扑结构有关系，拓扑中的spout 和bolt设置的parallelism_hint都会影响到exector和task的数量。task和exectuor之间的关系在设置上就已经确定了，最好exector和task之间，task 的数量最好设置成executor的倍数，这样每个executor执行的task才是一样的。<br>说到这里，相信大家对并发度，有了比较清晰的理解。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;什么是storm的并发度&quot;&gt;&lt;a href=&quot;#什么是storm的并发度&quot; class=&quot;headerlink&quot; title=&quot;什么是
      
    
    </summary>
    
      <category term="storm" scheme="http://www.liuyong520.cn/categories/storm/"/>
    
    
      <category term="storm" scheme="http://www.liuyong520.cn/tags/storm/"/>
    
  </entry>
  
  <entry>
    <title>storm 基本知识</title>
    <link href="http://www.liuyong520.cn/2019/05/02/storm-base/"/>
    <id>http://www.liuyong520.cn/2019/05/02/storm-base/</id>
    <published>2019-05-02T14:00:40.000Z</published>
    <updated>2019-06-11T09:37:15.528Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:48 GMT+0800 (GMT+08:00) --><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>介绍storm之前，我先抛出这两个问题：</p><blockquote><p>1.实时计算需要解决些什么问题？<br>2.storm作为实时计算到底有何优势？</p></blockquote><h1 id="storm简介"><a href="#storm简介" class="headerlink" title="storm简介"></a>storm简介</h1><p>官方介绍：</p><blockquote><p>Apache Storm is a free and open source distributed realtime computation system. Storm makes it easy to reliably process unbounded streams of data, doing for realtime processing what Hadoop did for batch processing. Storm is simple, can be used with any programming language, and is a lot of fun to use!<br>翻译：<br>Apache Storm是一个免费的开源分布式实时计算系统。Storm可以轻松可靠地处理无限数据流，实时处理Hadoop为批处理所做的工作。storm很简单，可以与任何编程语言一起使用，并且使用起来很有趣！</p></blockquote><p>简单的说就是：storm是一个分布式实时计算系统。<br>1.实时计算需要解决些什么问题？<br>伴随着信息科技的日新月异的发展，信息呈现出爆发式的膨胀，人们获取信息的渠道也更加多元化，获取信息的方式也更加便捷，对信息的实效性也越来越高，举个电商系统一个搜索的简单例子，当卖家发布一条宝贝信息时，买家在搜索的时候需要能够马上呈现出来，同时买家购买后，能够需要统计该商品的卖出的数量以及该商品总营业额，利润等等。而且可以根据最近的购买的记录，可以给用户推荐同类型的产品。诸如此类的都需要以大数据为基础的，通过离线或者实时计算，获取相关的信息，从而获得商机。</p><p>在Storm之前，进行实时处理是非常痛苦的事情: 需要维护一堆消息队列和消费者，他们构成了非常复杂的图结构。消费者进程从队列里取消息，处理完成后，去更新数据库，或者给其他队列发新消息。</p><p>这样进行实时处理是非常痛苦的。我们主要的时间都花在关注往哪里发消息，从哪里接收消息，消息如何序列化，真正的业务逻辑只占了源代码的一小部分。一个应用程序的逻辑运行在很多worker上，但这些worker需要各自单独部署，还需要部署消息队列。最大问题是系统很脆弱，而且不是容错的：需要自己保证消息队列和worker进程工作正常。<br>例如上面的例子，简单的统计数量，统计营业额，计算毛利润，根据购买记录，推荐相似商品等等，就是通过，开启多个工作线程，实时去扫表，或者是从消息对列中拿出数据，计算统计值，写入对应的表。<br>这种定时任务，往往数据处理也不够及时，实效性比较差。</p><p>2.实时计算系统要考虑哪些问题？</p><ul><li>低延迟 处理消息一定要及时，延迟高就不叫实时了。</li><li>高性能 性能不高，那么就要浪费机器，这样浪费机器就是浪费资源</li><li>分布式 系统数据和来源可能有多个，处理数据结果也有可能作为基础数据给其他系统。如果你的系统应用单机就能搞定，那么不需要考虑这么复杂了，实时计算系统就是为了解决这种单机系统无法解决的问题的。</li><li>可扩展 伴随业务的的发展，我们的业务量，及计算量可能会越来越大，系统是要求可以扩展的，</li><li>容错性 这个是分布式系统的通用问题了，一个节点挂了，不能影响到整个系统。<br>3.storm的优势</li><li>简单的编程模型。类似于MapReduce降低了批处理的复杂性，storm降低了进行实时处理的复杂性</li><li>服务化，一个服务框架，支持热部署，即时上线或者下线app</li><li>支持多种语言，你可以在storm之上使用各种编程语言，默认支持的有clojure,java,ruby,python</li><li>容错性，storm会管理工作进程和节点故障</li><li>水平扩展性，计算是在多个系统、进程、服务器之间进行的。可以水平扩展机器，进程，或者线程等。</li><li>可靠的消息处理 storm 能够保证消息至少能够得到一次完整的消息处理。任务失败时，它会负责从消息源头重新处理。</li><li>快速 系统的设计保证消息的快速处理，低版本的storm使用的zeroMQ作为内部消息系统。高版本中使用netty完全替代了ZeroMQ作为内部消息系统</li><li>本地模式 storm 又一个本地模式，能够模拟集群，使我们的开发测试变得更加简单。<h1 id="storm的基本概念"><a href="#storm的基本概念" class="headerlink" title="storm的基本概念"></a>storm的基本概念</h1></li></ul><ol><li><p>拓扑(Topologies)<br>实时应用程序的逻辑被打包到Storm拓扑中。Storm拓扑类似于MapReduce作业。一个关键的区别是MapReduce作业最终完成，而拓扑结构永远运行（当然，直到你杀死它）。个拓扑是一个通过流分组(stream grouping)把Spout和Bolt连接到一起的拓扑结构。图的每条边代表一个Bolt订阅了其他Spout或者Bolt的输出流。一个拓扑就是一个复杂的多阶段的流计算。</p></li><li><p>元组(Tuple)<br>元组是Storm提供的一个轻量级的数据格式，可以用来包装你需要实际处理的数据。元组是一次消息传递的基本单元。一个元组是一个命名的值列表，其中的每个值都可以是任意类型的。元组是动态地进行类型转化的–字段的类型不需要事先声明。在Storm中编程时，就是在操作和转换由元组组成的流。通常，元组包含整数，字节，字符串，浮点数，布尔值和字节数组等类型。要想在元组中使用自定义类型，就需要实现自己的序列化方式。</p></li><li><p>流(Streams)<br>流是Storm中的核心抽象。一个流由无限的元组序列组成，这些元组会被分布式并行地创建和处理。通过流中元组包含的字段名称来定义这个流。<br>每个流声明时都被赋予了一个ID。只有一个流的Spout和Bolt非常常见，所以OutputFieldsDeclarer提供了不需要指定ID来声明一个流的函数(Spout和Bolt都需要声明输出的流)。这种情况下，流的ID是默认的“default”。</p></li><li><p>Spouts(喷嘴)<br>Spout(喷嘴，这个名字很形象)是Storm中流的来源。通常Spout从外部数据源，如消息队列中读取元组数据并吐到拓扑里。Spout可以是可靠的(reliable)或者不可靠(unreliable)的。可靠的Spout能够在一个元组被Storm处理失败时重新进行处理，而非可靠的Spout只是吐数据到拓扑里，不关心处理成功还是失败了。</p></li></ol><p>Spout可以一次给多个流吐数据。此时需要通过OutputFieldsDeclarer的declareStream函数来声明多个流并在调用SpoutOutputCollector提供的emit方法时指定元组吐给哪个流。</p><p>Spout中最主要的函数是nextTuple，Storm框架会不断调用它去做元组的轮询。如果没有新的元组过来，就直接返回，否则把新元组吐到拓扑里。nextTuple必须是非阻塞的，因为Storm在同一个线程里执行Spout的函数。</p><p>Spout中另外两个主要的函数是ack和fail。当Storm检测到一个从Spout吐出的元组在拓扑中成功处理完时调用ack,没有成功处理完时调用fail。只有可靠型的Spout会调用ack和fail函数。</p><ol start="5"><li>Bolts<br>在拓扑中所有的计算逻辑都是在Bolt中实现的。一个Bolt可以处理任意数量的输入流，产生任意数量新的输出流。Bolt可以做函数处理，过滤，流的合并，聚合，存储到数据库等操作。Bolt就是流水线上的一个处理单元，把数据的计算处理过程合理的拆分到多个Bolt、合理设置Bolt的task数量，能够提高Bolt的处理能力，提升流水线的并发度。</li></ol><p>Bolt可以给多个流吐出元组数据。此时需要使用OutputFieldsDeclarer的declareStream方法来声明多个流并在使用<a href="https://storm.apache.org/javadoc/apidocs/backtype/storm/task/OutputCollector.html" target="_blank" rel="noopener">OutputColletor</a>的emit方法时指定给哪个流吐数据。</p><p>当你声明了一个Bolt的输入流，也就订阅了另外一个组件的某个特定的输出流。如果希望订阅另一个组件的所有流，需要单独挨个订阅。InputDeclarer有语法糖来订阅ID为默认值的流。例如declarer.shuffleGrouping(“redBolt”)订阅了redBolt组件上的默认流，跟declarer.shuffleGrouping(“redBolt”, DEFAULT_STREAM_ID)是相同的。</p><p>在Bolt中最主要的函数是execute函数，它使用一个新的元组当作输入。Bolt使用OutputCollector对象来吐出新的元组。Bolts必须为处理的每个元组调用OutputCollector的ack方法以便于Storm知道元组什么时候被各个Bolt处理完了（最终就可以确认Spout吐出的某个元组处理完了）。通常处理一个输入的元组时，会基于这个元组吐出零个或者多个元组，然后确认(ack)输入的元组处理完了，Storm提供了IBasicBolt接口来自动完成确认。</p><p>必须注意OutputCollector不是线程安全的，所以所有的吐数据(emit)、确认(ack)、通知失败(fail)必须发生在同一个线程里</p><ol start="6"><li><p>任务(Tasks)<br>每个Spout和Bolt会以多个任务(Task)的形式在集群上运行。每个任务对应一个执行线程，流分组定义了如何从一组任务(同一个Bolt)发送元组到另外一组任务(另外一个Bolt)上。可以在调用TopologyBuilder的setSpout和setBolt函数时设置每个Spout和Bolt的并发数。</p></li><li><p>组件(Component)<br>组件(component)是对Bolt和Spout的统称</p></li><li><p>流分组(Stream groupings)<br>定义拓扑的时候，一部分工作是指定每个Bolt应该消费哪些流。流分组定义了一个流在一个消费它的Bolt内的多个任务(task)之间如何分组。流分组跟计算机网络中的路由功能是类似的，决定了每个元组在拓扑中的处理路线。</p></li></ol><p>在Storm中有七个内置的流分组策略，你也可以通过实现CustomStreamGrouping接口来自定义一个流分组策略:</p><ul><li>洗牌分组(Shuffle grouping): 随机分配元组到Bolt的某个任务上，这样保证同一个Bolt的每个任务都能够得到相同数量的元组。</li><li>字段分组(Fields grouping): 按照指定的分组字段来进行流的分组。例如，流是用字段“user-id”来分组的，那有着相同“user-id”的元组就会分到同一个任务里，但是有不同“user-id”的元组就会分到不同的任务里。这是一种非常重要的分组方式，通过这种流分组方式，我们就可以做到让Storm产出的消息在这个”user-id”级别是严格有序的，这对一些对时序敏感的应用(例如，计费系统)是非常重要的。</li><li>Partial Key grouping: 跟字段分组一样，流也是用指定的分组字段进行分组的，但是在多个下游Bolt之间是有负载均衡的，这样当输入数据有倾斜时可以更好的利用资源。这篇论文很好的解释了这是如何工作的，有哪些优势。</li><li>All grouping: 流会复制给Bolt的所有任务。小心使用这种分组方式。在拓扑中，如果希望某类元祖发送到所有的下游消费者，就可以使用这种All grouping的流分组策略。</li><li>Global grouping: 整个流会分配给Bolt的一个任务。具体一点，会分配给有最小ID的任务。<br>不分组(None grouping): 说明不关心流是如何分组的。目前，None grouping等价于洗牌分组。</li><li>Direct grouping：一种特殊的分组。对于这样分组的流，元组的生产者决定消费者的哪个任务会接收处理这个元组。只能在声明做直连的流(direct streams)上声明Direct groupings分组方式。只能通过使用emitDirect系列函数来吐元组给直连流。一个Bolt可以通过提供的TopologyContext来获得消费者的任务ID，也可以通过OutputCollector对象的emit函数(会返回元组被发送到的任务的ID)来跟踪消费者的任务ID。在ack的实现中，Spout有两个直连输入流，ack和ackFail，使用了这种直连分组的方式。</li><li>Local or shuffle grouping：如果目标Bolt在同一个worker进程里有一个或多个任务，元组就会通过洗牌的方式分配到这些同一个进程内的任务里。否则，就跟普通的洗牌分组一样。这种方式的好处是可以提高拓扑的处理效率，因为worker内部通信就是进程内部通信了，相比拓扑间的进程间通信要高效的多。worker进程间通信是通过使用Netty来进行网络通信的。</li></ul><ol start="9"><li>可靠性(Reliability)<br>Storm保证了拓扑中Spout产生的每个元组都会被处理。Storm是通过跟踪每个Spout所产生的所有元组构成的树形结构并得知这棵树何时被完整地处理来达到可靠性。每个拓扑对这些树形结构都有一个关联的“消息超时”。如果在这个超时时间里Storm检测到Spout产生的一个元组没有被成功处理完，那Sput的这个元组就处理失败了，后续会重新处理一遍。</li></ol><p>为了发挥Storm的可靠性，需要你在创建一个元组树中的一条边时告诉Storm，也需要在处理完每个元组之后告诉Storm。这些都是通过Bolt吐元组数据用的OutputCollector对象来完成的。标记是在emit函数里完成，完成一个元组后需要使用ack函数来告诉Storm。</p><ol start="10"><li>Workers(工作进程)<br>拓扑以一个或多个Worker进程的方式运行。每个Worker进程是一个物理的Java虚拟机，执行拓扑的一部分任务。例如，如果拓扑的并发设置成了300，分配了50个Worker，那么每个Worker执行6个任务(作为Worker内部的线程）。Storm会尽量把所有的任务均分到所有的Worker上。</li></ol><h1 id="storm的工作流程"><a href="#storm的工作流程" class="headerlink" title="storm的工作流程"></a>storm的工作流程</h1><p>Storm实现了一个数据流(data flow)的模型，在这个模型中数据持续不断地流经一个由很多转换实体构成的网络。一个数据流的抽象叫做流(stream)，流是无限的元组(Tuple)序列。元组就像一个可以表示标准数据类型（例如int，float和byte数组）和用户自定义类型（需要额外序列化代码的）的数据结构。每个流由一个唯一的ID来标示的，这个ID可以用来构建拓扑中各个组件的数据源。</p><p>如下图所示，其中的水龙头代表了数据流的来源，一旦水龙头打开，数据就会源源不断地流经Bolt而被处理。图中有三个流，用不同的颜色来表示，每个数据流中流动的是元组(Tuple)，它承载了具体的数据。元组通过流经不同的转换实体而被处理。</p><p>Storm对数据输入的来源和输出数据的去向没有做任何限制。像Hadoop，是需要把数据放到自己的文件系统HDFS里的。在Storm里，可以使用任意来源的数据输入和任意的数据输出，只要你实现对应的代码来获取/写入这些数据就可以。典型场景下，输入/输出数据来是基于类似Kafka或者ActiveMQ这样的消息队列，但是数据库，文件系统或者web服务也都是可以的。<br>如图：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557330376448.png" alt="enter description here"></p><h1 id="storm-测试用例并运行"><a href="#storm-测试用例并运行" class="headerlink" title="storm 测试用例并运行"></a>storm 测试用例并运行</h1><p>往往我在学习这些开源框架的时候，查看官方文档和源码中的例子是入门上手比较快的一种方式。<br>这里我也是从官方文档和github上的代码入手的<br>1.clone 下来1.2.2的源码<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --branch v1.2.2 https://github.com/apache/storm.git</span><br></pre></td></tr></table></figure><p></p><p>2.进入examples目录下有很多例子，如storm-starter这个项目。同时在github上进入这个例子的目录下有README.md文件，介绍如何运行我们的测试例子。我们可以先感官体验一下storm运行拓扑是怎样的。详情请看<a href="https://github.com/apache/storm/tree/master/examples/storm-starter" target="_blank" rel="noopener">storm-starter</a><br>step 1：用idea 打开storm源码 然后用maven打包或者进入storm-starter项目里面执行<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mvn package</span><br></pre></td></tr></table></figure><p></p><p>会在target目录里面生成一个start-storm-{version}.jar包上传到storm的服务器。<br>step 2: 提交运行实例拓扑，有本地和集群两种模式。是不是本地模式🉐️看代码如何实现的。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">storm jar stormlib/storm-starter-1.2.2.jar org.apache.storm.starter.ExclamationTopology  ##本地模式</span><br><span class="line">storm jar stormlib/storm-starter-1.2.2.jar org.apache.storm.starter.ExclamationTopology ExclamationTopology ## ExclamationTopology为Topology的名字</span><br></pre></td></tr></table></figure><p></p><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557397799999.png" alt="enter description here"><br>step 3: org.apache.storm.starter.ExclamationTopology 这个拓扑类如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> org.apache.storm.starter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.LocalCluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.testing.TestWordSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.utils.Utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This is a basic example of a Storm topology.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExclamationTopology</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExclamationBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    OutputCollector _collector;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map conf, TopologyContext context, OutputCollector collector)</span> </span>&#123;</span><br><span class="line">      _collector = collector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">      _collector.emit(tuple, <span class="keyword">new</span> Values(tuple.getString(<span class="number">0</span>) + <span class="string">"!!!"</span>));</span><br><span class="line">      _collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">      declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="comment">//构建拓扑类</span></span><br><span class="line">    TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder(); </span><br><span class="line">    <span class="comment">//设置数据获取来源spout</span></span><br><span class="line">    builder.setSpout(<span class="string">"word"</span>, <span class="keyword">new</span> TestWordSpout(), <span class="number">10</span>);</span><br><span class="line">    <span class="comment">//设置数据处理bolt类按照word分组</span></span><br><span class="line">    builder.setBolt(<span class="string">"exclaim1"</span>, <span class="keyword">new</span> ExclamationBolt(), <span class="number">3</span>).shuffleGrouping(<span class="string">"word"</span>);</span><br><span class="line">    <span class="comment">//设置数据处理bolt类按照exclaim1分组</span></span><br><span class="line">    builder.setBolt(<span class="string">"exclaim2"</span>, <span class="keyword">new</span> ExclamationBolt(), <span class="number">2</span>).shuffleGrouping(<span class="string">"exclaim1"</span>);</span><br><span class="line">    <span class="comment">//设置配置参数，打开debug模式</span></span><br><span class="line">    Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">    conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line">    <span class="comment">// 根据传入参数创建对应拓扑，如果参数大于0，就提交到storm集群，集群模式运行</span></span><br><span class="line">    <span class="keyword">if</span> (args != <span class="keyword">null</span> &amp;&amp; args.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">      <span class="comment">//通过nimbus提交拓扑到suppervisisor工作节点运行</span></span><br><span class="line">      StormSubmitter.submitTopologyWithProgressBar(args[<span class="number">0</span>], conf, builder.createTopology());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123; <span class="comment">//否则就是local本地模式运行，本地模式运行所有的日志都会打印到本地，可以用来调试</span></span><br><span class="line"></span><br><span class="line">      LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">      cluster.submitTopology(<span class="string">"test"</span>, conf, builder.createTopology());</span><br><span class="line">      Utils.sleep(<span class="number">10000</span>);</span><br><span class="line">      <span class="comment">//运行10秒后杀掉拓扑</span></span><br><span class="line">      cluster.killTopology(<span class="string">"test"</span>); </span><br><span class="line">      <span class="comment">//同时释放资源，关掉storm</span></span><br><span class="line">      cluster.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>org.apache.storm.testing.TestWordSpout;<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> org.apache.storm.testing;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.utils.Utils;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestWordSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Logger LOG = LoggerFactory.getLogger(TestWordSpout.class);</span><br><span class="line">    <span class="keyword">boolean</span> _isDistributed;</span><br><span class="line">    SpoutOutputCollector _collector;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TestWordSpout</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">TestWordSpout</span><span class="params">(<span class="keyword">boolean</span> isDistributed)</span> </span>&#123;</span><br><span class="line">        _isDistributed = isDistributed;</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext context, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">        _collector = collector;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Utils.sleep(<span class="number">100</span>);</span><br><span class="line">        <span class="keyword">final</span> String[] words = <span class="keyword">new</span> String[] &#123;<span class="string">"nathan"</span>, <span class="string">"mike"</span>, <span class="string">"jackson"</span>, <span class="string">"golda"</span>, <span class="string">"bertels"</span>&#125;;</span><br><span class="line">        <span class="keyword">final</span> Random rand = <span class="keyword">new</span> Random();</span><br><span class="line">        <span class="keyword">final</span> String word = words[rand.nextInt(words.length)];</span><br><span class="line">        <span class="comment">//随机从这些字符串中获取数据</span></span><br><span class="line">        _collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ack</span><span class="params">(Object msgId)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fail</span><span class="params">(Object msgId)</span> </span>&#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, Object&gt; <span class="title">getComponentConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(!_isDistributed) &#123;</span><br><span class="line">            Map&lt;String, Object&gt; ret = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">            ret.put(Config.TOPOLOGY_MAX_TASK_PARALLELISM, <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><h1 id="storm-API-简单介绍"><a href="#storm-API-简单介绍" class="headerlink" title="storm API 简单介绍"></a>storm API 简单介绍</h1><p>1.拓扑构建<br>TopologyBuilder公开了Java API，用于指定要执行的Storm拓扑。拓扑结构最终是Thrift结构，但由于Thrift API非常冗长，TopologyBuilder极大地简化了创建拓扑的过程。用于创建和提交拓扑的模板类似于：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">builder.setSpout(<span class="string">"1"</span>, <span class="keyword">new</span> TestWordSpout(<span class="keyword">true</span>), <span class="number">5</span>);</span><br><span class="line">builder.setSpout(<span class="string">"2"</span>, <span class="keyword">new</span> TestWordSpout(<span class="keyword">true</span>), <span class="number">3</span>);</span><br><span class="line">builder.setBolt(<span class="string">"3"</span>, <span class="keyword">new</span> TestWordCounter(), <span class="number">3</span>)</span><br><span class="line">         .fieldsGrouping(<span class="string">"1"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>))</span><br><span class="line">         .fieldsGrouping(<span class="string">"2"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">builder.setBolt(<span class="string">"4"</span>, <span class="keyword">new</span> TestGlobalCount())</span><br><span class="line">         .globalGrouping(<span class="string">"1"</span>);</span><br><span class="line"></span><br><span class="line">Map conf = <span class="keyword">new</span> HashMap();</span><br><span class="line">conf.put(Config.TOPOLOGY_WORKERS, <span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">StormSubmitter.submitTopology(<span class="string">"mytopology"</span>, conf, builder.createTopology());</span><br></pre></td></tr></table></figure><p>在本地模式（正在处理）中运行完全相同的拓扑，并将其配置为记录所有发出的元组，如下所示。请注意，在关闭本地群集之前，它允许拓扑运行10秒。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line"></span><br><span class="line">builder.setSpout(<span class="string">"1"</span>, <span class="keyword">new</span> TestWordSpout(<span class="keyword">true</span>), <span class="number">5</span>);</span><br><span class="line">builder.setSpout(<span class="string">"2"</span>, <span class="keyword">new</span> TestWordSpout(<span class="keyword">true</span>), <span class="number">3</span>);</span><br><span class="line">builder.setBolt(<span class="string">"3"</span>, <span class="keyword">new</span> TestWordCounter(), <span class="number">3</span>)</span><br><span class="line">         .fieldsGrouping(<span class="string">"1"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>))</span><br><span class="line">         .fieldsGrouping(<span class="string">"2"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">builder.setBolt(<span class="string">"4"</span>, <span class="keyword">new</span> TestGlobalCount())</span><br><span class="line">         .globalGrouping(<span class="string">"1"</span>);</span><br><span class="line"></span><br><span class="line">Map conf = <span class="keyword">new</span> HashMap();</span><br><span class="line">conf.put(Config.TOPOLOGY_WORKERS, <span class="number">4</span>);</span><br><span class="line">conf.put(Config.TOPOLOGY_DEBUG, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">cluster.submitTopology(<span class="string">"mytopology"</span>, conf, builder.createTopology());</span><br><span class="line">Utils.sleep(<span class="number">10000</span>);</span><br><span class="line">cluster.shutdown();</span><br></pre></td></tr></table></figure><p>模式TopologyBuilder是使用setSpout和setBolt方法将组件ID映射到组件。这些方法返回的对象随后用于声明该组件的输入。<br>详情可以查看<a href="http://storm.apache.org/releases/1.2.2/javadocs/org/apache/storm/topology/TopologyBuilder.html" target="_blank" rel="noopener">TopologyBuilder</a><br>2.创建spout相关<br>ISpout接口：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">public interface ISpout extends Serializable &#123;</span><br><span class="line">    //初始化方法</span><br><span class="line">    void open(Map conf, TopologyContext context, SpoutOutputCollector collector);</span><br><span class="line">    //关闭</span><br><span class="line">    void close();</span><br><span class="line">    //遍历元组的方法，会一直执行这个方法</span><br><span class="line">    void nextTuple();</span><br><span class="line">    //成功时调用的确认方法</span><br><span class="line">    void ack(Object msgId);</span><br><span class="line">    //失败时调用的失败方法</span><br><span class="line">    void fail(Object msgId);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>storm已经给我们提供的很多的spout接口和实现类，我们只需要实现或者对应的实现类就能和其他技术集成在一起。基本的spout，我们可以实现IRichSpout或者继承BasicRichSpout<br>完成spout的创建。<br>3.创建Bolt类<br>storm已经给我们提供的很多的Bolt接口和实现类，我们只需要实现或者对应的实现类就能和其他技术集成在一起。基本的spout，我们可以实现IRichBolt或者继承BasicRichBolt<br>如<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* BaseRichBolt 是一个不需要实现的ACK确认方法和fail（）失败方法</span></span><br><span class="line"><span class="comment">* </span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    OutputCollector _collector;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map conf, TopologyContext context, OutputCollector collector)</span> </span>&#123;</span><br><span class="line">      _collector = collector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">      _collector.emit(tuple, <span class="keyword">new</span> Values(tuple.getString(<span class="number">0</span>) + <span class="string">"!!!"</span>));</span><br><span class="line">      _collector.ack(tuple);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">      declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p></p><p>Storm使用入门起来是非常简单的。<br>下面我将简单的自己实现一个拓扑<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.Config;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.LocalCluster;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.StormSubmitter;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AlreadyAliveException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.AuthorizationException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.generated.InvalidTopologyException;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.TopologyBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)HelloToplogy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:55&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloToplogy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(HelloToplogy.class);</span><br><span class="line">    <span class="comment">//Topology Name</span></span><br><span class="line">    <span class="comment">//component prefix</span></span><br><span class="line">    <span class="comment">//workers</span></span><br><span class="line">    <span class="comment">//spout executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//spout task size</span></span><br><span class="line">    <span class="comment">//bolt executor (parallelism_hint)</span></span><br><span class="line">    <span class="comment">//bolt task size</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        conf.setDebug(<span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">if</span> (args==<span class="keyword">null</span> || args.length &lt; <span class="number">7</span>) &#123;</span><br><span class="line">            conf.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">            builder.setSpout(<span class="string">"spout"</span>, <span class="keyword">new</span> HellowordSpout(), <span class="number">4</span>).setNumTasks(<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line">            builder.setBolt(<span class="string">"split-bolt"</span>, <span class="keyword">new</span> SplitBolt(),  <span class="number">4</span>).shuffleGrouping(<span class="string">"spout"</span>).setNumTasks(<span class="number">8</span>);</span><br><span class="line">            builder.setBolt(<span class="string">"count-bolt"</span>, <span class="keyword">new</span> HellowordBolt(), <span class="number">8</span>).fieldsGrouping(<span class="string">"split-bolt"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>)).setNumTasks(<span class="number">8</span>);</span><br><span class="line">            LocalCluster cluster = <span class="keyword">new</span> LocalCluster();</span><br><span class="line">            cluster.submitTopology(<span class="string">"word-count"</span>, conf, builder.createTopology());</span><br><span class="line"></span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            cluster.killTopology(<span class="string">"word-count"</span>);</span><br><span class="line">            cluster.shutdown();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            Options options = Options.builder(args);</span><br><span class="line">            conf.setNumWorkers(options.getWorkers());</span><br><span class="line">            builder.setSpout(options.getPrefix()+<span class="string">"-spout"</span>, <span class="keyword">new</span> HellowordSpout(), options.getSpoutParallelismHint()).setNumTasks(options.getSpoutTaskSize());</span><br><span class="line"></span><br><span class="line">            builder.setBolt(options.getPrefix()+<span class="string">"-split-bolt"</span>, <span class="keyword">new</span> SplitBolt(),  options.getBoltParallelismHint()).shuffleGrouping(options.getPrefix()+<span class="string">"-spout"</span>).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            builder.setBolt(options.getPrefix()+<span class="string">"-count-bolt"</span>, <span class="keyword">new</span> HellowordBolt(), options.getBoltParallelismHint()).fieldsGrouping(options.getPrefix()+<span class="string">"-split-bolt"</span>, <span class="keyword">new</span> Fields(<span class="string">"word"</span>)).setNumTasks(options.getBoltTaskSize());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                StormSubmitter.submitTopologyWithProgressBar(options.getTopologyName(), conf, builder.createTopology());</span><br><span class="line">                LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">                LOGGER.warn(<span class="string">"The Topology &#123;&#125; is Submited "</span>,options.getTopologyName());</span><br><span class="line">                LOGGER.warn(<span class="string">"==========================================================="</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (AlreadyAliveException | InvalidTopologyException | AuthorizationException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Options</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String topologyName;</span><br><span class="line">        <span class="keyword">private</span> String prefix;</span><br><span class="line">        <span class="keyword">private</span> Integer workers;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer spoutTaskSize;</span><br><span class="line">        <span class="keyword">private</span> Integer boltParallelismHint;</span><br><span class="line">        <span class="keyword">private</span> Integer boltTaskSize;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Options</span><span class="params">(String topologyName, String prefix, Integer workers, Integer spoutParallelismHint, Integer spoutTaskSize, Integer boltParallelismHint, Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Options <span class="title">builder</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> Options(args[<span class="number">0</span>],args[<span class="number">1</span>],Integer.parseInt(args[<span class="number">2</span>])</span><br><span class="line">            ,Integer.parseInt(args[<span class="number">3</span>]),Integer.parseInt(args[<span class="number">4</span>]),Integer.parseInt(args[<span class="number">5</span>]),Integer.parseInt(args[<span class="number">6</span>])</span><br><span class="line">            );</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getTopologyName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setTopologyName</span><span class="params">(String topologyName)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.topologyName = topologyName;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getPrefix</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrefix</span><span class="params">(String prefix)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.prefix = prefix;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getWorkers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setWorkers</span><span class="params">(Integer workers)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.workers = workers;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutParallelismHint</span><span class="params">(Integer spoutParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutParallelismHint = spoutParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getSpoutTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSpoutTaskSize</span><span class="params">(Integer spoutTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.spoutTaskSize = spoutTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltParallelismHint</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltParallelismHint</span><span class="params">(Integer boltParallelismHint)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltParallelismHint = boltParallelismHint;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Integer <span class="title">getBoltTaskSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setBoltTaskSize</span><span class="params">(Integer boltTaskSize)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.boltTaskSize = boltTaskSize;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>spout 类：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.spout.SpoutOutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichSpout;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Currency;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;HellowordSpout&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 20:27&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HellowordSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(HellowordSpout.class);</span><br><span class="line">    <span class="comment">//拓扑上下文</span></span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map config;</span><br><span class="line">    <span class="keyword">private</span> Random random;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map conf, TopologyContext topologyContext, SpoutOutputCollector collector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.config = conf;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = collector;</span><br><span class="line">        <span class="keyword">this</span>.random = <span class="keyword">new</span> Random();</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordSpout-&gt;open:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String[] sentences = <span class="keyword">new</span> String[]&#123;<span class="string">"hello world !"</span>, <span class="string">"hello Storm !"</span>,</span><br><span class="line">                <span class="string">"hello apache flink !"</span>, <span class="string">"hello apache kafka stream !"</span>, <span class="string">"hello apache spark !"</span>&#125;;</span><br><span class="line">        <span class="keyword">final</span> String sentence = sentences[random.nextInt(sentences.length)];</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(sentence));</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordSpout-&gt;nextTuple:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;,Values:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId(),sentence);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"sentence"</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordSpout-&gt;close:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>实现两个bolt一个用来统计单词出现个数，一个用来拆分语句。<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:19&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HellowordBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(HellowordBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Integer&gt; counts = <span class="keyword">new</span> HashMap(<span class="number">16</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        LOGGER.warn(<span class="string">"HellowordBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">        String word = tuple.getString(<span class="number">0</span>);</span><br><span class="line">        Integer count = counts.get(word);</span><br><span class="line">        <span class="keyword">if</span> (count == <span class="keyword">null</span>)</span><br><span class="line">            count = <span class="number">0</span>;</span><br><span class="line">        count++;</span><br><span class="line">        counts.put(word, count);</span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(word, count));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>, <span class="string">"count"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.storm.demo1;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.OutputCollector;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.task.TopologyContext;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.OutputFieldsDeclarer;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.topology.base.BaseRichBolt;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Fields;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Tuple;</span><br><span class="line"><span class="keyword">import</span> org.apache.storm.tuple.Values;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.storm.demo1&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):stormstudy&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-09 21:29&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOGGER = LoggerFactory.getLogger(SplitBolt.class);</span><br><span class="line">    <span class="keyword">private</span> TopologyContext context;</span><br><span class="line">    <span class="keyword">private</span> Map conf;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.conf=map;</span><br><span class="line">        <span class="keyword">this</span>.context = topologyContext;</span><br><span class="line">        <span class="keyword">this</span>.collector = outputCollector;</span><br><span class="line">        LOGGER.warn(<span class="string">"SplitBolt-&gt;prepare:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        String words = tuple.getStringByField(<span class="string">"sentence"</span>);</span><br><span class="line">        String[] contents = words.split(<span class="string">" +"</span>);</span><br><span class="line">        <span class="keyword">for</span> (String content : contents) &#123;</span><br><span class="line">            collector.emit(<span class="keyword">new</span> Values(content));</span><br><span class="line">            collector.ack(tuple);</span><br><span class="line">        &#125;</span><br><span class="line">        LOGGER.warn(<span class="string">"SplitBolt-&gt;execute:hashcode:&#123;&#125;-&gt;ThreadId:&#123;&#125;,TaskId:&#123;&#125;"</span>,<span class="keyword">this</span>.hashCode(),Thread.currentThread().getId(),context.getThisTaskId());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer declarer)</span> </span>&#123;</span><br><span class="line">        declarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>local模式启动运行<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1557417096146.png" alt="enter description here"></p><p>在pom文件中添加打包插件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;plugin&gt;</span><br><span class="line">    &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;</span><br><span class="line">    &lt;configuration&gt;</span><br><span class="line">        &lt;descriptorRefs&gt;</span><br><span class="line">            &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;</span><br><span class="line">        &lt;/descriptorRefs&gt;</span><br><span class="line">        &lt;archive&gt;</span><br><span class="line">            &lt;manifest&gt;</span><br><span class="line">                &lt;mainClass&gt;com.sonly.storm.demo1.HelloToplogy&lt;/mainClass&gt;</span><br><span class="line">            &lt;/manifest&gt;</span><br><span class="line">        &lt;/archive&gt;</span><br><span class="line">    &lt;/configuration&gt;</span><br><span class="line">&lt;/plugin&gt;</span><br></pre></td></tr></table></figure><p>同时修改dependency 的scope为provide<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;scope&gt;provide&lt;/scope&gt;</span><br></pre></td></tr></table></figure><p></p><p>原因是服务器上storm相关包都已经存在了，防止重复打包导致冲突。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">//Topology Name</span><br><span class="line">//component prefix</span><br><span class="line">//workers</span><br><span class="line">//spout executor (parallelism_hint)</span><br><span class="line">//spout task size</span><br><span class="line">//bolt executor (parallelism_hint)</span><br><span class="line">//bolt task size</span><br></pre></td></tr></table></figure><p></p><p>打包上传后，storm jar jarName arg0 arg1 arg2 args3 …<br>后面跟参数运行即可。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:48 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;引言&quot;&gt;&lt;a href=&quot;#引言&quot; class=&quot;headerlink&quot; title=&quot;引言&quot;&gt;&lt;/a&gt;引言&lt;/h1&gt;&lt;p&gt;介绍sto
      
    
    </summary>
    
      <category term="storm" scheme="http://www.liuyong520.cn/categories/storm/"/>
    
    
      <category term="storm" scheme="http://www.liuyong520.cn/tags/storm/"/>
    
  </entry>
  
  <entry>
    <title>kafka API的使用</title>
    <link href="http://www.liuyong520.cn/2019/05/02/kafka-API/"/>
    <id>http://www.liuyong520.cn/2019/05/02/kafka-API/</id>
    <published>2019-05-02T13:37:40.000Z</published>
    <updated>2019-06-11T09:37:15.530Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h1 id="kafka-API"><a href="#kafka-API" class="headerlink" title="kafka API"></a>kafka API</h1><p>kafka Consumer提供两套Java API：高级Consumer API、和低级Consumer API。</p><p>高级Consumer API 优点：</p><ul><li>高级API写起来简单，易用。<br>不需要自行去管理offset，API已经封装好了offset这块的东西，会通过zookeeper自行管理<br>不需要管理分区，副本等情况，系统自动管理<br>消费者断线后会自动根据上次记录在zookeeper中的offset接着消费消息。</li></ul><p>高级Consumer API 缺点：</p><ul><li>不能自行控制offset。</li><li>不能自行管理分区，副本，zk等相关信息。</li></ul><p>低级API 优点：</p><ul><li>能够让开发者自己维护offset.想从哪里消费就从哪里消费</li><li>自行控制连接分区，对分区自定义负载均衡</li><li>对zookeeper的依赖性降低（如 offset 不一定要用zk来存储，可以存在缓存里或者内存中）</li></ul><p>缺点：<br>过于复杂，需要自行控制offset，连接哪个分区，找分区leader等。</p><h1 id="简单入门使用"><a href="#简单入门使用" class="headerlink" title="简单入门使用"></a>简单入门使用</h1><ol><li><p>引入maven依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.2.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li><li><p>Producer简单使用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.kafka&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):kafkaAPIdemo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)demo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-03 12:17&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">demo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"k8s-n1:9092"</span>);</span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG,<span class="string">"1"</span>);</span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"mytest"</span>, Integer.toString(i), Integer.toString(i)));</span><br><span class="line">        producer.close();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>带回调函数的生产者<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.kafka&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):kafkaAPIdemo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-03 12:58&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">demo1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//设置kafka集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"k8s-n1:9092"</span>);</span><br><span class="line">        <span class="comment">//设置brokeACK应答机制</span></span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG,<span class="string">"1"</span>);</span><br><span class="line">        <span class="comment">//设置key序列化</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="comment">//设置value序列化</span></span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="comment">//设置批量大小</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG,<span class="string">"6238"</span>);</span><br><span class="line">        <span class="comment">//设置提交延时</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG,<span class="string">"1"</span>);</span><br><span class="line">        <span class="comment">//设置producer缓存</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,Long.MAX_VALUE);</span><br><span class="line"></span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">12</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> finalI = i;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"mytest"</span>, Integer.toString(i), Integer.toString(i)), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line"></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(exception==<span class="keyword">null</span>)&#123;</span><br><span class="line">                        System.out.println(<span class="string">"发送成功: "</span> + finalI +<span class="string">","</span>+metadata.partition()+<span class="string">","</span>+ metadata.offset());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>结果：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">发送成功: 0,0,170</span><br><span class="line">发送成功: 2,0,171</span><br><span class="line">发送成功: 11,0,172</span><br><span class="line">发送成功: 4,1,101</span><br><span class="line">发送成功: 5,2,116</span><br><span class="line">发送成功: 6,2,117</span><br><span class="line">发送成功: 10,2,118</span><br><span class="line">发送成功: 1,3,175</span><br><span class="line">发送成功: 3,3,176</span><br><span class="line">发送成功: 7,3,177</span><br><span class="line">发送成功: 8,3,178</span><br><span class="line">发送成功: 9,3,179</span><br></pre></td></tr></table></figure><p></p><p>数据不均等的分配到0-3 号分区上</p><ol start="3"><li>自定义分区发送<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.Cluster;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.kafka&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):kafkaAPIdemo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-03 13:43&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomProducer</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p>设置分区<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.kafka;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.kafka&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):kafkaAPIdemo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-03 13:46&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">demo2</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//设置kafka集群</span></span><br><span class="line">        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"k8s-n1:9092"</span>);</span><br><span class="line">        <span class="comment">//设置brokeACK应答机制</span></span><br><span class="line">        properties.put(ProducerConfig.ACKS_CONFIG,<span class="string">"1"</span>);</span><br><span class="line">        <span class="comment">//设置key序列化</span></span><br><span class="line">        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="comment">//设置value序列化</span></span><br><span class="line">        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        <span class="comment">//设置批量大小</span></span><br><span class="line">        properties.put(ProducerConfig.BATCH_SIZE_CONFIG,<span class="string">"6238"</span>);</span><br><span class="line">        <span class="comment">//设置提交延时</span></span><br><span class="line">        properties.put(ProducerConfig.LINGER_MS_CONFIG,<span class="string">"1"</span>);</span><br><span class="line">        <span class="comment">//设置producer缓存</span></span><br><span class="line">        properties.put(ProducerConfig.BUFFER_MEMORY_CONFIG,Long.MAX_VALUE);</span><br><span class="line">        <span class="comment">//设置partition</span></span><br><span class="line">        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,<span class="string">"com.sonly.kafka.CustomProducer"</span>);</span><br><span class="line">        KafkaProducer&lt;String, String&gt; producer = <span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line">        <span class="keyword">for</span> ( <span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">12</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> finalI = i;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(<span class="string">"mytest"</span>, Integer.toString(i), Integer.toString(i)), <span class="keyword">new</span> Callback() &#123;</span><br><span class="line"></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> </span>&#123;</span><br><span class="line">                    <span class="keyword">if</span>(exception==<span class="keyword">null</span>)&#123;</span><br><span class="line">                        System.out.println(<span class="string">"发送成功: "</span> + finalI +<span class="string">","</span>+metadata.partition()+<span class="string">","</span>+ metadata.offset());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>消费者高级API：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.kafka.consumer&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):kafkaAPIdemo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-03 13:59&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConsumerDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Properties properties = <span class="keyword">new</span> Properties();</span><br><span class="line">        <span class="comment">//设置kafka集群</span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">"k8s-n1:9092"</span>);</span><br><span class="line">        <span class="comment">//设置brokeACK应答机制</span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">"teste3432"</span>);</span><br><span class="line">        <span class="comment">//设置key反序列化</span></span><br><span class="line">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        <span class="comment">//设置value反序列化</span></span><br><span class="line">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,<span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        <span class="comment">//设置拿取大小</span></span><br><span class="line">        properties.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG,<span class="number">100</span>*<span class="number">1024</span>*<span class="number">1024</span>);</span><br><span class="line">        <span class="comment">//设置自动提交offset</span></span><br><span class="line">        properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG,<span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">//设置自动提交延时</span></span><br><span class="line">        properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,<span class="number">1000</span>);</span><br><span class="line">        KafkaConsumer&lt;String, String&gt; consumer = <span class="keyword">new</span> KafkaConsumer&lt;String, String&gt;(properties);</span><br><span class="line">        consumer.subscribe(Arrays.asList(<span class="string">"mytest"</span>,<span class="string">"test"</span>));</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>)&#123;</span><br><span class="line">            ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="number">10</span>);</span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records) &#123;</span><br><span class="line">                System.out.println(record.topic()+<span class="string">"--"</span>+record.partition()+<span class="string">"--"</span>+record.value());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>低级API：<br>1.消费者使用低级API的主要步骤</p><table><thead><tr><th>步骤</th><th>主要工作</th></tr></thead><tbody><tr><td>1</td><td>根据指定分区从topic元数据中找到leader</td></tr><tr><td>2</td><td>获取分区最新的消费进度</td></tr><tr><td>3</td><td>从主副本中拉取分区消息</td></tr><tr><td>4</td><td>识别主副本的变化，重试</td></tr></tbody></table><p>2.方法描述：</p><table><thead><tr><th>方法</th><th>描述</th></tr></thead><tbody><tr><td>findLeader()</td><td>客户端向种子阶段发送主题元数据，将副本加入备用节点</td></tr><tr><td>getLastOffset()</td><td>消费者客户端发送偏移量请求，获取分区最近的偏移量</td></tr><tr><td>run()</td><td>消费者低级API拉取消息的方法</td></tr><tr><td>findNewLeader()</td><td>当分区主副本节点发生故障时，客户端将要找出新的主副本</td></tr></tbody></table><p>修改pom<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka_2.11&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.1.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.1.1&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.sonly.kafka.consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kafka.api.FetchRequest;</span><br><span class="line"><span class="keyword">import</span> kafka.api.FetchRequestBuilder;</span><br><span class="line"><span class="keyword">import</span> kafka.api.KAFKA_0_8_1$;</span><br><span class="line"><span class="keyword">import</span> kafka.cluster.BrokerEndPoint;</span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.*;</span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.consumer.SimpleConsumer;</span><br><span class="line"><span class="keyword">import</span> kafka.javaapi.message.ByteBufferMessageSet;</span><br><span class="line"><span class="keyword">import</span> kafka.message.MessageAndOffset;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.Consumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.ByteBuffer;</span><br><span class="line"><span class="keyword">import</span> java.util.*;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;package:com.sonly.kafka.consumer&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;project(项目):kafkaAPIdemo&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;class(类)$&#123;CLASS_NAME&#125;&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;creat date(创建时间):2019-05-03 15:21&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;author(作者):&lt;/b&gt;xxydliuyss&lt;/br&gt;</span></span><br><span class="line"><span class="comment"> * &lt;b&gt;note(备注)):&lt;/b&gt;</span></span><br><span class="line"><span class="comment"> * If you want to change the file header,please modify zhe File and Code Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LowerConsumer</span> </span>&#123;</span><br><span class="line">    <span class="comment">//保存offset</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> offset;</span><br><span class="line">    <span class="comment">//保存分区副本</span></span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer,List&lt;BrokerEndPoint&gt;&gt; partitionsMap = <span class="keyword">new</span> HashMap&lt;Integer, List&lt;BrokerEndPoint&gt;&gt;(<span class="number">1024</span>);</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        List&lt;String&gt; brokers = Arrays.asList(<span class="string">"k8s-n1"</span>, <span class="string">"k8s-n2"</span>,<span class="string">"k8s-n3"</span>);</span><br><span class="line">        <span class="keyword">int</span> port = <span class="number">9092</span>;</span><br><span class="line">        <span class="keyword">int</span> partition = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">long</span> offset=<span class="number">2</span>;</span><br><span class="line">        LowerConsumer lowerConsumer = <span class="keyword">new</span> LowerConsumer();</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line"><span class="comment">//            offset = lowerConsumer.getOffset();</span></span><br><span class="line">            lowerConsumer.getData(brokers,port,<span class="string">"mytest"</span>,partition,offset);</span><br><span class="line">            TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getOffset</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> offset;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> BrokerEndPoint <span class="title">findLeader</span><span class="params">(Collection&lt;String&gt; brokers,<span class="keyword">int</span> port,String topic,<span class="keyword">int</span> partition)</span></span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (String broker : brokers) &#123;</span><br><span class="line">            <span class="comment">//创建消费者对象操作每一台服务器</span></span><br><span class="line">            SimpleConsumer getLeader = <span class="keyword">new</span> SimpleConsumer(broker, port, <span class="number">10000</span>, <span class="number">1024</span> * <span class="number">24</span>, <span class="string">"getLeader"</span>);</span><br><span class="line">            <span class="comment">//构造元数据请求</span></span><br><span class="line">            TopicMetadataRequest topicMetadataRequest = <span class="keyword">new</span> TopicMetadataRequest(Collections.singletonList(topic));</span><br><span class="line">            <span class="comment">//发送元数据请求</span></span><br><span class="line">            TopicMetadataResponse response = getLeader.send(topicMetadataRequest);</span><br><span class="line">            <span class="comment">//解析元数据</span></span><br><span class="line">            List&lt;TopicMetadata&gt; topicMetadatas = response.topicsMetadata();</span><br><span class="line">            <span class="comment">//遍历数据</span></span><br><span class="line">            <span class="keyword">for</span> (TopicMetadata topicMetadata : topicMetadatas) &#123;</span><br><span class="line">                <span class="comment">//获取分区元数据信息</span></span><br><span class="line">                List&lt;PartitionMetadata&gt; partitionMetadatas = topicMetadata.partitionsMetadata();</span><br><span class="line">                <span class="comment">//遍历分区元数据</span></span><br><span class="line">                <span class="keyword">for</span> (PartitionMetadata partitionMetadata : partitionMetadatas) &#123;</span><br><span class="line">                    <span class="keyword">if</span>(partition == partitionMetadata.partitionId())&#123;</span><br><span class="line">                        <span class="comment">//保存，分区对应的副本，如果需要主副本挂掉重新获取leader只需要遍历这个缓存即可</span></span><br><span class="line">                        List&lt;BrokerEndPoint&gt; isr = partitionMetadata.isr();</span><br><span class="line">                        <span class="keyword">this</span>.partitionsMap.put(partition,isr);</span><br><span class="line">                        <span class="keyword">return</span> partitionMetadata.leader();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">getData</span><span class="params">(Collection&lt;String&gt; brokers,<span class="keyword">int</span> port,String topic,<span class="keyword">int</span> partition,<span class="keyword">long</span> offset)</span></span>&#123;</span><br><span class="line">        <span class="comment">//获取leader</span></span><br><span class="line">        BrokerEndPoint leader = findLeader(brokers, port, topic, partition);</span><br><span class="line">        <span class="keyword">if</span>(leader==<span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">        String host = leader.host();</span><br><span class="line">        <span class="comment">//获取数据的消费者对象</span></span><br><span class="line">        SimpleConsumer getData = <span class="keyword">new</span> SimpleConsumer(host, port, <span class="number">10000</span>, <span class="number">1024</span> * <span class="number">10</span>, <span class="string">"getData"</span>);</span><br><span class="line">        <span class="comment">//构造获取数据request 这里一次可以添加多个topic addFecth 添加即可</span></span><br><span class="line">        FetchRequest fetchRequestBuilder = <span class="keyword">new</span> FetchRequestBuilder().addFetch(topic, partition, offset, <span class="number">1024</span> * <span class="number">10</span>).build();</span><br><span class="line">        <span class="comment">//发送获取数据请求</span></span><br><span class="line">        FetchResponse fetchResponse = getData.fetch(fetchRequestBuilder);</span><br><span class="line">        <span class="comment">//解析元数据返回，这是message的一个set集合</span></span><br><span class="line">        ByteBufferMessageSet messageAndOffsets = fetchResponse.messageSet(topic, partition);</span><br><span class="line">        <span class="comment">//遍历消息集合</span></span><br><span class="line">        <span class="keyword">for</span> (MessageAndOffset messageAndOffset : messageAndOffsets) &#123;</span><br><span class="line">            <span class="keyword">long</span> offset1 = messageAndOffset.offset();</span><br><span class="line">            <span class="keyword">this</span>.setOffset(offset);</span><br><span class="line">            ByteBuffer payload = messageAndOffset.message().payload();</span><br><span class="line">            <span class="keyword">byte</span>[] buffer = <span class="keyword">new</span> <span class="keyword">byte</span>[payload.limit()];</span><br><span class="line">            payload.get(buffer);</span><br><span class="line">            String message = <span class="keyword">new</span> String(buffer);</span><br><span class="line">            System.out.println(<span class="string">"offset:"</span>+ offset1 +<span class="string">"--message:"</span>+ message);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setOffset</span><span class="params">(<span class="keyword">long</span> offset)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.offset = offset;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个低级API在最新的kafka版本中已经不再提供了。<br><i class="fas fa-quote-left fa-3x fa-pull-left"></i></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;kafka-API&quot;&gt;&lt;a href=&quot;#kafka-API&quot; class=&quot;headerlink&quot; title=&quot;kafka API
      
    
    </summary>
    
      <category term="消息队列" scheme="http://www.liuyong520.cn/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="kafka" scheme="http://www.liuyong520.cn/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>storm 安装使用</title>
    <link href="http://www.liuyong520.cn/2019/05/02/storm-install/"/>
    <id>http://www.liuyong520.cn/2019/05/02/storm-install/</id>
    <published>2019-05-02T13:37:40.000Z</published>
    <updated>2019-06-11T09:37:15.238Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><h2 id="zookeeper集群环境"><a href="#zookeeper集群环境" class="headerlink" title="zookeeper集群环境"></a>zookeeper集群环境</h2><p>storm是依赖于zookeeper注册中心的一款分布式消息对列，所以需要有zookeeper单机或者集群环境。</p><h2 id="准备三台服务器："><a href="#准备三台服务器：" class="headerlink" title="准备三台服务器："></a>准备三台服务器：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.16.18.198 k8s-n1</span><br><span class="line">172.16.18.199 k8s-n2</span><br><span class="line">172.16.18.200 k8s-n3</span><br></pre></td></tr></table></figure><h2 id="下载storm安装包"><a href="#下载storm安装包" class="headerlink" title="下载storm安装包"></a>下载storm安装包</h2><p><a href="http://storm.apache.org/downloads.html" target="_blank" rel="noopener">http://storm.apache.org/downloads.html</a> 中下载，目前最新版本的strom已经到1.2.2,我这里之前下载的是1.1.3版本的。</p><h1 id="安装storm集群"><a href="#安装storm集群" class="headerlink" title="安装storm集群"></a>安装storm集群</h1><h2 id="上传压缩包到三台服务器解压缩到-opt-目录下"><a href="#上传压缩包到三台服务器解压缩到-opt-目录下" class="headerlink" title="上传压缩包到三台服务器解压缩到/opt/目录下"></a>上传压缩包到三台服务器解压缩到/opt/目录下</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf apache-storm-1.1.3.tar.gz -C /opt</span><br><span class="line">ln -sf apache-storm-1.1.3/ storm</span><br></pre></td></tr></table></figure><h2 id="修改-conf目录下的storm-yml文件"><a href="#修改-conf目录下的storm-yml文件" class="headerlink" title="修改 conf目录下的storm.yml文件"></a>修改 conf目录下的storm.yml文件</h2><p>Storm包含一个conf/storm.yaml配置Storm守护进程的文件。这个文件里面配置的值会覆盖掉default.yml里面的值，同时里面有一些配置是必须填的<br><strong>注意：yml文件的前面的空格必须有，不然就会出问题，yml配置文件有严格的格式</strong><br>1)storm.zookeeper.servers：这是Storm集群的Zookeeper集群中的主机列表。它应该看起来像：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">storm.zookeeper.servers:</span><br><span class="line">  - &quot;k8s-n1&quot;</span><br><span class="line">  - &quot;k8s-n2</span><br><span class="line">  - &quot;k8s-n3&quot;</span><br></pre></td></tr></table></figure><p>2)如果zookeeper的默认端口不是2181的话还需要配置storm.zookeeper.port,如果是2181，此选项可以不用配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm.zookeeper.port: 2181</span><br></pre></td></tr></table></figure><p>3）storm.local.dir：Nimbus和Supervisor守护进程需要本地磁盘上的一个目录来存储少量状态（如jar，confs和类似的东西）。您应该在每台计算机上创建该目录，为其提供适当的权限，然后使用此配置填写目录位置。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm.local.dir: &quot;/data/storm&quot;</span><br></pre></td></tr></table></figure><p>4）nimbus.seeds：工作节点需要知道哪些机器是主机的候选者才能下载拓扑罐和confs。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nimbus.seeds: [&quot;k8s-n1&quot;,&quot;k8s-n2&quot;,&quot;k8s-n3&quot;]</span><br></pre></td></tr></table></figure><p>4）supervisor.slots.ports：对于每个工作者计算机，您可以使用此配置配置在该计算机上运行的工作程序数。每个工作人员使用单个端口接收消息，此设置定义哪些端口可以使用。如果您在此处定义了五个端口，那么Storm将分配最多五个工作人员在此计算机上运行。如果您定义了三个端口，Storm最多只能运行三个端口。默认情况下，此设置配置为在端口6700,6701,6702和6703上运行4个工作程序。例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">supervisor.slots.ports:</span><br><span class="line">    - 6700</span><br><span class="line">    - 6701</span><br><span class="line">    - 6702</span><br><span class="line">    - 6703</span><br></pre></td></tr></table></figure><p>5)开启监督机制监督健康状况<br>Storm提供了一种机制，管理员可以通过该机制定期管理员定期运行管理员提供的脚本，以确定节点是否健康。管理员可以让主管通过在storm.health.check.dir中的脚本中执行他们选择的任何检查来确定节点是否处于健康状态。如果脚本检测到节点处于不健康状态，则必须从标准输出打印一行，以字符串ERROR开头。主管将定期运行运行状况检查目录中的脚本并检查输出。如果脚本的输出包含字符串ERROR，如上所述，主管将关闭所有工作人员并退出。</p><p>如果主管在监督下运行，则可以调用“/ bin / storm node-health-check”来确定是否应该启动主管或节点是否运行状况不佳。</p><p>运行状况检查目录位置可以配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm.health.check.dir: &quot;healthchecks&quot;</span><br></pre></td></tr></table></figure><p>脚本必须具有执行权限。允许任何给定的运行状况检查脚本在由于超时而标记为失败之前运行的时间可以配置为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">storm.health.check.timeout.ms: 5000</span><br></pre></td></tr></table></figure><p>启动</p><p>Nimbus：在主机监督下运行命令“bin / storm nimbus”。<br>主管：在每台工作机器的监督下运行命令“bin / storm supervisor”。管理程序守护程序负责启动和停止该计算机上的工作进程。<br>UI：通过在监督下运行命令“bin / storm ui”，运行Storm UI（您可以从浏览器访问的站点，该站点提供对群集和拓扑的诊断）。可以通过将Web浏览器导航到http：// {ui host}：8080来访问UI。<br>如您所见，运行守护进程非常简单。守护程序将在您解压缩Storm版本的任何位置登录到logs /目录。<br>后台启动<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup storm ui &gt;/dev/null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h1&gt;
      
    
    </summary>
    
      <category term="storm" scheme="http://www.liuyong520.cn/categories/storm/"/>
    
    
      <category term="storm" scheme="http://www.liuyong520.cn/tags/storm/"/>
    
  </entry>
  
  <entry>
    <title>kafka基本介绍</title>
    <link href="http://www.liuyong520.cn/2019/04/29/kafka-intruduce/"/>
    <id>http://www.liuyong520.cn/2019/04/29/kafka-intruduce/</id>
    <published>2019-04-29T02:56:51.000Z</published>
    <updated>2019-06-11T09:37:16.614Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><h1 id="kafka是什么？"><a href="#kafka是什么？" class="headerlink" title="kafka是什么？"></a>kafka是什么？</h1><p>Kafka是一个分布式流式存储并处理的消息队列。由scale+java语言编写，它提供了类似于JMS的特性，但是在设计实现上又完全不同，因为kafka并不是按照JMS规范实现的。kafka集群由多个broke（Kafka实例称之为broke）组成，在集群里，kafka通过消息订阅和发布将消息以topic的形式发布出来，同时，消息也是存储在topic中的，消息的发送者成为producer，消息接受者成为Consummer。<br>同时，topic 是根据分区partitions，和副本replications来实现的数据的分布式存储，和加强数据的可靠性。</p><p><img src="http://kafka.apache.org/22/images/kafka-apis.png" alt="官方图片"></p><h1 id="何为topic？"><a href="#何为topic？" class="headerlink" title="何为topic？"></a>何为topic？</h1><p>一个topic可以认为是一类消息，每个topic将被分成多个partitions，每个partition在存储append log的形式存在文件里的。任何发布到partition的消息都会直接被追加到log文件的末尾，每条消息在文件中的位置称之为offset偏移量，offset为一个long型数字，它唯一标识一条消息，kafka并没有提供其他索引来存储offset，因此kafka不支持消息的随机读写。<br><img src="http://kafka.apache.org/22/images/log_anatomy.png" alt="分区结构图"></p><p>kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后(默认是7天)删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支.</p><h1 id="kafka消息如何消费的？"><a href="#kafka消息如何消费的？" class="headerlink" title="kafka消息如何消费的？"></a>kafka消息如何消费的？</h1><p>对于consumer而言,它需要保存消费消息的offset,对于offset的保存和使用,有consumer来控制;当consumer正常消费消息时,offset将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将offset重置为任意值..(kafka 老版本中offset将会保存在zookeeper中,1.x之后也会存储在broke集群里,参见下文)</p><h1 id="kafka-集群里consumer和producer的状态信息是如何保存的？"><a href="#kafka-集群里consumer和producer的状态信息是如何保存的？" class="headerlink" title="kafka 集群里consumer和producer的状态信息是如何保存的？"></a>kafka 集群里consumer和producer的状态信息是如何保存的？</h1><p>kafka集群几乎不需要维护任何consumer和producer状态信息,这些信息由zookeeper保存;因此producer和consumer的客户端实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响.</p><h1 id="kafka为何要引入分区的概念，有何好处？"><a href="#kafka为何要引入分区的概念，有何好处？" class="headerlink" title="kafka为何要引入分区的概念，有何好处？"></a>kafka为何要引入分区的概念，有何好处？</h1><p>partitions的设计目的有多个.最根本原因是kafka基于文件存储.通过分区,可以将日志内容分散到多个kafka实例上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存;可以将一个topic切分多任意多个partitions,来消息保存/消费的效率.此外越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.有负载均衡的功效(具体原理参见下文).</p><h1 id="kakfa数据是如何写入到磁盘的？"><a href="#kakfa数据是如何写入到磁盘的？" class="headerlink" title="kakfa数据是如何写入到磁盘的？"></a>kakfa数据是如何写入到磁盘的？</h1><p>一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性.</p><p>基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定.这和zookeeper的follower是有区别的：zookeeper的follower是可以读到数据的，而kafka的follower是读不到数据的。</p><p>kafka使用文件存储消息,这就直接决定kafka在性能上严重依赖文件系统的本身特性.且无论任何OS下,对文件系统本身的优化几乎没有可能.文件缓存/直接内存映射等是常用的手段.因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.</p><h1 id="kafka中消费者组如何理解？"><a href="#kafka中消费者组如何理解？" class="headerlink" title="kafka中消费者组如何理解？"></a>kafka中消费者组如何理解？</h1><p>Producer将消息发布到指定的Topic中,同时Producer也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等.</p><p>本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费.</p><p>如果所有的consumer都具有相同的group,这种情况和queue模式很像;消息将会在consumers之间负载均衡.<br>如果所有的consumer都具有不同的group,那这就是”发布-订阅”;消息将会广播给所有的消费者.</p><p>在kafka中,一个partition中的消息只会被group中的一个consumer消费;每个group中consumer消息消费互相独立;我们可以认为一个group是一个”订阅”者,一个Topic中的每个partions,只会被一个”订阅者”中的一个consumer消费,不过一个consumer可以消费多个partitions中的消息.kafka只能保证一个partition中的消息被某个consumer消费时,消息是顺序的.事实上,从Topic角度来说,消息仍不是有序的. 因为消费者消费消息的时候是按照分区依次读取的，所以无法保证消息的全局顺序性，只能保证在同一个分区内的消息是顺序的。如果想要所有的消息都是顺序的，可以把分区数设置为1.</p><h1 id="kafka中如何保证数据一段时间内不丢失？"><a href="#kafka中如何保证数据一段时间内不丢失？" class="headerlink" title="kafka中如何保证数据一段时间内不丢失？"></a>kafka中如何保证数据一段时间内不丢失？</h1><p>kafka 的producer有ACK机制。可以由用户自行设定是否开启确认机制，如果开启确认机制，kafka会等发送消息到kafka集群时，当leader服务器，会返回元数据给producer客户端，ACK机制也在元数据里，这里的ACK有两种，一种就是leader只要接收成功，就返回确认，另外一种就是：要等所有follower都收到了之后才返回确认。producer在接收到确认之后，才会发下一条消息。而所有的消息最终都是存储在磁盘一段时间的，所以一段时间内消息是不会丢失的。</p><h1 id="kafka-的应用场景主要有哪些？"><a href="#kafka-的应用场景主要有哪些？" class="headerlink" title="kafka 的应用场景主要有哪些？"></a>kafka 的应用场景主要有哪些？</h1><p>官方介绍是讲可以用作message queue，数据采集，简单流式计算等。</p><h1 id="用作消息队列message-queue有哪些优缺点？"><a href="#用作消息队列message-queue有哪些优缺点？" class="headerlink" title="用作消息队列message queue有哪些优缺点？"></a>用作消息队列message queue有哪些优缺点？</h1><p>对于一些常规的消息系统,kafka是个不错的选择;partitons/replication和容错,可以使kafka具有良好的扩展性和性能优势.不过到目前为止,我们应该很清楚认识到,kafka并没有提供JMS中的”事务性””消息传输担保(消息确认机制)””消息分组”等企业级特性;kafka只能使用作为”常规”的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等)</p><h1 id="kafka是如何保持高性能的？"><a href="#kafka是如何保持高性能的？" class="headerlink" title="kafka是如何保持高性能的？"></a>kafka是如何保持高性能的？</h1><p>需要考虑的影响性能点很多,除磁盘IO之外,我们还需要考虑网络IO,这直接关系到kafka的吞吐量问题.kafka并没有提供太多高超的技巧;对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker;对于consumer端也是一样,批量fetch多条消息.不过消息量的大小可以通过配置文件来指定.对于kafka broker端,似乎有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,socket直接读取相应的内存区域即可,而无需进程再次copy和交换. 其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka支持gzip/snappy等多种压缩方式.</p><h1 id="kafka在消费者端有哪些异常处理策略？"><a href="#kafka在消费者端有哪些异常处理策略？" class="headerlink" title="kafka在消费者端有哪些异常处理策略？"></a>kafka在消费者端有哪些异常处理策略？</h1><p>对于JMS实现,消息传输担保非常直接:有且只有一次(exactly once).在kafka中稍有不同:<br>1) at most once: 最多一次,这个和JMS中”非持久化”消息类似.发送一次,无论成败,将不会重发.<br>2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.<br>3) exactly once: 消息只会发送一次.<br>at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后”未处理”的消息将不能被fetch到,这就是”at most once”.<br>at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态.</p><p>exactly once: kafka中并没有严格的去实现基于2阶段提交,事务),我们认为这种策略在kafka中是没有必要的.<br>通常情况下”at-least-once”是我们搜选.(相比at most once而言,重复接收数据总比丢失数据要好).</p><h1 id="kafka-工作流程是怎样的？"><a href="#kafka-工作流程是怎样的？" class="headerlink" title="kafka 工作流程是怎样的？"></a>kafka 工作流程是怎样的？</h1><ol><li>主要结构图：大体可以从三个方面分析：生产者产生消息、消费者消费消息、Broker cluster保存消息。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/attachments_1556770670858.drawio.png" alt="结构图"></li><li><p>生产者产生消息过程分析</p><ul><li>写入方式：<br>producer 采用push的方式将消息发送到broker cluster，每条消息都被追加到分区中，属于顺序写磁盘（顺序写磁盘效率比随机写内存效率要高，能提高Kafka吞吐率）<br>而且broker集群并不是每一条消息都及时写磁盘，而是先写buffer，达到一定大小或者每隔一段时间再flush到磁盘上。<br>多个producer可以给同一个topic 发布消息，而且可以指定分区发布。</li><li>分区Partition<br>每个Topic可以有多个分区，而消息最终是存储在磁盘的文件里的，Partition在磁盘上是文件夹的形式存在的。如<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cd /var/applog/kafka/ ## 赚到kafka数据目录 即log.dir=配置的目录</span><br><span class="line">ls</span><br><span class="line">cleaner-offset-checkpoint  __consumer_offsets-22  __consumer_offsets-4   log-start-offset-checkpoint  recovery-point-offset-checkpoint</span><br><span class="line">__consumer_offsets-1       __consumer_offsets-25  __consumer_offsets-40  meta.properties              replication-offset-checkpoint</span><br><span class="line">__consumer_offsets-10      __consumer_offsets-28  __consumer_offsets-43  mytest-0                     test-0</span><br><span class="line">__consumer_offsets-13      __consumer_offsets-31  __consumer_offsets-46  mytest-1</span><br><span class="line">__consumer_offsets-16      __consumer_offsets-34  __consumer_offsets-49  mytest-2</span><br><span class="line">__consumer_offsets-19      __consumer_offsets-37  __consumer_offsets-7   mytest-3</span><br></pre></td></tr></table></figure></li></ul><p>其中mytest-0 mytest-1 mytest-2 mytest-3 即为分区Partition，里面的文件就是分区里面存放的数据。</p></li><li><p>broker cluster 保存消息<br>broker 收到消息后，首先会去找topic对应分区的leader，找到leader后，先将数据写入buffer，再flush到磁盘。然后zookeeper会协调follower自动同步leader分区的数据，以达到replication备份的目的，同时leader会按照备份完成的先后顺序给follower作一次排序，作为leader发生意外时选举时选举为leader的顺序。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1556780993351.png" alt="enter description here"></p></li><li>消费者消费消息<ol><li>消费者消费消息，同一个分区里的数据不能够被一个消费组里面的多个消费者同时消费，同一个消费组里的消费者只能消费不同分区的数据。</li><li>不同消费者组可以消费同一个分区里的数据。</li><li>消费者消费数据时是按照分区的一个一个分区数据进行消费的。<h1 id="zookeeper在kafka中的具体作用是什么？"><a href="#zookeeper在kafka中的具体作用是什么？" class="headerlink" title="zookeeper在kafka中的具体作用是什么？"></a>zookeeper在kafka中的具体作用是什么？</h1>kafka是依赖于zookeeper注册中心的，主要来协调各个broker的分区备份，broker的选举，以及消费者相关状信息的存储。<br>kafka使用zookeeper来存储一些meta信息,并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)<br>1) Broker node registry: 当一个kafkabroker启动后,首先会向zookeeper注册自己的节点信息(临时znode),同时当broker和zookeeper断开连接时,此znode也会被删除.<br>格式: /broker/ids/[0…N] –&gt;host:port;其中[0..N]表示broker id,每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),znode的值为此broker的host:port信息.<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ zkCli -server k8s-n1:2181</span><br><span class="line">$ ls /brokers</span><br><span class="line">[ids, topics, seqid]</span><br><span class="line">$ ls /brokers/ids</span><br><span class="line">[0, 1, 2]</span><br><span class="line">$ get /brokers/ids/0</span><br><span class="line">&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://k8s-n1:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;k8s-n1&quot;,&quot;timestamp&quot;:&quot;1556568752340&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;</span><br><span class="line">cZxid = 0xd0000003c</span><br><span class="line">ctime = Wed Apr 24 16:10:19 CST 2019</span><br><span class="line">mZxid = 0xd0000003c</span><br><span class="line">mtime = Wed Apr 24 16:10:19 CST 2019</span><br><span class="line">pZxid = 0xd0000003c</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 1</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x26a4e173fc40002</span><br><span class="line">dataLength = 182</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure></li></ol></li></ol><p>2) Broker Topic Registry: 当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息,仍然是一个临时znode.<br>格式: /broker/topics/[topic]/[0…N] 其中[0..N]表示partition索引号.<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls /brokers/topics</span><br><span class="line">[test, __consumer_offsets]</span><br></pre></td></tr></table></figure><p></p><p>__consumer_offsets 是消费端的offset<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ ls /brokers/topics/test</span><br><span class="line">[partitions] ##test的分区信息</span><br><span class="line">$ ls /brokers/topics/test/partitions</span><br><span class="line">[0]</span><br><span class="line">$ ls /brokers/topics/test/partitions/0</span><br><span class="line">[state]</span><br><span class="line">$ get /brokers/topics/test/partitions/0/state   </span><br><span class="line">&#123;&quot;controller_epoch&quot;:19,&quot;leader&quot;:0,&quot;version&quot;:1,&quot;leader_epoch&quot;:3,&quot;isr&quot;:[0]&#125;</span><br><span class="line">cZxid = 0x2000000b6</span><br><span class="line">ctime = Wed Apr 24 07:53:42 CST 2019</span><br><span class="line">mZxid = 0xd00000044</span><br><span class="line">mtime = Wed Apr 24 16:10:19 CST 2019</span><br><span class="line">pZxid = 0x2000000b6</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 3</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 73</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure><p></p><p>3) Consumer and Consumer group: 每个consumer客户端被创建时,会向zookeeper注册自己的信息;此作用主要是为了”负载均衡”.<br>一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,让partition相对均衡的分散到每个consumer上.</p><p>4) Consumer id Registry: 每个consumer都有一个唯一的ID(host:uuid,可以通过配置文件指定,也可以由系统生成),此id用来标记消费者信息.<br>格式:/consumers/[group_id]/ids/[consumer_id]<br>仍然是一个临时的znode,此节点的值为{“topic_name”:#streams…},即表示此consumer目前所消费的topic + partitions列表.<br>启动消费者：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  kafka-console-consumer.sh --bootstrap-server k8s-n2:9092 --topic test</span><br></pre></td></tr></table></figure><p></p><p>启动生成者：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list k8s-n1:9092 --topic test</span><br></pre></td></tr></table></figure><p></p><p>查看zookeeper信息：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ls /</span><br><span class="line">[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]</span><br><span class="line">$ ls /consumers</span><br><span class="line">[]</span><br></pre></td></tr></table></figure><p></p><p>发现consummer下啥也没有？这是因为新版本的kafka，consumer中offset不是放在这个位置的，而是放在__consumer_offset 这个topic下的。那么该如何验证呢？<br>启动消费者：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$  kafka-console-consumer.sh --bootstrap-server k8s-n2:9092 --topic test</span><br></pre></td></tr></table></figure><p></p><p>启动生成者：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list k8s-n1:9092 --topic test</span><br></pre></td></tr></table></figure><p></p><p>验证消息生产成功<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list k8s-n1:9092 --topic mytest --time -1</span><br><span class="line">mytest:0:15</span><br><span class="line">mytest:1:16</span><br><span class="line">mytest:2:16</span><br><span class="line">mytest:3:15</span><br></pre></td></tr></table></figure><p></p><p>mytest topic 上 0号分区有15条消息。很好理解。<br>再创建一个消费者组<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server k8s-n1:9092 --topic mytest --from-beginning</span><br></pre></td></tr></table></figure><p></p><p>查询一下消费者组信息<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-consumer-groups.sh --bootstrap-server k8s-n1:9092 --list</span><br><span class="line">console-consumer-24766</span><br><span class="line">console-consumer-52794</span><br></pre></td></tr></table></figure><p></p><p>查询一下topic里的内容：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server k8s-n1:9092 --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config/consumer.properties --from-beginning</span><br></pre></td></tr></table></figure><p></p><p>结果：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> [console-consumer-52794,__consumer_offsets,12]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,45]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,1]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,5]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,26]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,29]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,34]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,10]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,32]::OffsetAndMetadata(offset=5, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">[console-consumer-52794,__consumer_offsets,40]::OffsetAndMetadata(offset=3, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)</span><br><span class="line">^CProcessed a total of 1674 messages</span><br></pre></td></tr></table></figure><p></p><p>参考了 <a href="http://www.cnblogs.com/huxi2b/p/6061110.html这篇blog的作法，但是我的版本是kafka_2.2.0里面并没有找offset的命令。" target="_blank" rel="noopener">http://www.cnblogs.com/huxi2b/p/6061110.html这篇blog的作法，但是我的版本是kafka_2.2.0里面并没有找offset的命令。</a></p><p>5) Consumer offset Tracking: 用来跟踪每个consumer目前所消费的partition中最大的offset.<br>格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value<br>此znode为持久节点,可以看出offset跟group_id有关,以表明当group中一个消费者失效,其他consumer可以继续消费.<br>6) Partition Owner registry: 用来标记partition被哪个consumer消费.临时znode<br>格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id当consumer启动时,所触发的操作:<br>A) 首先进行”Consumer id Registry”;<br>B) 然后在”Consumer id Registry”节点下注册一个watch用来监听当前group中其他consumer的”leave”和”join”;只要此znode path下节点列表变更,都会触发此group下consumer的负载均衡.(比如一个consumer失效,那么其他consumer接管partitions).<br>C) 在”Broker id registry”节点下,注册一个watch用来监听broker的存活情况;如果broker列表变更,将会触发所有的groups下的consumer重新balance.</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;kafka是什么？&quot;&gt;&lt;a href=&quot;#kafka是什么？&quot; class=&quot;headerlink&quot; title=&quot;kafka是什么？
      
    
    </summary>
    
      <category term="消息队列" scheme="http://www.liuyong520.cn/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="kafka" scheme="http://www.liuyong520.cn/tags/kafka/"/>
    
      <category term="linux" scheme="http://www.liuyong520.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux下kafka集群搭建</title>
    <link href="http://www.liuyong520.cn/2019/04/29/kafka-install/"/>
    <id>http://www.liuyong520.cn/2019/04/29/kafka-install/</id>
    <published>2019-04-29T02:56:51.000Z</published>
    <updated>2019-06-11T09:37:16.613Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ol><li><p>zookeeper集群环境<br>kafka是依赖于zookeeper注册中心的一款分布式消息对列，所以需要有zookeeper单机或者集群环境。</p></li><li><p>三台服务器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.16.18.198 k8s-n1</span><br><span class="line">172.16.18.199 k8s-n2</span><br><span class="line">172.16.18.200 k8s-n3</span><br></pre></td></tr></table></figure></li><li><p>下载kafka安装包</p></li></ol><p><a href="http://kafka.apache.org/downloads" target="_blank" rel="noopener">http://kafka.apache.org/downloads</a> 中下载，目前最新版本的kafka已经到2.2.0,我这里之前下载的是kafka_2.11-2.2.0.tgz.</p><h2 id="安装kafka集群"><a href="#安装kafka集群" class="headerlink" title="安装kafka集群"></a>安装kafka集群</h2><ol><li><p>上传压缩包到三台服务器解压缩到/opt/目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf kafka_2.11-2.2.0.tgz -C /opt/</span><br><span class="line">ls -s kafka_2.11-2.2.0 kafka</span><br></pre></td></tr></table></figure></li><li><p>修改 server.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">############################# Server Basics #############################</span><br><span class="line"></span><br><span class="line"># The id of the broker. This must be set to a unique integer for each broker.</span><br><span class="line">broker.id=0</span><br><span class="line"></span><br><span class="line">############################# Socket Server Settings #############################</span><br><span class="line"></span><br><span class="line"># The address the socket server listens on. It will get the value returned from </span><br><span class="line"># java.net.InetAddress.getCanonicalHostName() if not configured.</span><br><span class="line">#   FORMAT:</span><br><span class="line">#     listeners = listener_name://host_name:port</span><br><span class="line">#   EXAMPLE:</span><br><span class="line">#     listeners = PLAINTEXT://your.host.name:9092</span><br><span class="line">listeners=PLAINTEXT://k8s-n1:9092</span><br><span class="line"></span><br><span class="line"># Hostname and port the broker will advertise to producers and consumers. If not set, </span><br><span class="line"># it uses the value for &quot;listeners&quot; if configured.  Otherwise, it will use the value</span><br><span class="line"># returned from java.net.InetAddress.getCanonicalHostName().</span><br><span class="line">advertised.listeners=PLAINTEXT://k8s-n1:9092</span><br><span class="line"></span><br><span class="line"># Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details</span><br><span class="line">#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL</span><br><span class="line"></span><br><span class="line"># The number of threads that the server uses for receiving requests from the network and sending responses to the network</span><br><span class="line">num.network.threads=3</span><br><span class="line"></span><br><span class="line"># The number of threads that the server uses for processing requests, which may include disk I/O</span><br><span class="line">num.io.threads=8</span><br><span class="line"></span><br><span class="line"># The send buffer (SO_SNDBUF) used by the socket server</span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"></span><br><span class="line"># The receive buffer (SO_RCVBUF) used by the socket server</span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"></span><br><span class="line"># The maximum size of a request that the socket server will accept (protection against OOM)</span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">############################# Log Basics #############################</span><br><span class="line"></span><br><span class="line"># A comma separated list of directories under which to store log files</span><br><span class="line">log.dirs=/var/applog/kafka/</span><br><span class="line"></span><br><span class="line"># The default number of log partitions per topic. More partitions allow greater</span><br><span class="line"># parallelism for consumption, but this will also result in more files across</span><br><span class="line"># the brokers.</span><br><span class="line">num.partitions=5</span><br><span class="line"></span><br><span class="line"># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</span><br><span class="line"># This value is recommended to be increased for installations with data dirs located in RAID array.</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"></span><br><span class="line">############################# Internal Topic Settings  #############################</span><br><span class="line"># The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;</span><br><span class="line"># For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.</span><br><span class="line">offsets.topic.replication.factor=1</span><br><span class="line">transaction.state.log.replication.factor=1</span><br><span class="line">transaction.state.log.min.isr=1</span><br><span class="line"></span><br><span class="line">############################# Log Flush Policy #############################</span><br><span class="line"></span><br><span class="line"># Messages are immediately written to the filesystem but by default we only fsync() to sync</span><br><span class="line"># the OS cache lazily. The following configurations control the flush of data to disk.</span><br><span class="line"># There are a few important trade-offs here:</span><br><span class="line">#    1. Durability: Unflushed data may be lost if you are not using replication.</span><br><span class="line">#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.</span><br><span class="line">#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.</span><br><span class="line"># The settings below allow one to configure the flush policy to flush data after a period of time or</span><br><span class="line"># every N messages (or both). This can be done globally and overridden on a per-topic basis.</span><br><span class="line"></span><br><span class="line"># The number of messages to accept before forcing a flush of data to disk</span><br><span class="line">log.flush.interval.messages=10000</span><br><span class="line"></span><br><span class="line"># The maximum amount of time a message can sit in a log before we force a flush</span><br><span class="line">log.flush.interval.ms=1000</span><br><span class="line"></span><br><span class="line">############################# Log Retention Policy #############################</span><br><span class="line"></span><br><span class="line"># The following configurations control the disposal of log segments. The policy can</span><br><span class="line"># be set to delete segments after a period of time, or after a given size has accumulated.</span><br><span class="line"># A segment will be deleted whenever *either* of these criteria are met. Deletion always happens</span><br><span class="line"># from the end of the log.</span><br><span class="line"></span><br><span class="line"># The minimum age of a log file to be eligible for deletion due to age</span><br><span class="line">log.retention.hours=24</span><br><span class="line"></span><br><span class="line"># A size-based retention policy for logs. Segments are pruned from the log unless the remaining</span><br><span class="line"># segments drop below log.retention.bytes. Functions independently of log.retention.hours.</span><br><span class="line">#log.retention.bytes=1073741824</span><br><span class="line"></span><br><span class="line"># The maximum size of a log segment file. When this size is reached a new log segment will be created.</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line"></span><br><span class="line"># The interval at which log segments are checked to see if they can be deleted according</span><br><span class="line"># to the retention policies</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"></span><br><span class="line">############################# Zookeeper #############################</span><br><span class="line"></span><br><span class="line"># Zookeeper connection string (see zookeeper docs for details).</span><br><span class="line"># This is a comma separated host:port pairs, each corresponding to a zk</span><br><span class="line"># server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.</span><br><span class="line"># You can also append an optional chroot string to the urls to specify the</span><br><span class="line"># root directory for all kafka znodes.</span><br><span class="line">zookeeper.connect=k8s-n1:2181,k8s-n2:2181,k8s-n3:2181</span><br><span class="line"></span><br><span class="line"># Timeout in ms for connecting to zookeeper</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">############################# Group Coordinator Settings #############################</span><br><span class="line"></span><br><span class="line"># The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.</span><br><span class="line"># The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.</span><br><span class="line"># The default value for this is 3 seconds.</span><br><span class="line"># We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.</span><br><span class="line"># However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.</span><br><span class="line">group.initial.rebalance.delay.ms=0</span><br><span class="line"></span><br><span class="line">delete.topic.enable=true</span><br></pre></td></tr></table></figure></li></ol><p>拷贝两份到k8s-n2,k8s-n3<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-n2 config]# cat server.properties </span><br><span class="line">broker.id=1</span><br><span class="line">listeners=PLAINTEXT://k8s-n2:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://k8s-n2:9092</span><br><span class="line"></span><br><span class="line">[root@k8s-n3 config]# cat server.properties</span><br><span class="line">broker.id=2</span><br><span class="line">listeners=PLAINTEXT://k8s-n3:9092</span><br><span class="line">advertised.listeners=PLAINTEXT://k8s-n3:9092</span><br></pre></td></tr></table></figure><p></p><ol start="3"><li>添加环境变量 在/etc/profile 中添加</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/kafka_2.11-2.2.0</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure><p>source /etc/profile 重载生效</p><ol start="4"><li>启动kafka<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-server-start.sh config/server.properties &amp;</span><br></pre></td></tr></table></figure></li></ol><h3 id="Zookeeper-Kafka集群测试"><a href="#Zookeeper-Kafka集群测试" class="headerlink" title="Zookeeper+Kafka集群测试"></a>Zookeeper+Kafka集群测试</h3><ol><li><p>创建topic:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create --zookeeper k8s-n1:2181, k8s-n2:2181, k8s-n3:2181 --replication-factor 3 --partitions 3 --topic test</span><br></pre></td></tr></table></figure></li><li><p>显示topic</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --describe --zookeeper k8s-n1:2181, k8s-n2:2181, k8s-n3:2181 --topic test</span><br></pre></td></tr></table></figure></li><li><p>列出topic</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --list --zookeeper k8s-n1:2181, k8s-n2:2181, k8s-n3:2181</span><br><span class="line">test</span><br></pre></td></tr></table></figure></li></ol><p>创建 producer(生产者);<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-producer.sh --broker-list k8s-n1:9092 --topic test</span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p></p><p>创建 consumer（消费者）<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kafka-console-consumer.sh --bootstrap-server k8s-n1:9092 --topic test --from-beginning</span><br><span class="line">hello</span><br></pre></td></tr></table></figure><p></p><p>至此，kafka集群搭建就已经完成了。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;环境准备&quot;&gt;&lt;a href=&quot;#环境准备&quot; class=&quot;headerlink&quot; title=&quot;环境准备&quot;&gt;&lt;/a&gt;环境准备&lt;/h2&gt;
      
    
    </summary>
    
      <category term="消息队列" scheme="http://www.liuyong520.cn/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/"/>
    
    
      <category term="kafka" scheme="http://www.liuyong520.cn/tags/kafka/"/>
    
      <category term="linux" scheme="http://www.liuyong520.cn/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux下zookeeper集群搭建</title>
    <link href="http://www.liuyong520.cn/2019/04/29/zookeeper-install/"/>
    <id>http://www.liuyong520.cn/2019/04/29/zookeeper-install/</id>
    <published>2019-04-29T02:56:51.000Z</published>
    <updated>2019-06-11T09:37:16.607Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:48 GMT+0800 (GMT+08:00) --><h2 id="部署前准备"><a href="#部署前准备" class="headerlink" title="部署前准备"></a>部署前准备</h2><ol><li><p>下载zookeeper的安装包<br><a href="http://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">http://zookeeper.apache.org/releases.html</a> 我下载的版本是zookeeper-3.4.10。</p></li><li><p>准备三台服务器<br>ip地址为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">172.16.18.198</span><br><span class="line">172.16.18.199</span><br><span class="line">172.16.18.200</span><br></pre></td></tr></table></figure></li><li><p>检查jdk版本，安装jdk环境，jdk需要1.7以上。</p></li></ol><h2 id="安装zookeeper"><a href="#安装zookeeper" class="headerlink" title="安装zookeeper"></a>安装zookeeper</h2><ol><li><p>三台服务器分别上传zookeeper安装包，上传到/opt/目录下，然后tar zxvf zookeeper-3.4.10.tar.gz</p></li><li><p>拷贝zoo_sample.cfg 为zoo.cfg 修改/opt/zookeeper-3.4.10/conf/zoo.cfg配置文件，添加如下内容：</p></li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.1=172.16.18.198:2888:3888</span><br><span class="line">server.2=172.16.18.199:2888:3888</span><br><span class="line">server.3=172.16.18.200:2888:3888</span><br></pre></td></tr></table></figure><ol start="3"><li>修改zookeeper数据文件存放目录<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/data/zookeeper</span><br></pre></td></tr></table></figure></li></ol><p>此时zoo.cfg 配置文件内容为：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000 ##zookeeper单位时间为2ms</span><br><span class="line"># The number of ticks that the initial </span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10  ##对于从节点最初连接到主节点时的超时时间，单位为tick值的倍数。即20ms</span><br><span class="line"># The number of ticks that can pass between </span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5   ##对于主节点与从节点进行同步操作时的超时时间，单位为tick值的倍数。即10ms</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use /tmp for storage, /tmp here is just </span><br><span class="line"># example sakes.</span><br><span class="line">dataDir=/data/zookeeper</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181  ##客户端链接端口</span><br><span class="line"># the maximum number of client connections.</span><br><span class="line"># increase this if you need to handle more clients</span><br><span class="line">maxClientCnxns=60 ##客户端最大链接数</span><br><span class="line">#</span><br><span class="line"># Be sure to read the maintenance section of the </span><br><span class="line"># administrator guide before turning on autopurge.</span><br><span class="line">#</span><br><span class="line"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span><br><span class="line">#</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">#autopurge.snapRetainCount=3</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">#autopurge.purgeInterval=1</span><br><span class="line">server.1=172.16.18.198:2888:3888  </span><br><span class="line">server.2=172.16.18.199:2888:3888</span><br><span class="line">server.3=172.16.18.200:2888:3888</span><br></pre></td></tr></table></figure><p></p><ol start="4"><li><p>新建myid文件<br>在三台服务器的数据存放目录下新建myid文件，并写入对应的server.num 中的num数字<br>如：在172.16.18.198上将server.1中1写入myid</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt;/data/zookeeper/myid</span><br></pre></td></tr></table></figure></li><li><p>添加环境变量，方便我们执行脚本命令<br>vi etc/profile 在最后添加如下两个。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper-3.4.9</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf</span><br></pre></td></tr></table></figure></li></ol><p>保存后重新加载一下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p></p><ol start="6"><li>修改日志存放目录（可选）<br>vi /opt/zookeeper/bin/zkEnv.sh 找到ZOO_LOG_DIR 和 ZOO_LOG4J_PROP位置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ] </span><br><span class="line">then </span><br><span class="line">    #配置zookeeper日志输出存放路径 </span><br><span class="line">    ZOO_LOG_DIR=&quot;/var/applog/zookeeper&quot; </span><br><span class="line">fi </span><br><span class="line"></span><br><span class="line">if [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ] </span><br><span class="line">then </span><br><span class="line">    #配置日志输出级别,这里把几个级别一并配上 </span><br><span class="line">    ZOO_LOG4J_PROP=&quot;INFO,CONSOLE,ROLLINGFILE,TRACEFILE&quot; </span><br><span class="line">fi</span><br></pre></td></tr></table></figure></li></ol><p>编辑conf目录下log4j.properties<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Define some default values that can be overridden by system properties </span><br><span class="line">zookeeper.root.logger=INFO, CONSOLE, ROLLINGFILE, TRACEFILE </span><br><span class="line">zookeeper.console.threshold=INFO </span><br><span class="line">zookeeper.log.dir=. </span><br><span class="line">zookeeper.log.file=zookeeper.log </span><br><span class="line">zookeeper.log.threshold=ERROR </span><br><span class="line">zookeeper.tracelog.dir=. </span><br><span class="line">zookeeper.tracelog.file=zookeeper_trace.log </span><br><span class="line">log4j.rootLogger=$&#123;zookeeper.root.logger&#125;</span><br></pre></td></tr></table></figure><p></p><p>完成log的日志目录的修改。<br>7.启动zookeeper服务</p><p>zkServer.sh start来启动。</p><p>zkServer.sh restart　　(重启)</p><p>zkServer.sh status　　(查看状态)</p><p>zkServer.sh stop　　(关闭)</p><p>zkServer.sh start-foreground　　(以打印日志方式启动)<br>三台服务器分别执行：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><p></p><p>然后用 status 检查下状态 如果出现 Mode：leader 或者Mode:follower 表示搭建成功。否则前台执行看一下日志。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper-3.4.10/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure><p></p><p>如出现：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2019-04-29 14:04:05,992 [myid:3] - INFO  [ListenerThread:QuorumCnxManager$Listener@739] - My election bind port: /172.16.18.200:3888</span><br><span class="line">2019-04-29 14:04:06,019 [myid:3] - INFO  [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:QuorumPeer@865] - LOOKING</span><br><span class="line">2019-04-29 14:04:06,025 [myid:3] - INFO  [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:FastLeaderElection@818] - New election. My id =  3, proposed zxid=0x0</span><br><span class="line">2019-04-29 14:04:06,056 [myid:3] - WARN  [WorkerSender[myid=3]:QuorumCnxManager@588] - Cannot open channel to 1 at election address /172.16.18.198:3888</span><br><span class="line">java.net.NoRouteToHostException: 没有到主机的路由</span><br><span class="line">        at java.net.PlainSocketImpl.socketConnect(Native Method)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:345)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)</span><br><span class="line">        at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)</span><br><span class="line">&quot;zookeeper.log&quot; 303L, 35429C</span><br></pre></td></tr></table></figure><p></p><p>报这种异常一般有三种情况：</p><p>1）：zoo.cfg配置文件中，server.x:2888:3888配置出现错误；</p><p>2）：myid文件内容和server.x不对应，或者myid不在data目录下；</p><p>3）：系统防火墙是否在启动。</p><p>我检查了三种原因后发现是防火墙running。</p><p>centos7下查看防火墙状态的命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --state</span><br></pre></td></tr></table></figure><p></p><p>关闭防火墙的命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br><span class="line">systemctl disable firewalld.service   （禁止开机启动，永久关闭防火墙）</span><br></pre></td></tr></table></figure><p></p><p>关闭防火墙后重启即可。</p><ol start="8"><li>验证是否成功<br>在命令行中输入：zkCli.sh -server 172.16.18.198:2181（由于本人在不同的办公地点在修改该文章，所以ip地址也在变化，知道原理即可）即可连接到其中一台ZooKeeper服务器。其他自动实现同步，客户端只需要和一台保持连接即可。出现如下表示链接成功<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:None path:null</span><br><span class="line">[zk: 172.16.18.198:2181(CONNECTED) 0]</span><br></pre></td></tr></table></figure></li></ol><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:48 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;部署前准备&quot;&gt;&lt;a href=&quot;#部署前准备&quot; class=&quot;headerlink&quot; title=&quot;部署前准备&quot;&gt;&lt;/a&gt;部署前准备&lt;
      
    
    </summary>
    
      <category term="分布式集群" scheme="http://www.liuyong520.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/"/>
    
    
      <category term="linux" scheme="http://www.liuyong520.cn/tags/linux/"/>
    
      <category term="ZooKeeper" scheme="http://www.liuyong520.cn/tags/ZooKeeper/"/>
    
  </entry>
  
  <entry>
    <title>mysql 快速安装</title>
    <link href="http://www.liuyong520.cn/2018/06/09/mysql-install/"/>
    <id>http://www.liuyong520.cn/2018/06/09/mysql-install/</id>
    <published>2018-06-09T01:12:23.000Z</published>
    <updated>2019-06-11T09:37:15.280Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><p>废话少说直接贴脚本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/usr/bin/bash</span><br><span class="line"><span class="meta">#</span>#install_mysql.sh mysql-8.0.15-linux-glibc2.12-x86_64.tar.xz</span><br><span class="line">yum install -y libaio</span><br><span class="line"></span><br><span class="line">mysqltar=$1</span><br><span class="line">extension="$&#123;mysqltar#*x86_64&#125;"</span><br><span class="line">filename=`basename $1 $&#123;extension&#125;`</span><br><span class="line">tar -xvf $&#123;mysqltar&#125; &amp;&amp; mv -f $&#123;filename&#125; /usr/local/mysql</span><br><span class="line"><span class="meta">#</span>#添加权限</span><br><span class="line">groupadd mysql</span><br><span class="line"><span class="meta">#</span>#添加用户mysql</span><br><span class="line">useradd -r -g mysql mysql</span><br><span class="line">mkdir -p /etc/my.cnf.d/</span><br><span class="line">mkdir -p /data/log/mysql-log/</span><br><span class="line">mkdir -p /usr/local/mysql/data</span><br><span class="line">cd /data/log/mysql-log/ &amp;&amp; touch error.log</span><br><span class="line">chown -R mysql:mysql /data/log/mysql-log/</span><br><span class="line">MYSQL_HOME=`cd -P /usr/local/mysql; pwd`</span><br><span class="line"></span><br><span class="line">echo "修改权限目录：$&#123;MYSQL_HOME&#125;"</span><br><span class="line">export MYSQL_HOME=$&#123;MYSQL_HOME&#125;</span><br><span class="line">export PATH=$PATH:$MYSQL_HOME/bin</span><br><span class="line"><span class="meta">#</span>#修改目录权限</span><br><span class="line">chown -R mysql:mysql $&#123;MYSQL_HOME&#125;</span><br><span class="line">mysqlpath=`cd $&#123;MYSQL_HOME&#125; &amp;&amp; pwd`</span><br><span class="line"></span><br><span class="line">cat &gt; /etc/my.cnf &lt;&lt;EOF</span><br><span class="line">[client]</span><br><span class="line">port=3306 # 设置mysql客户端连接服务端时默认使用的端口</span><br><span class="line"></span><br><span class="line">default-character-set=utf8</span><br><span class="line">socket=/usr/local/mysql/data/mysql.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line"><span class="meta">#</span> 设置mysql的安装目录</span><br><span class="line">basedir=/usr/local/mysql</span><br><span class="line"><span class="meta">#</span>datadir=/usr/local/mysql/data</span><br><span class="line"></span><br><span class="line">socket=/usr/local/mysql/data/mysql.sock</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> 设置3306端口</span><br><span class="line">port=3306</span><br><span class="line"><span class="meta">#</span> 允许最大连接数</span><br><span class="line">max_connections=10000</span><br><span class="line"><span class="meta">#</span> 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统</span><br><span class="line">max_connect_errors=10</span><br><span class="line"><span class="meta">#</span> 服务端使用的字符集默认为UTF8</span><br><span class="line">character-set-server=UTF8MB4</span><br><span class="line"><span class="meta">#</span> 创建新表时将使用的默认存储引擎</span><br><span class="line">default-storage-engine=INNODB</span><br><span class="line"><span class="meta">#</span> 默认使用“mysql_native_password”插件认证</span><br><span class="line">default_authentication_plugin=mysql_native_password</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> Settings user and group are ignored when systemd is used.</span><br><span class="line"><span class="meta">#</span> If you need to run mysqld under a different user or group,</span><br><span class="line"><span class="meta">#</span> customize your systemd unit file for mariadb according to the</span><br><span class="line"><span class="meta">#</span> instructions in http://fedoraproject.org/wiki/Systemd</span><br><span class="line"></span><br><span class="line">[mysqld_safe]</span><br><span class="line">log-error=/data/log/mysql-log/error.log</span><br><span class="line">pid-file=/usr/local/mysql/data/mysql.pid</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> include all files from the config directory</span><br><span class="line"><span class="meta">#</span></span><br><span class="line">!includedir /etc/my.cnf.d</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span>#初始化mysql</span><br><span class="line">echo "初始化mysql$&#123;mysqlpath&#125;"</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span>&#123;MYSQL_HOME&#125;/bin/mysqld --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data</span><br><span class="line">echo "添加启动服务"</span><br><span class="line"></span><br><span class="line">cp $&#123;MYSQL_HOME&#125;/support-files/mysql.server /etc/init.d/mysql</span><br><span class="line"></span><br><span class="line">echo "启动服务"</span><br><span class="line">service mysql start &amp;&amp; service mysql status</span><br><span class="line">chkconfig --add mysql</span><br><span class="line">echo "设置root用户密码"</span><br><span class="line"><span class="meta">$</span>&#123;MYSQL_HOME&#125;/bin/mysqladmin -u root password '123456'</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span>&#123;MYSQL_HOME&#125;/bin/mysql -uroot -p123456 -e "use mysql;update user set host = '%' where user = 'root';FLUSH PRIVILEGES;"</span><br></pre></td></tr></table></figure><p>安装包地址：链接: <a href="https://pan.baidu.com/s/1nUZNjWrvJSqGXT55CUcj7w" target="_blank" rel="noopener">https://pan.baidu.com/s/1nUZNjWrvJSqGXT55CUcj7w</a> 提取码: nc3i 复制这段内容后打开百度网盘手机App，操作更方便哦</p><h1 id="mysql多实例运行"><a href="#mysql多实例运行" class="headerlink" title="mysql多实例运行"></a>mysql多实例运行</h1><p>利用mysqld_muti来运行</p><h2 id="mysqld-multi多实例启动工具"><a href="#mysqld-multi多实例启动工具" class="headerlink" title="mysqld_multi多实例启动工具"></a>mysqld_multi多实例启动工具</h2><p>我们往往喜欢在一台服务器上安装多个实例，一般使用不同的端口，如3306，3307等，那么怎么才能启动这些实例呢？怎么才能一起启动呢？又怎么才能一个一个启动呢？MySQL很人性化的提供了一款自带的工具：mysqld_multi，可以毫无压力地满足我们对多实例启动的方式。</p><h2 id="mysqld-multi准备知识"><a href="#mysqld-multi准备知识" class="headerlink" title="mysqld_multi准备知识"></a>mysqld_multi准备知识</h2><ul><li>mysqld_multi启动会查找my.cnf文件中的[mysqldN]组，N为mysqld_multi后携带的整数值。</li><li>mysqld_multi的固定选项可在配置文件my.cnf中进行配置，在[mysqld_multi]组下配置（如果没有该组，可自行建立）。</li><li>mysqld_multi使用方式如下：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld_multi [options] &#123;start|stop|reload|report&#125; [GNR[,GNR] ...]</span><br></pre></td></tr></table></figure><h2 id="mysqld-multi选项"><a href="#mysqld-multi选项" class="headerlink" title="mysqld_multi选项"></a>mysqld_multi选项</h2><p>start 开启MySQL实例<br>stop 关闭MySQL实例<br>reload 重新加载MySQL实例<br>report 返回MySQL当前状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> report返回当前MySQL状态</span><br><span class="line">[root@mysql log]# mysqld_multi report 3307</span><br><span class="line">Reporting MySQL servers</span><br><span class="line">MySQL server from group: mysqld3307 is not running</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> start开启MySQL实例</span><br><span class="line">[root@mysql log]# mysqld_multi start 3307</span><br><span class="line">[root@mysql log]# mysqld_multi report 3307</span><br><span class="line">Reporting MySQL servers</span><br><span class="line">MySQL server from group: mysqld3307 is running</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> reload重新加载MySQL实例</span><br><span class="line">[root@mysql log]# mysqld_multi reload 3307</span><br><span class="line">[root@mysql log]# mysqld_multi report 3307</span><br><span class="line">Reporting MySQL servers</span><br><span class="line">MySQL server from group: mysqld3307 is running</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span> stop关闭MySQL实例，注意此处是需要一个具有shutdown权限的用户，且密码并被是加密的，也不可以交互式输入密码，Linux又具有history功能，所以为了数据库的安全，还是不要用mysqld_multi stop的方式关闭数据库了吧</span><br><span class="line">[root@mysql log]# mysqld_multi stop 3307 --user=root --password=******</span><br><span class="line">[root@mysql log]# mysqld_multi report 3307</span><br><span class="line">Reporting MySQL servers</span><br><span class="line">MySQL server from group: mysqld3307 is not running</span><br></pre></td></tr></table></figure><ul><li><p>–example 输出一个mysqld_multi配置文件中的配置示例</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"> mysqld_multi --example</span><br><span class="line"><span class="meta">#</span> This is an example of a my.cnf file for mysqld_multi.</span><br><span class="line"><span class="meta">#</span> Usually this file is located in home dir ~/.my.cnf or /etc/my.cnf</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> SOME IMPORTANT NOTES FOLLOW:</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 1.COMMON USER</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   Make sure that the MySQL user, who is stopping the mysqld services, has</span><br><span class="line"><span class="meta">#</span>   the same password to all MySQL servers being accessed by mysqld_multi.</span><br><span class="line"><span class="meta">#</span>   This user needs to have the 'Shutdown_priv' -privilege, but for security</span><br><span class="line"><span class="meta">#</span>   reasons should have no other privileges. It is advised that you create a</span><br><span class="line"><span class="meta">#</span>   common 'multi_admin' user for all MySQL servers being controlled by</span><br><span class="line"><span class="meta">#</span>   mysqld_multi. Here is an example how to do it:</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   GRANT SHUTDOWN ON *.* TO multi_admin@localhost IDENTIFIED BY 'password'</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   You will need to apply the above to all MySQL servers that are being</span><br><span class="line"><span class="meta">#</span>   controlled by mysqld_multi. 'multi_admin' will shutdown the servers</span><br><span class="line"><span class="meta">#</span>   using 'mysqladmin' -binary, when 'mysqld_multi stop' is being called.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 2.PID-FILE</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   If you are using mysqld_safe to start mysqld, make sure that every</span><br><span class="line"><span class="meta">#</span>   MySQL server has a separate pid-file. In order to use mysqld_safe</span><br><span class="line"><span class="meta">#</span>   via mysqld_multi, you need to use two options:</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   mysqld=/path/to/mysqld_safe</span><br><span class="line"><span class="meta">#</span>   ledir=/path/to/mysqld-binary/</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   ledir (library executable directory), is an option that only mysqld_safe</span><br><span class="line"><span class="meta">#</span>   accepts, so you will get an error if you try to pass it to mysqld directly.</span><br><span class="line"><span class="meta">#</span>   For this reason you might want to use the above options within [mysqld#]</span><br><span class="line"><span class="meta">#</span>   group directly.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 3.DATA DIRECTORY</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   It is NOT advised to run many MySQL servers within the same data directory.</span><br><span class="line"><span class="meta">#</span>   You can do so, but please make sure to understand and deal with the</span><br><span class="line"><span class="meta">#</span>   underlying caveats. In short they are:</span><br><span class="line"><span class="meta">#</span>   - Speed penalty</span><br><span class="line"><span class="meta">#</span>   - Risk of table/data corruption</span><br><span class="line"><span class="meta">#</span>   - Data synchronising problems between the running servers</span><br><span class="line"><span class="meta">#</span>   - Heavily media (disk) bound</span><br><span class="line"><span class="meta">#</span>   - Relies on the system (external) file locking</span><br><span class="line"><span class="meta">#</span>   - Is not applicable with all table types. (Such as InnoDB)</span><br><span class="line"><span class="meta">#</span>     Trying so will end up with undesirable results.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 4.TCP/IP Port</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   Every server requires one and it must be unique.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 5.[mysqld#] Groups</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   In the example below the first and the fifth mysqld group was</span><br><span class="line"><span class="meta">#</span>   intentionally left out. You may have 'gaps' in the config file. This</span><br><span class="line"><span class="meta">#</span>   gives you more flexibility.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 6.MySQL Server User</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   You can pass the user=... option inside [mysqld#] groups. This</span><br><span class="line"><span class="meta">#</span>   can be very handy in some cases, but then you need to run mysqld_multi</span><br><span class="line"><span class="meta">#</span>   as UNIX root.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span> 7.A Start-up Manage Script for mysqld_multi</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   In the recent MySQL distributions you can find a file called</span><br><span class="line"><span class="meta">#</span>   mysqld_multi.server.sh. It is a wrapper for mysqld_multi. This can</span><br><span class="line"><span class="meta">#</span>   be used to start and stop multiple servers during boot and shutdown.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   You can place the file in /etc/init.d/mysqld_multi.server.sh and</span><br><span class="line"><span class="meta">#</span>   make the needed symbolic links to it from various run levels</span><br><span class="line"><span class="meta">#</span>   (as per Linux/Unix standard). You may even replace the</span><br><span class="line"><span class="meta">#</span>   /etc/init.d/mysql.server script with it.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   Before using, you must create a my.cnf file either in /usr/my.cnf</span><br><span class="line"><span class="meta">#</span>   or /root/.my.cnf and add the [mysqld_multi] and [mysqld#] groups.</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="meta">#</span>   The script can be found from support-files/mysqld_multi.server.sh</span><br><span class="line"><span class="meta">#</span>   in MySQL distribution. (Verify the script before using)</span><br><span class="line"><span class="meta">#</span></span><br><span class="line"></span><br><span class="line">[mysqld_multi]</span><br><span class="line">mysqld     = /usr/bin/mysqld_safe</span><br><span class="line">mysqladmin = /usr/bin/mysqladmin</span><br><span class="line">user       = multi_admin</span><br><span class="line">password   = my_password</span><br><span class="line"></span><br><span class="line">[mysqld2]</span><br><span class="line">socket     = /tmp/mysql.sock2</span><br><span class="line">port       = 3307</span><br><span class="line">pid-file   = /var/lib/mysql2/hostname.pid2</span><br><span class="line">datadir    = /var/lib/mysql2</span><br><span class="line">language   = /usr/share/mysql/mysql/english</span><br><span class="line">user       = unix_user1</span><br><span class="line"></span><br><span class="line">[mysqld3]</span><br><span class="line">mysqld     = /path/to/mysqld_safe</span><br><span class="line">ledir      = /path/to/mysqld-binary/</span><br><span class="line">mysqladmin = /path/to/mysqladmin</span><br><span class="line">socket     = /tmp/mysql.sock3</span><br><span class="line">port       = 3308</span><br><span class="line">pid-file   = /var/lib/mysql3/hostname.pid3</span><br><span class="line">datadir    = /var/lib/mysql3</span><br><span class="line">language   = /usr/share/mysql/mysql/swedish</span><br><span class="line">user       = unix_user2</span><br><span class="line"></span><br><span class="line">[mysqld4]</span><br><span class="line">socket     = /tmp/mysql.sock4</span><br><span class="line">port       = 3309</span><br><span class="line">pid-file   = /var/lib/mysql4/hostname.pid4</span><br><span class="line">datadir    = /var/lib/mysql4</span><br><span class="line">language   = /usr/share/mysql/mysql/estonia</span><br><span class="line">user       = unix_user3</span><br><span class="line"> </span><br><span class="line">[mysqld6]</span><br><span class="line">socket     = /tmp/mysql.sock6</span><br><span class="line">port       = 3311</span><br><span class="line">pid-file   = /var/lib/mysql6/hostname.pid6</span><br><span class="line">datadir    = /var/lib/mysql6</span><br><span class="line">language   = /usr/share/mysql/mysql/japanese</span><br><span class="line">user       = unix_user4</span><br></pre></td></tr></table></figure></li><li><p>–log=file_name 指定一个日志输出文件，如果文件存在则在文件末尾处添加日志信息</p></li><li>–mysqladmin=pro_name 用于指定一个程序来实现mysqladmin的功能</li><li>–mysqld=pro_name 用于指定一个程序来实现mysqld的功能，如mysqld_safe</li><li>–no-log 将日志信息输出到屏幕上，而不是输入日志文件中</li><li>–password= mysqladmin用户的密码</li><li>–silent 简要信息</li><li>–user= mysqladmin用户，默认为mysql</li><li>–tcp-ip 连接到每个服务器的tcp/ip端口，有时候sock文件丢失，但仍然可以通过tcp/ip端口连接服务器<br>上面是介绍<br>例子：<br>在/etc/mysql/目录下新建mysqld_muti.cnf 内容如下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[mysqld_multi]</span><br><span class="line">mysqld=/usr/local/mysql/bin/mysqld_safe</span><br><span class="line">mysqladmin=/usr/local/mysql/bin/mysqladmin</span><br><span class="line">user=root</span><br><span class="line">password=123456</span><br><span class="line">log=/var/log/mysqld_multi.log</span><br><span class="line"></span><br><span class="line">[mysqld3307]</span><br><span class="line">port=3307</span><br><span class="line">pid-file=/var/lib/mysql3307/mysql3307.pid</span><br><span class="line">socket=/var/lib/mysql3307/mysql3307.sock</span><br><span class="line">datadir=/var/lib/mysql3307</span><br><span class="line">user=mysql</span><br><span class="line">log_bin=mysql-bin</span><br><span class="line">server_id=3307</span><br><span class="line"></span><br><span class="line">[mysqld3308]</span><br><span class="line">port=3308</span><br><span class="line">pid-file=/var/lib/mysql3308/mysql3308.pid</span><br><span class="line">socket=/var/lib/mysql3308/mysql3308.sock</span><br><span class="line">datadir=/var/lib/mysql3308</span><br><span class="line">user=mysql</span><br><span class="line">log_bin=mysql-bin</span><br><span class="line">server_id=3308</span><br><span class="line">relay_log=/var/lib/mysql3308/mysql-relay-bin</span><br><span class="line">log_slave_updates=1</span><br><span class="line">read_only=1</span><br><span class="line"></span><br><span class="line">[mysqld3309]</span><br><span class="line">port=3309</span><br><span class="line">pid-file=/var/lib/mysql3309/mysql3309.pid</span><br><span class="line">socket=/var/lib/mysql3309/mysql3309.sock</span><br><span class="line">datadir=/var/lib/mysql3309</span><br><span class="line">user=mysql</span><br><span class="line">log_bin=mysql-bin</span><br><span class="line">server_id=3309</span><br><span class="line">relay_log=/var/lib/mysql3309/mysql-relay-bin</span><br><span class="line">log_slave_updates=1</span><br><span class="line">read_only=1</span><br></pre></td></tr></table></figure></li></ul><p>启动全部实例：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld_multi --defaults-file=/etc/mysql/mysqld_muti.cnf start</span><br></pre></td></tr></table></figure><p></p><p>查看实例状态：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysqld_multi --defaults-file=/etc/mysql/mysqld_muti.cnf report</span><br><span class="line">Reporting MySQL servers</span><br><span class="line">MySQL server from group: mysqld3307 is running</span><br><span class="line">MySQL server from group: mysqld3308 is running</span><br><span class="line">MySQL server from group: mysqld3309 is running</span><br></pre></td></tr></table></figure><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;废话少说直接贴脚本&lt;/p&gt;&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutte
      
    
    </summary>
    
      <category term="mysql" scheme="http://www.liuyong520.cn/categories/mysql/"/>
    
    
      <category term="mysql" scheme="http://www.liuyong520.cn/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统之冗余数据一致性</title>
    <link href="http://www.liuyong520.cn/2018/05/04/distributed-base-redundant-data/"/>
    <id>http://www.liuyong520.cn/2018/05/04/distributed-base-redundant-data/</id>
    <published>2018-05-04T05:34:47.000Z</published>
    <updated>2019-06-11T09:37:15.539Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><h1 id="一，为什么要冗余数据"><a href="#一，为什么要冗余数据" class="headerlink" title="一，为什么要冗余数据"></a>一，为什么要冗余数据</h1><p>互联网数据量很大的业务场景，往往数据库需要进行水平切分来降低单库数据量。</p><p>水平切分会有一个patition key，通过patition key的查询能够直接定位到库，但是非patition key上的查询可能就需要扫描多个库了。</p><p>此时常见的架构设计方案，是使用数据冗余这种反范式设计来满足分库后不同维度的查询需求。</p><p>例如：订单业务，对用户和商家都有查询需求：<br>Order(oid, info_detail);<br>T(buyer_id, seller_id, oid);<br>如果用buyer_id来分库，seller_id的查询就需要扫描多库。<br>如果用seller_id来分库，buyer_id的查询就需要扫描多库。</p><p>此时可以使用数据冗余来分别满足buyer_id和seller_id上的查询需求：<br>T1(buyer_id, seller_id, oid)<br>T2(seller_id, buyer_id, oid)<br>同一个数据，冗余两份，一份以buyer_id来分库，满足买家的查询需求；一份以seller_id来分库，满足卖家的查询需求。</p><p>如何实施数据的冗余，以及如何保证数据的一致性，是今天将要讨论的内容。</p><h1 id="二，如何进行数据冗余"><a href="#二，如何进行数据冗余" class="headerlink" title="二，如何进行数据冗余"></a>二，如何进行数据冗余</h1><h2 id="服务同步双写"><a href="#服务同步双写" class="headerlink" title="服务同步双写"></a>服务同步双写</h2><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559541736658.png" alt="enter description here"></p><p>顾名思义，由服务层同步写冗余数据，如上图1-4流程：</p><ul><li>业务方调用服务，新增数据</li><li>服务先插入DB1数据</li><li>服务再插入DB2数据</li><li>服务返回业务方新增数据成功</li></ul><p><strong>优点</strong>：<br>不复杂，服务层由单次写，变两次写<br>数据一致性相对较高（因为双写成功才返回）</p><p><strong>缺点</strong>：<br>请求的处理时间增加（要插入两次，时间加倍）<br>数据仍可能不一致，例如第二步写入T1完成后服务重启，则数据不会写入T2</p><p>如果系统对处理时间比较敏感，引出常用的第二种方案。</p><h2 id="服务异步双写"><a href="#服务异步双写" class="headerlink" title="服务异步双写"></a>服务异步双写</h2><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559541777225.png" alt="enter description here"><br>数据的双写并不再由服务来完成，服务层异步发出一个消息，通过消息总线发送给一个专门的数据复制服务来写入冗余数据，如上图1-6流程：</p><ul><li>业务方调用服务，新增数据</li><li>服务先插入DB1数据</li><li>服务向消息总线发送一个异步消息（发出即可，不用等返回，通常很快就能完成）</li><li>服务返回业务方新增数据成功</li><li>消息总线将消息投递给数据同步中心</li><li>数据同步中心插入DB2数据</li></ul><p><strong>优点</strong>：</p><ul><li>请求处理时间短（只插入1次）</li></ul><p><strong>缺点</strong>：</p><ul><li>系统的复杂性增加了，多引入了一个组件（消息总线）和一个服务（专用的数据复制服务）</li><li>因为返回业务线数据插入成功时，数据还不一定插入到T2中，因此数据有一个不一致时间窗口（这个窗口很短，最终是一致的）</li><li>在消息总线丢失消息时，冗余表数据会不一致</li></ul><p>不管是服务同步双写，还是服务异步双写，服务都需要关注“冗余数据”带来的复杂性。如果想解除“数据冗余”对系统的耦合，引出常用的第三种方案。</p><h2 id="线下异步双写"><a href="#线下异步双写" class="headerlink" title="线下异步双写"></a>线下异步双写</h2><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559542589601.png" alt="enter description here"><br>为了屏蔽“冗余数据”对服务带来的复杂性，数据的双写不再由服务层来完成，而是由线下的一个服务或者任务来完成，如上图1-6流程：</p><ul><li>业务方调用服务，新增数据</li><li>服务先插入DB1数据</li><li>服务返回业务方新增数据成功</li><li>数据会被写入到数据库的log中</li><li>线下服务或者任务读取数据库的log</li><li>线下服务或者任务插入DB2数据</li></ul><p><strong>优点</strong>：</p><ul><li>数据双写与业务完全解耦</li><li>请求处理时间短（只插入1次）</li></ul><p><strong>缺点</strong>：</p><ul><li>返回业务线数据插入成功时，数据还不一定插入到T2中，因此数据有一个不一致时间窗口（这个窗口很短，最终是一致的）</li><li>数据的一致性依赖于线下服务或者任务的可靠性</li></ul><p>不管哪种方案，毕竟不是分布式事务，万一出现数据不一致，怎么办呢？<br>高并发的情况下，实时一致性很难，方法论是：<strong>最终一致性</strong>。<br>实现方式是：<strong>异步检测，异步修复</strong>。</p><h1 id="三，如何保证数据的一致性"><a href="#三，如何保证数据的一致性" class="headerlink" title="三，如何保证数据的一致性"></a>三，如何保证数据的一致性</h1><h2 id="线下扫描全量数据法"><a href="#线下扫描全量数据法" class="headerlink" title="线下扫描全量数据法"></a>线下扫描全量数据法</h2><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559543150549.png" alt="enter description here"><br>如上图所示，线下启动一个离线的扫描工具，不停的比对正表DB1和反表DB2，如果发现数据不一致，就进行补偿修复。</p><p><strong>优点</strong>：</p><ul><li>比较简单，开发代价小</li><li>线上服务无需修改，修复工具与线上服务解耦</li></ul><p><strong>缺点</strong>：</p><ul><li>扫描效率低，会扫描大量的“已经能够保证一致”的数据</li><li>由于扫描的数据量大，扫描一轮的时间比较长，即数据如果不一致，不一致的时间窗口比较长</li></ul><p>有没有只扫描“可能存在不一致可能性”的数据，而不是每次扫描全部数据，以提高效率的优化方法呢？</p><h2 id="线下扫描增量数据法"><a href="#线下扫描增量数据法" class="headerlink" title="线下扫描增量数据法"></a>线下扫描增量数据法</h2><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559543906788.png" alt="enter description here"><br>每次只扫描增量的日志数据，就能够极大提高效率，缩短数据不一致的时间窗口，如上图2-8流程所示：</p><ul><li>写入正表DB1</li><li>第一步成功后，写入日志log1</li><li>写入反表DB2</li><li>第二步成功后，写入日志log2<br>当然，我们还是需要一个离线的扫描工具，不停的比对日志log1和日志log2，如果发现数据不一致，就进行补偿修复</li></ul><p><strong>优点</strong>：</p><ul><li>虽比方法一复杂，但仍然是比较简单的</li><li>数据扫描效率高，只扫描增量数据</li></ul><p><strong>缺点</strong>：</p><ul><li>线上服务略有修改（代价不高，多写了2条日志）</li><li>虽然比方法一更实时，但时效性还是不高，不一致窗口取决于扫描的周期</li></ul><p>有没有实时检测一致性并进行修复的方法呢？</p><h2 id="线上实时检测“消息对”法"><a href="#线上实时检测“消息对”法" class="headerlink" title="线上实时检测“消息对”法"></a>线上实时检测“消息对”法</h2><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559544318583.png" alt="enter description here"><br>这次不是写日志了，而是向消息总线发送消息，如上图2-7流程所示：</p><ul><li>写入正表DB1</li><li>第一步成功后，发送消息msg1</li><li>写入反表DB2</li><li>第二步成功后，发送消息msg2<br>这次不是需要一个周期扫描的离线工具了，而是一个实时订阅消息的服务不停的收消息。</li></ul><p>假设正常情况下，msg1和msg2的接收时间应该在3s以内，如果检测服务在收到msg1后没有收到msg2，就尝试检测数据的一致性，不一致时进行补偿修复。</p><p><strong>优点</strong>：</p><ul><li>效率高</li><li>实时性高</li></ul><p><strong>缺点</strong>：</p><ul><li>方案比较复杂，上线引入了消息总线这个组件</li><li>线下多了一个订阅总线的检测服务</li></ul><p>however，技术方案本身就是一个投入产出比的折衷，可以根据业务对一致性的需求程度决定使用哪一种方法。我曾经做过IM系统，好友关系链上亿，好友数据正反表的数据冗余，使用的就是方法二。</p><h1 id="四，总结"><a href="#四，总结" class="headerlink" title="四，总结"></a>四，总结</h1><p>互联网数据量大的业务场景，常常:</p><ul><li>使用水平切分来降低单库数据量</li><li>使用数据冗余的反范式设计来满足不同维度的查询需求<br>冗余数据三种方案：<br>(1)服务同步双写法能够很容易的实现数据冗余<br>(2)为了降低时延，可以优化为服务异步双写法<br>(3)为了屏蔽“冗余数据”对服务带来的复杂性，可以优化为线下异步双写法<br>保证数据一致性的方案：<br>(1)最简单的方式，线下脚本扫全量数据比对<br>(2)提高效率的方式，线下脚本扫增量数据比对<br>(3)最实时的方式，线上检测“消息对”</li></ul><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;一，为什么要冗余数据&quot;&gt;&lt;a href=&quot;#一，为什么要冗余数据&quot; class=&quot;headerlink&quot; title=&quot;一，为什么要冗
      
    
    </summary>
    
      <category term="分布式系统" scheme="http://www.liuyong520.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="分布式系统" scheme="http://www.liuyong520.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统之分布式事务处理</title>
    <link href="http://www.liuyong520.cn/2018/04/05/distributed-base-transaction/"/>
    <id>http://www.liuyong520.cn/2018/04/05/distributed-base-transaction/</id>
    <published>2018-04-05T09:23:25.000Z</published>
    <updated>2019-06-11T09:37:15.347Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><p>为保障系统的可用性、可靠性以及性能，在分布式系统中，往往会设置数据冗余，即对数据进行复制。举例来说，当一个数据库的副本被破环以后，那么系统只需要转换到其他数据副本就能继续运行下去。另外一个例子，当访问单一服务器管理的数据的进程数不断增加时，系统就需要对服务器的数量进行扩充，此时，对服务器进行复制，随后让它们分担工作负荷，就可以提高性能。但同时，如何保障多个数据节点之间数据的一致以及如何处理分布式事务，将成为为一个复杂的话题。本文将介绍常用的事务处理机制。</p><p>举个例子：</p><p>用户下了一个订单，需要修改余额表，订单表，流水表，于是会有类似的伪代码：<br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">start</span> <span class="keyword">transaction</span>;</span><br><span class="line"> CURD table t_account;  any Exception <span class="keyword">rollback</span>;</span><br><span class="line"> CURD table t_order;    any Exception <span class="keyword">rollback</span>;</span><br><span class="line"> CURD table t_flow;     any Exception <span class="keyword">rollback</span>;</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p></p><ul><li>如果对余额表，订单表，流水表的SQL操作全部成功，则全部提交</li><li>如果任何一个出现问题，则全部回滚<br>事务，以保证数据的完整性以及一致性。</li></ul><h1 id="事务的方案会有什么潜在问题？"><a href="#事务的方案会有什么潜在问题？" class="headerlink" title="事务的方案会有什么潜在问题？"></a>事务的方案会有什么潜在问题？</h1><p>答：互联网的业务特点是海量数据，大并发的数据访问量，所以经常使用拆库的方式提升系统的性能。如果进行了拆库，余额、订单、流水可能分布在不同的数据库上，甚至不同的数据库实例上，此时就不能用数据库原生事务来保证数据的一致性了，就需要用到分布式事务才能解决这类问题了。</p><h1 id="那么常见的分布式事务解决方案有哪些呢？"><a href="#那么常见的分布式事务解决方案有哪些呢？" class="headerlink" title="那么常见的分布式事务解决方案有哪些呢？"></a>那么常见的分布式事务解决方案有哪些呢？</h1><ul><li>补偿事务</li><li>后置提交优化</li><li>两阶段提交（2pc）</li><li>三阶段提交</li><li>TCC事务解决方案</li><li>可靠消息一致性解决方案</li></ul><h1 id="什么是补偿事务？"><a href="#什么是补偿事务？" class="headerlink" title="什么是补偿事务？"></a>什么是补偿事务？</h1><p>补偿事务，是一种在业务端实施业务逆向操作事务。</p><p>举个栗子：<br>修改余额，事务为：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Do_AccountT</span><span class="params">(uid, money)</span></span>&#123;</span><br><span class="line">    start transaction;</span><br><span class="line">         <span class="comment">//余额改变money这么多</span></span><br><span class="line">         CURD table t_account with money <span class="keyword">for</span> uid;</span><br><span class="line">         anyException rollback <span class="keyword">return</span> NO;</span><br><span class="line">    commit;</span><br><span class="line">    <span class="keyword">return</span> YES;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>那么，修改余额，补偿事务可以是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">Compensate_AccountT</span><span class="params">(uid, money)</span></span>&#123;</span><br><span class="line">         <span class="comment">//做一个money的反向操作</span></span><br><span class="line">         <span class="keyword">return</span> Do_AccountT(uid, -<span class="number">1</span>*money)&#123;</span><br><span class="line">&#125;</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">同理，订单操作，事务是：Do_OrderT，新增一个订单；</span><br><span class="line">订单操作，补偿事务是：Compensate_OrderT，删除一个订单。</span><br><span class="line"> </span><br><span class="line">要保证余额与订单的一致性，伪代码：</span><br><span class="line"></span><br><span class="line">```java</span><br><span class="line"><span class="comment">// 执行第一个事务</span></span><br><span class="line"><span class="keyword">int</span> flag = Do_AccountT();</span><br><span class="line"><span class="keyword">if</span>(flag=YES)&#123;</span><br><span class="line">    <span class="comment">//第一个事务成功，则执行第二个事务</span></span><br><span class="line">    flag= Do_OrderT();</span><br><span class="line">    <span class="keyword">if</span>(flag=YES)&#123;</span><br><span class="line">        <span class="comment">// 第二个事务成功，则成功</span></span><br><span class="line">        <span class="keyword">return</span> YES;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">// 第二个事务失败，执行第一个事务的补偿事务</span></span><br><span class="line">        Compensate_AccountT();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">``` </span><br><span class="line"># 补偿事务有什么缺点？</span><br><span class="line"></span><br><span class="line">- 不同的业务要写不同的补偿事务，不具备通用性；</span><br><span class="line">- 没有考虑补偿事务的失败；</span><br><span class="line">- 如果业务流程很复杂，<span class="keyword">if</span>/<span class="keyword">else</span>会嵌套非常多层；</span><br><span class="line"></span><br><span class="line">**上面的例子还只考虑了余额+订单的一致性，就有<span class="number">2</span>*<span class="number">2</span>=<span class="number">4</span>个分支，如果要考虑余额+订单+流水的一致性，则会有<span class="number">2</span>*<span class="number">2</span>*<span class="number">2</span>=<span class="number">8</span>个<span class="keyword">if</span>/<span class="keyword">else</span>分支，复杂性呈指数级增长。**</span><br><span class="line"></span><br><span class="line"># 后置提交优化</span><br><span class="line"></span><br><span class="line">举个例子：</span><br><span class="line">单库是用这样一个大事务保证一致性：</span><br><span class="line">```java</span><br><span class="line">start transaction;</span><br><span class="line"> CURD table t_account;  any Exception rollback;</span><br><span class="line"> CURD table t_order;      any Exception rollback;</span><br><span class="line"> CURD table t_flow;        any Exception rollback;</span><br><span class="line">commit;</span><br></pre></td></tr></table></figure><p>拆分成了多个库后，大事务会变成三个小事务：<br></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start transaction1;</span><br><span class="line">         <span class="comment">//第一个库事务执行</span></span><br><span class="line">         CURD table t_account; any Exception rollback;</span><br><span class="line">         …</span><br><span class="line"><span class="comment">// 第一个库事务提交</span></span><br><span class="line">commit1;</span><br></pre></td></tr></table></figure><p></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start transaction2;</span><br><span class="line">         <span class="comment">//第二个库事务执行</span></span><br><span class="line">         CURD table t_order; any Exception rollback;</span><br><span class="line">         …</span><br><span class="line"><span class="comment">// 第二个库事务提交</span></span><br><span class="line">commit2;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">start transaction3;</span><br><span class="line">         <span class="comment">//第三个库事务执行</span></span><br><span class="line">         CURD table t_flow; any Exception rollback;</span><br><span class="line">         …</span><br><span class="line"><span class="comment">// 第三个库事务提交</span></span><br><span class="line">commit3;</span><br></pre></td></tr></table></figure><p><strong>再次提醒</strong>，这三个事务发生在三个库，甚至3个不同实例的数据库上。</p><p>一个事务，分成执行与提交两个阶段：</p><ul><li>执行(CURD)的时间很长</li><li>提交(commit)的执行很快</li></ul><p>于是整个执行过程的时间轴如下：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559477428143.png" alt="enter description here"></p><p>第一个事务执行200ms，提交1ms；<br>第二个事务执行200ms，提交1ms；<br>第三个事务执行250ms，提交1ms；</p><h1 id="在什么时候，会出现不一致？"><a href="#在什么时候，会出现不一致？" class="headerlink" title="在什么时候，会出现不一致？"></a>在什么时候，会出现不一致？</h1><p>第一个事务成功提交之后，最后一个事务成功提交之前，如果出现问题（例如服务器重启，数据库异常等），都可能导致数据不一致。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559477840556.png" alt="enter description here"><br>如上图，最后452ms可能会出现数据不一致的问题</p><h1 id="何谓后置提交优化？"><a href="#何谓后置提交优化？" class="headerlink" title="何谓后置提交优化？"></a>何谓后置提交优化？</h1><p>如果改变事务执行与提交的时序，变成事务先执行，最后一起提交。就变成了下图<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559478439352.png" alt="enter description here"><br>第一个事务执行200ms，第二个事务执行200ms，第三个事务执行250ms；<br>第一个事务提交1ms，第二个事务提交1ms，第三个事务提交1ms；</p><h1 id="后置提交优化后，在什么时候，会出现不一致？"><a href="#后置提交优化后，在什么时候，会出现不一致？" class="headerlink" title="后置提交优化后，在什么时候，会出现不一致？"></a>后置提交优化后，在什么时候，会出现不一致？</h1><p>第一个事务成功提交之后，最后一个事务成功提交之前，如果出现问题（例如服务器重启，数据库异常等），都可能导致数据不一致<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559479001240.png" alt="enter description here"><br>如上图最后2ms可能会出现数据不一致。</p><h1 id="有什么区别和差异？"><a href="#有什么区别和差异？" class="headerlink" title="有什么区别和差异？"></a>有什么区别和差异？</h1><ul><li>串行事务方案，总执行时间是653ms，最后452ms内出现异常都可能导致不一致；</li><li>后置提交优化方案，总执行时间也是653ms，但最后2ms内出现异常才会导致不一致；<br>虽然没有彻底解决数据的一致性问题，但不一致出现的概率大大降低了。<br>上面这个例子，概率降低了250倍。</li></ul><h1 id="后置提交优化，有什么不足？"><a href="#后置提交优化，有什么不足？" class="headerlink" title="后置提交优化，有什么不足？"></a>后置提交优化，有什么不足？</h1><p>对事务吞吐量会有影响：</p><ul><li>串行事务方案，第一个库事务提交，数据库连接就释放了；</li><li>后置提交优化方案，所有库的连接，要等到所有事务执行完才释放；<br>这就意味着，数据库连接占用的时间增长了，系统整体的吞吐量降低了。</li></ul><h1 id="两阶段提交（2PC）"><a href="#两阶段提交（2PC）" class="headerlink" title="两阶段提交（2PC）"></a>两阶段提交（2PC）</h1><p>两阶段提交协议 （Two-phase commit protocol，2PC）的过程涉及到协调者和参与者。协调者可以看做成事务的发起者，同时也是事务的一个参与者。对于一个分布式事务来说，一个事务是涉及到多个参与者的。具体的两阶段提交的过程如下：<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559524279889.png" alt="enter description here"></p><h2 id="第一阶段（准备阶段）"><a href="#第一阶段（准备阶段）" class="headerlink" title="第一阶段（准备阶段）"></a>第一阶段（准备阶段）</h2><p>协调者节点向所有参与者节点询问是否可以执行提交操作(vote)，并开始等待各参与者节点的响应。<br>参与者节点执行询问发起为止的所有事务操作，并将 Undo 信息和 Redo 信息写入日志。（注意：若成功这里其实每个参与者已经执行了事务操作）<br>各参与者节点响应协调者节点发起的询问。如果参与者节点的事务操作实际执行成功，则它返回一个“同意”消息；如果参与者节点的事务操作实际执行失败，则它返回一个“中止”消息。</p><h2 id="第二阶段（提交阶段）"><a href="#第二阶段（提交阶段）" class="headerlink" title="第二阶段（提交阶段）"></a>第二阶段（提交阶段）</h2><p>如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)</p><p>当协调者节点从所有参与者节点获得的相应消息都为“同意”时:</p><ul><li>协调者节点向所有参与者节点发出“正式提交(commit)”的请求。</li><li>参与者节点正式完成操作，并释放在整个事务期间内占用的资源。</li><li>参与者节点向协调者节点发送“完成”消息。<br>如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：</li><li>协调者节点向所有参与者节点发出”回滚操作(rollback)”的请求。</li><li>参与者节点利用之前写入的Undo信息执行回滚，并释放在整个事务期间内占用的资源。</li><li>参与者节点向协调者节点发送”回滚完成”消息。</li><li>协调者节点受到所有参与者节点反馈的”回滚完成”消息后，取消事务。</li><li>协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务<br>不管最后结果如何，第二阶段都会结束当前事务。</li></ul><h2 id="二段式提交协议的优缺点："><a href="#二段式提交协议的优缺点：" class="headerlink" title="二段式提交协议的优缺点："></a>二段式提交协议的优缺点：</h2><p>优点：原理简单，实现方便；</p><p>缺点：</p><ul><li>同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。</li><li>单点故障。由于协调者的重要性，一旦协调者发生故障，参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。</li><li>数据不一致。在阶段二中，当协调者向参与者发送 commit 请求之后，发生了局部网络异常或者在发送 commit 请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了 commit 请求。而在这部分参与者接到 commit 请求之后就会执行 commit 操作。但是其他部分未接到 commit 请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。</li><li>二阶段无法解决的问题：协调者再发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。<br>为了解决两阶段提交协议的种种问题，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。</li></ul><h1 id="三阶段提交（3PC）"><a href="#三阶段提交（3PC）" class="headerlink" title="三阶段提交（3PC）"></a>三阶段提交（3PC）</h1><p>三阶段提交协议（Three-phase commit protocol，3PC），是二阶段提交（2PC）的改进版本。与两阶段提交不同的是，三阶段提交有两个改动点：</p><ul><li>引入超时机制。同时在协调者和参与者中都引入超时机制。</li><li>在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。<br>即 3PC 把 2PC 的准备阶段再次一分为二，这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段。</li></ul><h2 id="CanCommit-阶段"><a href="#CanCommit-阶段" class="headerlink" title="CanCommit 阶段"></a>CanCommit 阶段</h2><p>CanCommit 阶段其实和 2PC 的准备阶段很像。协调者向参与者发送 commit 请求，参与者如果可以提交就返回 Yes 响应，否则返回 No 响应。</p><ul><li>事务询问：协调者向参与者发送 CanCommit 请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。</li><li>响应反馈：参与者接到 CanCommit 请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回 Yes 响应，并进入预备状态。否则反馈 No</li></ul><h2 id="PreCommit-阶段"><a href="#PreCommit-阶段" class="headerlink" title="PreCommit 阶段"></a>PreCommit 阶段</h2><p>协调者根据参与者的反应情况来决定是否可以记性事务的 PreCommit 操作。根据响应情况，有以下两种可能。</p><ul><li>假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务的预执行。<br>发送预提交请求：协调者向参与者发送 PreCommit 请求，并进入Prepared 阶段。</li><li>事务预提交：参与者接收到 PreCommit 请求后，会执行事务操作，并将undo 和 redo 信息记录到事务日志中。</li><li>响应反馈：如果参与者成功的执行了事务操作，则返回 ACK 响应，同时开始等待最终指令。</li><li>假如有任何一个参与者向协调者发送了 No 响应，或者等待超时之后，协调者都没有接到参与者的响应，那么就执行事务的中断。</li><li>发送中断请求：协调者向所有参与者发送 abort 请求。</li><li>中断事务：参与者收到来自协调者的 abort 请求之后（或超时之后，仍未收到协调者的请求），执行事务的中断。</li></ul><h2 id="doCommit-阶段"><a href="#doCommit-阶段" class="headerlink" title="doCommit 阶段"></a>doCommit 阶段</h2><p>该阶段进行真正的事务提交，也可以分为以下两种情况。</p><ul><li>执行提交</li><li>发送提交请求：协调接收到参与者发送的 ACK 响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送 doCommit 请求。</li><li>事务提交：参与者接收到 doCommit 请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。</li><li>响应反馈：事务提交完之后，向协调者发送 ACK 响应。</li><li>完成事务：协调者接收到所有参与者的 ACK 响应之后，完成事务。</li><li>中断事务：协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是 ACK 响应，也可能响应超时），那么就会执行中断事务。</li><li>发送中断请求：协调者向所有参与者发送 abort 请求</li><li>事务回滚：参与者接收到 abort 请求之后，利用其在阶段二记录的undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。</li><li>反馈结果：参与者完成事务回滚之后，向协调者发送 ACK 消息</li><li>中断事务：协调者接收到参与者反馈的 ACK 消息之后，执行事务的中断。<br>在 doCommit 阶段，如果参与者无法及时接收到来自协调者的 doCommit 或者 rebort 请求时，会在等待超时之后，会继续进行事务的提交。即当进入第三阶段时，由于网络超时等原因，虽然参与者没有收 到 commit 或者 abort 响应，事务仍然会提交。</li></ul><p>三阶段提交不会一直持有事务资源并处于阻塞状态。但是这种机制也会导致数据一致性问题，因为，由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作，这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。</p><h1 id="TCC事务解决方案"><a href="#TCC事务解决方案" class="headerlink" title="TCC事务解决方案"></a>TCC事务解决方案</h1><p>在08年的软件开发2.0技术大会上，支付宝程立在PPT大规模SOA系统中的分布事务处理，提出TCC概念。在网络上搜索分布式事务相关的博客，基本都会提及这个PPT，目前很多分布式事务开源项目也都是基于TCC的思想实现。</p><p>TCC 将事务提交分为 Try - Confirm - Cancel 3个操作。</p><p>Try：预留业务资源/数据效验<br>Confirm：确认执行业务操作<br>Cancel：取消执行业务操作<br>TCC事务处理流程和 2PC 二阶段提交类似，不过 2PC通常都是在跨库的DB层面，而TCC本质就是一个应用层面的2PC。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559525194271.png" alt="此图摘自网络"></p><p>事务开始时，业务应用会向事务协调器注册启动事务。之后业务应用会调用所有服务的try接口，完成一阶段准备。之后事务协调器会根据try接口返回情况，决定调用confirm接口或者cancel接口。如果接口调用失败，会进行重试。</p><h1 id="TCC事务的优缺点"><a href="#TCC事务的优缺点" class="headerlink" title="TCC事务的优缺点"></a>TCC事务的优缺点</h1><p>优点：</p><ul><li>让应用自己定义数据库操作的粒度，使得降低锁冲突、提高吞吐量成为可能。<br>缺点：</li><li>对应用的侵入性强。业务逻辑的每个分支都需要实现try、confirm、cancel三个操作，应用侵入性较强，改造成本高。</li><li>实现难度较大。需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。为了满足一致性的要求，confirm和cancel接口必须实现幂等。</li></ul><p>举个例子：<br>支付宝红包+余额支付的例子：用户下一个订单等待支付，会修改余额账户和红包账户系统的钱。<br>假设用户下单操作来自3个系统下单系统、资金账户系统、红包账户系统，下单成功需要同时调用资金账户服务和红包服务完成支付</p><p>假设购买商品1000元，使用账户红包200元，余额800元，确认支付。<br>伪代码：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Try操作</span><br><span class="line">tryX create tb_order   //下单系统创建待支付订单</span><br><span class="line">tryY freeze tb_balance //update tb_balance set freezebanlance=freezebalance+200 冻结账户红包200元</span><br><span class="line">tryZ freeze tb_account //update tb_balance set freezeaccount=freezeaccount+800 冻结资金账户800元</span><br><span class="line"></span><br><span class="line">Confirm操作</span><br><span class="line">confirmX update tb_order set state=&quot;success&quot; // 订单更新为支付成功</span><br><span class="line">confirmY update tb_balance set balance= balance-200//扣减账户红包200元</span><br><span class="line">confirmZ update tb_account set account= account-800 //扣减资金账户800元</span><br><span class="line"></span><br><span class="line">Cancel操作</span><br><span class="line">cancelX 订单处理异常，资金红包退回，订单支付失败</span><br><span class="line">cancelY 冻结红包失败，账户余额退回，订单支付失败</span><br><span class="line">cancelZ 冻结余额失败，账户红包退回，订单支付失败</span><br></pre></td></tr></table></figure><p></p><h1 id="可靠消息一致性解决方案"><a href="#可靠消息一致性解决方案" class="headerlink" title="可靠消息一致性解决方案"></a>可靠消息一致性解决方案</h1><p>消息一致性方案是通过消息中间件保证上、下游应用数据操作的一致性。基本思路是将本地操作和发送消息放在一个事务中，保证本地操作和消息发送要么两者都成功或者都失败。下游应用向消息系统订阅该消息，收到消息后执行相应操作。<br><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559527994255.png" alt="enter description here"><br>消息方案从本质上讲是将分布式事务转换为两个本地事务，然后依靠下游业务的重试机制达到最终一致性。基于消息的最终一致性方案对应用侵入性也很高，应用需要进行大量业务改造，成本较高。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;为保障系统的可用性、可靠性以及性能，在分布式系统中，往往会设置数据冗余，即对数据进行复制。举例来说，当一个数据库的副本被破环以后，那么系统只需要
      
    
    </summary>
    
      <category term="分布式系统" scheme="http://www.liuyong520.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="分布式系统" scheme="http://www.liuyong520.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统之CAP定理</title>
    <link href="http://www.liuyong520.cn/2018/04/02/distributed-base/"/>
    <id>http://www.liuyong520.cn/2018/04/02/distributed-base/</id>
    <published>2018-04-02T08:04:25.000Z</published>
    <updated>2019-06-11T09:37:16.616Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --><p>分布式系统非常关注三个指标：</p><ul><li>数据一致性</li><li>系统可用性</li><li>节点连通性与扩展性</li></ul><h1 id="关于一致性"><a href="#关于一致性" class="headerlink" title="关于一致性"></a>关于一致性</h1><p>数据“强一致性”，是希望系统只读到最新写入的数据，例如：通过单点串行化的方式，就能够达到这个效果。</p><p>关于session一致性，DB主从一致性，DB双主一致性，DB与Cache一致性，数据冗余一致性，消息时序一致性，分布式事务一致性，库存扣减一致性，详见文章《究竟啥才是互联网架构“一致性”》。</p><h1 id="关于可用性"><a href="#关于可用性" class="headerlink" title="关于可用性"></a>关于可用性</h1><p>如果系统每运行100个时间单位，会有1个时间单位无法提供服务，则说系统的可用性是99%。</p><p>可用性和可靠性是比较容易搞混的两个指标，以一台取款机为例：</p><ul><li>正确的输入，能够取到正确的钱，表示系统可靠</li><li>取款机7*24小时提供服务，表示系统可用</li></ul><p>保证系统高可用的方法是：</p><ul><li>冗余</li><li>故障自动转移</li></ul><p>反向代理层，站点层，服务层，缓存层，数据库层各层保证系统高可用的方法，详见文章《究竟啥才是互联网架构“高可用”》。</p><h1 id="关于连通性与扩展性"><a href="#关于连通性与扩展性" class="headerlink" title="关于连通性与扩展性"></a>关于连通性与扩展性</h1><p>分布式系统，往往有多个节点，每个节点之间，都不是完全独立的，需要相互通信，当发生节点无法联通时，数据是否还能保持一致，系统要如何进行容错处理，是需要考虑的。</p><p>同时，连通性和扩展性紧密相关，想要加机器扩展性能，必须有良好的连通性。当一个节点脱离系统，系统就出现问题，往往意味着系统是无法扩展的。</p><h1 id="什么是CAP定理？"><a href="#什么是CAP定理？" class="headerlink" title="什么是CAP定理？"></a>什么是CAP定理？</h1><p><strong>CAP定理</strong>，是对上述分布式系统的三个特性，进行了归纳：</p><ul><li>一致性(Consistency)</li><li>可用性(Availability)</li><li>分区容忍性(Partition Tolerance)<br>并且，定理指出，在系统实现时，这三者最多兼顾两点。</li></ul><p>一致性，可用性，多节点扩展性三者只能取其二，既然加锁已经加上，常见的最佳工程架构实践是什么呢？<br>互联网，最常见的实践是这样的：<br>节点连通性，多节点扩展性，连通性异常的处理必须保证，满足P<br>一致性C与可用性A一般二选一<br>选择一致性C，举例：传统单库水平切分，就是这类选型的典型<br>选择可用性A，举例：双主库同步高可用，就是这类选型的典型</p><h1 id="强一致很难怎么办？"><a href="#强一致很难怎么办？" class="headerlink" title="强一致很难怎么办？"></a>强一致很难怎么办？</h1><p>单点串行化，虽然能保证“强一致”，但对系统的并发性能，以及高可用有较大影响，互联网的玩法，更多的是“最终一致性”，短期内未必读到最新的数据，但在一个可接受的时间窗口之后，能够读到最新的数据。</p><p>例如：数据库主从同步，从库上的数据，就是一个最终的一致。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>CAP可以理解为一致性，可用性，联通与扩展性<br>CAP三者只能取其二<br>最常见的实践是AP+最终一致性</p><p><strong>思路</strong>比结论重要。</p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:46 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;分布式系统非常关注三个指标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据一致性&lt;/li&gt;&lt;li&gt;系统可用性&lt;/li&gt;&lt;li&gt;节点连通性与扩展性&lt;/li&gt;&lt;/ul
      
    
    </summary>
    
      <category term="分布式系统" scheme="http://www.liuyong520.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
    
      <category term="分布式系统" scheme="http://www.liuyong520.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>6张图读懂大型网站架构</title>
    <link href="http://www.liuyong520.cn/2018/03/02/distributed/"/>
    <id>http://www.liuyong520.cn/2018/03/02/distributed/</id>
    <published>2018-03-02T07:08:52.000Z</published>
    <updated>2019-06-11T09:37:16.159Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><h1 id="大型网站架构演化"><a href="#大型网站架构演化" class="headerlink" title="大型网站架构演化"></a>大型网站架构演化</h1><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559459544644.png" alt="enter description here"></p><h1 id="大型网站架构方法"><a href="#大型网站架构方法" class="headerlink" title="大型网站架构方法"></a>大型网站架构方法</h1><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559459959928.png" alt="enter description here"></p><h1 id="网站的安全架构"><a href="#网站的安全架构" class="headerlink" title="网站的安全架构"></a>网站的安全架构</h1><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559459975621.png" alt="enter description here"></p><h1 id="网站的高可用架构"><a href="#网站的高可用架构" class="headerlink" title="网站的高可用架构"></a>网站的高可用架构</h1><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559459990192.png" alt="enter description here"></p><h1 id="网站的伸缩性架构"><a href="#网站的伸缩性架构" class="headerlink" title="网站的伸缩性架构"></a>网站的伸缩性架构</h1><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559460003145.png" alt="enter description here"></p><h1 id="大型网站核心架构要素"><a href="#大型网站核心架构要素" class="headerlink" title="大型网站核心架构要素"></a>大型网站核心架构要素</h1><p><img src="https://www.github.com/liuyong520/pic/raw/master/小书匠/1559460050437.png" alt="enter description here"></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;h1 id=&quot;大型网站架构演化&quot;&gt;&lt;a href=&quot;#大型网站架构演化&quot; class=&quot;headerlink&quot; title=&quot;大型网站架构演化&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="分布式架构" scheme="http://www.liuyong520.cn/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Docker 容器技术</title>
    <link href="http://www.liuyong520.cn/2018/02/12/docker/"/>
    <id>http://www.liuyong520.cn/2018/02/12/docker/</id>
    <published>2018-02-12T04:15:31.000Z</published>
    <updated>2019-06-11T09:37:16.606Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --><h2 id="一、Docker-简介"><a href="#一、Docker-简介" class="headerlink" title="一、Docker 简介"></a>一、Docker 简介</h2><p>Docker是一个新的容器化的技术，它轻巧，且易移植。</p><h3 id="Docker-组件与元素"><a href="#Docker-组件与元素" class="headerlink" title="Docker 组件与元素"></a>Docker 组件与元素</h3><p>Docker有三个组件和三个基本元素。</p><p>三个组件分别是：</p><ul><li><code>Docker Client</code> 是用户界面，它支持用户与<code>Docker Daemon</code>之间通信。</li><li><code>Docker Daemon</code>运行于主机上，处理服务请求。</li><li><code>Docker Index</code>是中央registry，支持拥有公有与私有访问权限的Docker容器镜像的备份。</li></ul><p>三个基本要素分别是：</p><ul><li><code>Docker Containers</code>负责应用程序的运行，包括操作系统、用户添加的文件以及元数据。</li><li><code>Docker Images</code>是一个只读模板，用来运行Docker容器。</li><li><code>DockerFile</code>是文件指令集，用来说明如何自动创建Docker镜像。</li></ul><p><img src="http://topweshare.qiniudn.com/1522984222.png?imageMogr2/thumbnail/!70p" alt></p><h3 id="1-1-Docker-守护进程"><a href="#1-1-Docker-守护进程" class="headerlink" title="1.1 Docker 守护进程"></a>1.1 Docker 守护进程</h3><p>如上图所示，Docker 守护进程运行在一台主机上。用户并不直接和守护进程进行交互，而是通过 Docker 客户端间接和其通信。</p><h3 id="1-2-Docker-客户端"><a href="#1-2-Docker-客户端" class="headerlink" title="1.2 Docker 客户端"></a>1.2 Docker 客户端</h3><p>Docker 客户端，实际上是 docker 的二进制程序，是主要的用户与 Docker 交互方式。它接收用户指令并且与背后的 Docker 守护进程通信，如此来回往复。</p><h3 id="1-3-Docker-内部"><a href="#1-3-Docker-内部" class="headerlink" title="1.3 Docker 内部"></a>1.3 Docker 内部</h3><p>要理解 Docker 内部构建，需要理解以下三种部件：</p><ul><li>Docker 镜像 - Docker images</li><li>Docker 仓库 - Docker registeries</li><li>Docker 容器 - Docker containers</li></ul><h4 id="Docker-镜像"><a href="#Docker-镜像" class="headerlink" title="Docker 镜像"></a>Docker 镜像</h4><p>Docker 镜像是 Docker 容器运行时的只读模板，每一个镜像由一系列的层 (layers) 组成。Docker 使用 UnionFS 来将这些层联合到单独的镜像中。UnionFS 允许独立文件系统中的文件和文件夹(称之为分支)被透明覆盖，形成一个单独连贯的文件系统。正因为有了这些层的存在，Docker 是如此的轻量。当你改变了一个 Docker 镜像，比如升级到某个程序到新的版本，一个新的层会被创建。因此，不用替换整个原先的镜像或者重新建立(在使用虚拟机的时候你可能会这么做)，只是一个新 的层被添加或升级了。现在你不用重新发布整个镜像，只需要升级，层使得分发 Docker 镜像变得简单和快速。</p><h4 id="Docker-仓库"><a href="#Docker-仓库" class="headerlink" title="Docker 仓库"></a>Docker 仓库</h4><p>Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。同样的，Docker 仓库也有公有和私有的概念。公有的 Docker 仓库名字是 Docker Hub。Docker Hub 提供了庞大的镜像集合供使用。这些镜像可以是自己创建，或者在别人的镜像基础上创建。Docker 仓库是 Docker 的分发部分。</p><h4 id="Docker-容器"><a href="#Docker-容器" class="headerlink" title="Docker 容器"></a>Docker 容器</h4><p>Docker 容器和文件夹很类似，一个Docker容器包含了所有的某个应用运行所需要的环境。每一个 Docker 容器都是从 Docker 镜像创建的。Docker 容器可以运行、开始、停止、移动和删除。每一个 Docker 容器都是独立和安全的应用平台，Docker 容器是 Docker 的运行部分。</p><h2 id="二、Docker-安装"><a href="#二、Docker-安装" class="headerlink" title="二、Docker 安装"></a>二、Docker 安装</h2><p>docker 的相关安装方法这里不作介绍，具体安装参考 <a href="https://docs.docker.com/installation/" target="_blank" rel="noopener">官档</a></p><p>获取当前 docker 版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker version</span><br><span class="line">Client version: 1.3.2</span><br><span class="line">Client API version: 1.15</span><br><span class="line">Go version (client): go1.3.3</span><br><span class="line">Git commit (client): 39fa2fa/1.3.2</span><br><span class="line">OS/Arch (client): linux/amd64</span><br><span class="line">Server version: 1.3.2</span><br><span class="line">Server API version: 1.15</span><br><span class="line">Go version (server): go1.3.3</span><br><span class="line">Git commit (server): 39fa2fa/1.3.2</span><br></pre></td></tr></table></figure><h2 id="三、Docker-基础用法"><a href="#三、Docker-基础用法" class="headerlink" title="三、Docker 基础用法"></a>三、Docker 基础用法</h2><p><a href="https://registry.hub.docker.com/" target="_blank" rel="noopener">Docker HUB</a> : Docker镜像首页，包括官方镜像和其它公开镜像</p><p>因为国情的原因，国内下载 Docker HUB 官方的相关镜像比较慢，可以使用 <a href="http://opskumu.github.io/docker.cn" target="_blank" rel="noopener">docker.cn</a> 镜像，镜像保持和官方一致，关键是速度块，推荐使用。</p><h3 id="3-1-Search-images"><a href="#3-1-Search-images" class="headerlink" title="3.1 Search images"></a>3.1 Search images</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker search ubuntu</span><br></pre></td></tr></table></figure><h3 id="3-2-Pull-images"><a href="#3-2-Pull-images" class="headerlink" title="3.2 Pull images"></a>3.2 Pull images</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull ubuntu # 获取 ubuntu 官方镜像 $ sudo docker images # 查看当前镜像列表</span><br></pre></td></tr></table></figure><h3 id="3-3-Running-an-interactive-shell"><a href="#3-3-Running-an-interactive-shell" class="headerlink" title="3.3 Running an interactive shell"></a>3.3 Running an interactive shell</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -i -t ubuntu:14.04 /bin/bash</span><br></pre></td></tr></table></figure><ul><li>docker run - 运行一个容器</li><li>-t - 分配一个（伪）tty (link is external)</li><li>-i - 交互模式 (so we can interact with it)</li><li>ubuntu:14.04 - 使用 ubuntu 基础镜像 14.04</li><li>/bin/bash - 运行命令 bash shell</li></ul><p>注: ubuntu 会有多个版本，通过指定 tag 来启动特定的版本 [image]:[tag]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker ps # 查看当前运行的容器, ps -a 列出当前系统所有的容器 CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br><span class="line">6c9129e9df10        ubuntu:14.04        /bin/bash 6 minutes ago       Up 6 minutes                            cranky_babbage</span><br></pre></td></tr></table></figure><h2 id="四、Docker-命令帮助"><a href="#四、Docker-命令帮助" class="headerlink" title="四、Docker 命令帮助"></a>四、Docker 命令帮助</h2><h3 id="4-1-docker-help"><a href="#4-1-docker-help" class="headerlink" title="4.1 docker help"></a>4.1 docker help</h3><h4 id="docker-command"><a href="#docker-command" class="headerlink" title="docker command"></a>docker command</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker   # docker 命令帮助</span><br><span class="line"></span><br><span class="line">Commands:</span><br><span class="line">    attach    Attach to a running container                 # 当前 shell 下 attach 连接指定运行镜像</span><br><span class="line">    build     Build an image from a Dockerfile              # 通过 Dockerfile 定制镜像</span><br><span class="line">    commit    Create a new image from a container&apos;s changes # 提交当前容器为新的镜像</span><br><span class="line">    cp        Copy files/folders from the containers filesystem to the host path</span><br><span class="line">              # 从容器中拷贝指定文件或者目录到宿主机中</span><br><span class="line">    create    Create a new container                        # 创建一个新的容器，同 run，但不启动容器</span><br><span class="line">    diff      Inspect changes on a container&apos;s filesystem   # 查看 docker 容器变化</span><br><span class="line">    exec      Run a command in an existing container        # 在已存在的容器上运行命令</span><br><span class="line">    export    Stream the contents of a container as a tar archive   </span><br><span class="line">              # 导出容器的内容流作为一个 tar 归档文件[对应 import ]</span><br><span class="line">    history   Show the history of an image                  # 展示一个镜像形成历史</span><br><span class="line">    images    List images                                   # 列出系统当前镜像</span><br><span class="line">    import    Create a new filesystem image from the contents of a tarball  </span><br><span class="line">              # 从tar包中的内容创建一个新的文件系统映像[对应 export]</span><br><span class="line">    info      Display system-wide information               # 显示系统相关信息</span><br><span class="line">    inspect   Return low-level information on a container   # 查看容器详细信息</span><br><span class="line">    kill      Kill a running container                      # kill 指定 docker 容器</span><br><span class="line">    load      Load an image from a tar archive              # 从一个 tar 包中加载一个镜像[对应 save]</span><br><span class="line">    login     Register or Login to the docker registry server   </span><br><span class="line">              # 注册或者登陆一个 docker 源服务器</span><br><span class="line">    logout    Log out from a Docker registry server         # 从当前 Docker registry 退出</span><br><span class="line">    logs      Fetch the logs of a container                 # 输出当前容器日志信息</span><br><span class="line">    port      Lookup the public-facing port which is NAT-ed to PRIVATE_PORT</span><br><span class="line">              # 查看映射端口对应的容器内部源端口</span><br><span class="line">    pause     Pause all processes within a container        # 暂停容器</span><br><span class="line">    ps        List containers                               # 列出容器列表</span><br><span class="line">    pull      Pull an image or a repository from the docker registry server</span><br><span class="line">              # 从docker镜像源服务器拉取指定镜像或者库镜像</span><br><span class="line">    push      Push an image or a repository to the docker registry server</span><br><span class="line">              # 推送指定镜像或者库镜像至docker源服务器</span><br><span class="line">    restart   Restart a running container                   # 重启运行的容器</span><br><span class="line">    rm        Remove one or more containers                 # 移除一个或者多个容器</span><br><span class="line">    rmi       Remove one or more images                 </span><br><span class="line">              # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除]</span><br><span class="line">    run       Run a command in a new container</span><br><span class="line">              # 创建一个新的容器并运行一个命令</span><br><span class="line">    save      Save an image to a tar archive                # 保存一个镜像为一个 tar 包[对应 load]</span><br><span class="line">    search    Search for an image on the Docker Hub         # 在 docker hub 中搜索镜像</span><br><span class="line">    start     Start a stopped containers                    # 启动容器</span><br><span class="line">    stop      Stop a running containers                     # 停止容器</span><br><span class="line">    tag       Tag an image into a repository                # 给源中镜像打标签</span><br><span class="line">    top       Lookup the running processes of a container   # 查看容器中运行的进程信息</span><br><span class="line">    unpause   Unpause a paused container                    # 取消暂停容器</span><br><span class="line">    version   Show the docker version information           # 查看 docker 版本号</span><br><span class="line">    wait      Block until a container stops, then print its exit code   </span><br><span class="line">              # 截取容器停止时的退出状态值</span><br><span class="line">Run &apos;docker COMMAND --help&apos; for more information on a command.</span><br></pre></td></tr></table></figure><h4 id="docker-option"><a href="#docker-option" class="headerlink" title="docker option"></a>docker option</h4><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">Usage of docker:</span><br><span class="line">  --api-enable-cors=<span class="literal">false</span>                Enable CORS headers <span class="keyword">in</span> the remote API                      # 远程 API 中开启 CORS 头</span><br><span class="line">  -b, --bridge=<span class="string">""</span>                        Attach containers to a pre-existing network bridge         # 桥接网络</span><br><span class="line">                                           use 'none' to disable container networking</span><br><span class="line">  --bip=""                               Use this CIDR notation address for the network bridge's IP, not compatible with -b</span><br><span class="line">                                         # 和 -b 选项不兼容，具体没有测试过</span><br><span class="line">  -d, --daemon=<span class="literal">false</span>                     Enable daemon mode                                      # daemon 模式</span><br><span class="line">  -D, --<span class="keyword">debug</span>=<span class="literal">false</span>                      Enable <span class="keyword">debug</span> mode                                            # <span class="keyword">debug</span> 模式</span><br><span class="line">  --dns=[]                               Force docker to use specific DNS servers                   # 强制 docker 使用指定 dns 服务器</span><br><span class="line">  --dns-search=[]                        Force Docker to use specific DNS search domains            # 强制 docker 使用指定 dns 搜索域</span><br><span class="line">  -e, --exec-driver=<span class="string">"native"</span>             Force the docker runtime to use a specific exec driver     # 强制 docker 运行时使用指定执行驱动器</span><br><span class="line">  --fixed-cidr=<span class="string">""</span>                        IPv4 subnet <span class="keyword">for</span> fixed IPs (ex: <span class="number">10.20</span>.0.0/<span class="number">16</span>)</span><br><span class="line">                                           <span class="keyword">this</span> subnet must be nested <span class="keyword">in</span> the bridge subnet (which <span class="keyword">is</span> defined by -b or --bip)</span><br><span class="line">  -G, --group=<span class="string">"docker"</span>                   Group to assign the unix socket specified by -H when running <span class="keyword">in</span> daemon mode</span><br><span class="line">                                           use '' (the empty string) to disable setting of a group</span><br><span class="line">  -g, --graph=<span class="string">"/var/lib/docker"</span>          Path to use as the root of the docker runtime              # 容器运行的根目录路径</span><br><span class="line">  -H, --host=[]                          The socket(s) to bind to <span class="keyword">in</span> daemon mode                    # daemon 模式下 docker 指定绑定方式[tcp or 本地 socket]</span><br><span class="line">                                           specified using one or more tcp:<span class="comment">//host:port, unix:///path/to/socket, fd://* or fd://socketfd.</span></span><br><span class="line">  --icc=<span class="literal">true</span>                             Enable inter-container communication                       # 跨容器通信</span><br><span class="line">  --insecure-registry=[]                 Enable insecure communication <span class="keyword">with</span> specified registries (no certificate verification <span class="keyword">for</span> HTTPS and enable HTTP fallback) (e.g., localhost:<span class="number">5000</span> or <span class="number">10.20</span>.0.0/<span class="number">16</span>)</span><br><span class="line">  --ip=<span class="string">"0.0.0.0"</span>                         Default IP address to use when binding container ports     # 指定监听地址，默认所有 ip</span><br><span class="line">  --ip-forward=<span class="literal">true</span>                      Enable net.ipv4.ip_forward                                 # 开启转发</span><br><span class="line">  --ip-masq=true                         Enable IP masquerading for bridge's IP range</span><br><span class="line">  --iptables=true                        Enable Docker's addition of iptables rules                 # 添加对应 iptables 规则</span><br><span class="line">  --mtu=<span class="number">0</span>                                Set the containers network MTU                             # 设置网络 mtu</span><br><span class="line">                                           <span class="keyword">if</span> no value <span class="keyword">is</span> provided: <span class="keyword">default</span> to the <span class="keyword">default</span> route MTU or <span class="number">1500</span> <span class="keyword">if</span> no <span class="keyword">default</span> route <span class="keyword">is</span> available</span><br><span class="line">  -p, --pidfile=<span class="string">"/var/run/docker.pid"</span>    Path to use <span class="keyword">for</span> daemon PID file                            # 指定 pid 文件位置</span><br><span class="line">  --registry-mirror=[]                   Specify a preferred Docker registry mirror                  </span><br><span class="line">  -s, --storage-driver=<span class="string">""</span>                Force the docker runtime to use a specific storage driver  # 强制 docker 运行时使用指定存储驱动</span><br><span class="line">  --selinux-enabled=<span class="literal">false</span>                Enable selinux support                                     # 开启 selinux 支持</span><br><span class="line">  --storage-opt=[]                       Set storage driver options                                 # 设置存储驱动选项</span><br><span class="line">  --tls=<span class="literal">false</span>                            Use TLS; implied by tls-verify flags                       # 开启 tls</span><br><span class="line">  --tlscacert=<span class="string">"/root/.docker/ca.pem"</span>     Trust only remotes providing a certificate signed by the CA given here</span><br><span class="line">  --tlscert=<span class="string">"/root/.docker/cert.pem"</span>     Path to TLS certificate file                               # tls 证书文件位置</span><br><span class="line">  --tlskey=<span class="string">"/root/.docker/key.pem"</span>       Path to TLS key file                                       # tls key 文件位置</span><br><span class="line">  --tlsverify=<span class="literal">false</span>                      Use TLS and verify the remote (daemon: verify client, client: verify daemon) # 使用 tls 并确认远程控制主机</span><br><span class="line">  -v, --<span class="keyword">version</span>=<span class="literal">false</span>                    Print <span class="keyword">version</span> information and quit                         # 输出 docker 版本信息</span><br></pre></td></tr></table></figure><h3 id="4-2-docker-search"><a href="#4-2-docker-search" class="headerlink" title="4.2 docker search"></a>4.2 docker search</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker search --help</span><br><span class="line"></span><br><span class="line">Usage: docker search TERM</span><br><span class="line"></span><br><span class="line">Search the Docker Hub for images # 从 Docker Hub 搜索镜像 --automated=false Only show automated builds</span><br><span class="line">  --no-trunc=false Don&apos;t truncate output</span><br><span class="line">  -s, --stars=0 Only displays with at least xxx stars</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker search -s 100 ubuntu # 查找 star 数至少为 100 的镜像，找出只有官方镜像 start 数超过 100，默认不加 s 选项找出所有相关 ubuntu 镜像 NAME      DESCRIPTION                  STARS     OFFICIAL   AUTOMATED</span><br><span class="line">ubuntu    Official Ubuntu base image 425 [OK]</span><br></pre></td></tr></table></figure><h3 id="4-3-docker-info"><a href="#4-3-docker-info" class="headerlink" title="4.3 docker info"></a>4.3 docker info</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker info </span><br><span class="line">Containers: 1 # 容器个数 Images: 22 # 镜像个数 Storage Driver: devicemapper # 存储驱动 Pool Name: docker-8:17-3221225728-pool</span><br><span class="line"> Pool Blocksize: 65.54 kB</span><br><span class="line"> Data file: /data/docker/devicemapper/devicemapper/data</span><br><span class="line"> Metadata file: /data/docker/devicemapper/devicemapper/metadata</span><br><span class="line"> Data Space Used: 1.83 GB</span><br><span class="line"> Data Space Total: 107.4 GB</span><br><span class="line"> Metadata Space Used: 2.191 MB</span><br><span class="line"> Metadata Space Total: 2.147 GB</span><br><span class="line"> Library Version: 1.02.84-RHEL7 (2014-03-26) Execution Driver: native-0.2 # 存储驱动 Kernel Version: 3.10.0-123.el7.x86_64</span><br><span class="line">Operating System: CentOS Linux 7 (Core)</span><br></pre></td></tr></table></figure><h3 id="4-4-docker-pull-amp-amp-docker-push"><a href="#4-4-docker-pull-amp-amp-docker-push" class="headerlink" title="4.4 docker pull &amp;&amp; docker push"></a>4.4 docker pull &amp;&amp; docker push</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull --help # pull 拉取镜像 Usage: docker pull [OPTIONS] NAME[:TAG] Pull an image or a repository from the registry</span><br><span class="line"></span><br><span class="line">  -a, --all-tags=false Download all tagged images in the repository $ sudo docker push # push 推送指定镜像 Usage: docker push NAME[:TAG] Push an image or a repository to the registry</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker pull ubuntu # 下载官方 ubuntu docker 镜像，默认下载所有 ubuntu 官方库镜像 $ sudo docker pull ubuntu:14.04 # 下载指定版本 ubuntu 官方镜像</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker push 192.168.0.100:5000/ubuntu # 推送镜像库到私有源[可注册 docker 官方账户，推送到官方自有账户] $ sudo docker push 192.168.0.100:5000/ubuntu:14.04 # 推送指定镜像到私有源</span><br></pre></td></tr></table></figure><h3 id="4-5-docker-images"><a href="#4-5-docker-images" class="headerlink" title="4.5 docker images"></a>4.5 docker images</h3><p>列出当前系统镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker images --help</span><br><span class="line"></span><br><span class="line">Usage: docker images [OPTIONS] [NAME] List images</span><br><span class="line"></span><br><span class="line">  -a, --all=false Show all images (by default filter out the intermediate image layers) # -a 显示当前系统的所有镜像，包括过渡层镜像，默认 docker images 显示最终镜像，不包括过渡层镜像 -f, --filter=[] Provide filter values (i.e. &apos;dangling=true&apos;) --no-trunc=false Don&apos;t truncate output</span><br><span class="line">  -q, --quiet=false Only show numeric IDs</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker images # 显示当前系统镜像，不包括过渡层镜像 $ sudo docker images -a # 显示当前系统所有镜像，包括过渡层镜像 $ sudo docker images ubuntu # 显示当前系统 docker ubuntu 库中的所有镜像 REPOSITORY                 TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span><br><span class="line">ubuntu                     12.04               ebe4be4dd427 4 weeks ago         210.6 MB</span><br><span class="line">ubuntu                     14.04               e54ca5efa2e9 4 weeks ago         276.5 MB</span><br><span class="line">ubuntu                     14.04-ssh           6334d3ac099a 7 weeks ago         383.2 MB</span><br></pre></td></tr></table></figure><h3 id="4-6-docker-rmi"><a href="#4-6-docker-rmi" class="headerlink" title="4.6 docker rmi"></a>4.6 docker rmi</h3><p>删除一个或者多个镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker rmi --help</span><br><span class="line"></span><br><span class="line">Usage: docker rmi IMAGE [IMAGE...] Remove one or more images</span><br><span class="line"></span><br><span class="line">  -f, --force=false Force removal of the image # 强制移除镜像不管是否有容器使用该镜像 --no-prune=false Do not delete untagged parents # 不要删除未标记的父镜像 </span><br><span class="line">  </span><br><span class="line">$ sudo docker rm `docker ps -a -q`    !!!批量清除所有容器</span><br></pre></td></tr></table></figure><h3 id="4-7-docker-run"><a href="#4-7-docker-run" class="headerlink" title="4.7 docker run"></a>4.7 docker run</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --help</span><br><span class="line"></span><br><span class="line">Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] Run a command in a new container</span><br><span class="line"></span><br><span class="line">  -a, --attach=[] Attach to stdin, stdout or stderr.</span><br><span class="line">  -c, --cpu-shares=0 CPU shares (relative weight) # 设置 cpu 使用权重 --cap-add=[] Add Linux capabilities</span><br><span class="line">  --cap-drop=[] Drop Linux capabilities</span><br><span class="line">  --cidfile=&quot;&quot; Write the container ID to the file # 把容器 id 写入到指定文件 </span><br><span class="line">  --cpuset=&quot;&quot; CPUs in which to allow execution (0-3, 0,1) # cpu 绑定 </span><br><span class="line">  -d, --detach=false Detached mode: Run container in the background, print new container id # 后台运行容器 --device=[] Add a host device to the container (e.g. --device=/dev/sdc:/dev/xvdc) </span><br><span class="line">  --dns=[] Set custom dns servers # 设置 dns --dns-search=[] Set custom dns search domains # 设置 dns 域搜索 </span><br><span class="line">  -e, --env=[] Set environment variables # 定义环境变量 --entrypoint=&quot;&quot; Overwrite the default entrypoint of the image # ？ </span><br><span class="line">  --env-file=[] Read in a line delimited file of ENV variables # 从指定文件读取变量值 --expose=[] Expose a port from the container without publishing it to your host # 指定对外提供服务端口 </span><br><span class="line">  -h, --hostname=&quot;&quot; Container host name # 设置容器主机名 </span><br><span class="line">  -i, --interactive=false Keep stdin open even if not attached # 保持标准输出开启即使没有 attached --link=[] Add link to another container (name:alias) # 添加链接到另外一个容器 --lxc-conf=[] (lxc exec-driver only) Add custom lxc options --lxc-conf=&quot;lxc.cgroup.cpuset.cpus = 0,1&quot; </span><br><span class="line">  -m, --memory=&quot;&quot; Memory limit (format: &lt;number&gt;&lt;optional unit&gt;, where unit = b, k, m or g) # 内存限制 </span><br><span class="line">  --name=&quot;&quot; Assign a name to the container # 设置容器名 </span><br><span class="line">  --net=&quot;bridge&quot; Set the Network mode for the container # 设置容器网络模式 &apos;bridge&apos;: creates a new network stack for the container on the docker bridge &apos;none&apos;: no networking for this container &apos;container:&lt;name|id&gt;&apos;: reuses another container network stack &apos;host&apos;: use the host network stack inside the container.  Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure.</span><br><span class="line">  -P, --publish-all=false Publish all exposed ports to the host interfaces # 自动映射容器对外提供服务的端口 -p, --publish=[] Publish a container&apos;s port to the host             # 指定端口映射  format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort  (use &apos;docker port&apos; to see the actual mapping) </span><br><span class="line">  --privileged=false Give extended privileges to this container # 提供更多的权限给容器 --restart=&quot;&quot; Restart policy to apply when a container exits (no, on-failure[:max-retry], always) </span><br><span class="line">  --rm=false Automatically remove the container when it exits (incompatible with -d) # 如果容器退出自动移除和 -d 选项冲突 --security-opt=[] Security Options</span><br><span class="line">  --sig-proxy=true Proxify received signals to the process (even in non-tty mode). SIGCHLD is not proxied.</span><br><span class="line">  -t, --tty=false Allocate a pseudo-tty # 分配伪终端 </span><br><span class="line">  -u, --user=&quot;&quot; Username or UID # 指定运行容器的用户 uid 或者用户名</span><br><span class="line">  -v, --volume=[] Bind mount a volume (e.g., from the host: -v /host:/container, from docker: -v /container) # 挂载卷 --volumes-from=[] Mount volumes from the specified container(s) # 从指定容器挂载卷 </span><br><span class="line">  -w, --workdir=&quot;&quot; Working directory inside the container # 指定容器工作目录</span><br></pre></td></tr></table></figure><p>示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker images ubuntu</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE</span><br><span class="line">ubuntu              14.04               e54ca5efa2e9 4 weeks ago         276.5 MB</span><br><span class="line">... ... </span><br><span class="line">$ sudo docker run -t -i -c 100 -m 512MB -h test1 -d --name=&quot;docker_test1&quot; ubuntu /bin/bash # 创建一个 cpu 优先级为 100，内存限制 512MB，主机名为 test1，名为 docker_test1 后台运行 bash 的容器 a424ca613c9f2247cd3ede95adfbaf8d28400cbcb1d5f9b69a7b56f97b2b52e5 </span><br><span class="line">$ sudo docker ps </span><br><span class="line">CONTAINER ID        IMAGE           COMMAND         CREATED             STATUS              PORTS       NAMES</span><br><span class="line">a424ca613c9f        ubuntu:14.04    /bin/bash 6 seconds ago       Up 5 seconds                    docker_test1 </span><br><span class="line">$ sudo docker attach docker_test1</span><br><span class="line">root@test1:/# pwd /</span><br><span class="line">root@test1:/# exit exit</span><br></pre></td></tr></table></figure><h3 id="4-8-docker-start-stop-kill…-…"><a href="#4-8-docker-start-stop-kill…-…" class="headerlink" title="4.8 docker start|stop|kill… …"></a>4.8 docker start|stop|kill… …</h3><p>dockerstart|stop|kill|restart|pause|unpause|rm|commit|inspect|logs</p><ul><li><p>docker start CONTAINER [CONTAINER…]</p><ul><li># 运行一个或多个停止的容器</li></ul></li><li><p>docker stop CONTAINER [CONTAINER…]</p><p>​</p><ul><li># 停掉一个或多个运行的容器-t选项可指定超时时间</li></ul></li><li><p>docker kill [OPTIONS] CONTAINER [CONTAINER…]</p><ul><li># 默认 kill 发送 SIGKILL 信号-s可以指定发送 kill 信号类型</li></ul></li><li><p>docker restart [OPTIONS] CONTAINER [CONTAINER…]</p><ul><li># 重启一个或多个运行的容器-t选项可指定超时时间</li></ul></li><li><p>docker pause CONTAINER</p><ul><li># 暂停一个容器，方便 commit</li></ul></li><li><p>docker unpause CONTAINER</p><ul><li># 继续暂停的容器</li></ul></li><li><p>docker rm [OPTIONS] CONTAINER [CONTAINER…]</p><p>​</p><ul><li># 移除一个或多个容器</li><li>-f, –force=false Force removal of running container</li><li>-l, –link=false Remove the specified link and not the underlying container</li><li>-v, –volumes=false Remove the volumes associated with the container</li></ul></li><li><p>docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</p><p>​</p><ul><li># 提交指定容器为镜像</li><li>-a, –author=”” Author (e.g., “John Hannibal Smith <a href="mailto:hannibal@a-team.com" target="_blank" rel="noopener">hannibal@a-team.com</a>“)</li><li>-m, –message=”” Commit message</li><li>-p, –pause=true Pause container during commit<ul><li># 默认 commit 是暂停状态</li></ul></li></ul></li><li><p>docker inspect CONTAINER|IMAGE [CONTAINER|IMAGE…]</p><p>​</p><ul><li># 查看容器或者镜像的详细信息</li></ul></li><li><p>docker logs CONTAINER</p><ul><li># 输出指定容器日志信息</li><li>-f, –follow=false Follow log output<ul><li># 类似 tail -f</li></ul></li><li>-t, –timestamps=false Show timestamps</li><li>–tail=”all” Output the specified number of lines at the end of logs (defaults to all logs)</li></ul></li></ul><p>参考文档：<a href="https://docs.docker.com/reference/run/" target="_blank" rel="noopener">Docker Run Reference</a></p><h2 id="五、Docker-端口映射"><a href="#五、Docker-端口映射" class="headerlink" title="五、Docker 端口映射"></a>五、Docker 端口映射</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Find IP address of container with ID &lt;container_id&gt; 通过容器 id 获取 ip </span><br><span class="line">$ sudo docker inspect &lt;container_id&gt; | grep IPAddress | cut -d ’&quot;’ -f 4</span><br></pre></td></tr></table></figure><p>无论如何，这些 ip 是基于本地系统的并且容器的端口非本地主机是访问不到的。此外，除了端口只能本地访问外，对于容器的另外一个问题是这些 ip 在容器每次启动的时候都会改变。</p><p>Docker 解决了容器的这两个问题，并且给容器内部服务的访问提供了一个简单而可靠的方法。Docker 通过端口绑定主机系统的接口，允许非本地客户端访问容器内部运行的服务。为了简便的使得容器间通信，Docker 提供了这种连接机制。</p><h3 id="5-1-自动映射端口"><a href="#5-1-自动映射端口" class="headerlink" title="5.1 自动映射端口"></a>5.1 自动映射端口</h3><p>-P使用时需要指定–expose选项，指定需要对外提供服务的端口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -P --expose 22 --name server  ubuntu:14.04</span><br></pre></td></tr></table></figure><p>使用docker run -P自动绑定所有对外提供服务的容器端口，映射的端口将会从没有使用的端口池中 (49000..49900) 自动选择，你可以通过docker ps、docker inspect &lt;container_id&gt;或者docker port &lt;container_id&gt;<port>确定具体的绑定信息。</port></p><h3 id="5-2-绑定端口到指定接口"><a href="#5-2-绑定端口到指定接口" class="headerlink" title="5.2 绑定端口到指定接口"></a>5.2 绑定端口到指定接口</h3><p>基本语法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -p [([&lt;host_interface&gt;:[host_port]])|(&lt;host_port&gt;):]&lt;container_port&gt;[/udp] &lt;image&gt; &lt;cmd&gt;</span><br></pre></td></tr></table></figure><p>默认不指定绑定 ip 则监听所有网络接口。</p><h4 id="绑定-TCP-端口"><a href="#绑定-TCP-端口" class="headerlink" title="绑定 TCP 端口"></a>绑定 TCP 端口</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Bind TCP port 8080 of the container to TCP port 80 on 127.0.0.1 of the host machine. </span><br><span class="line">$ sudo docker run -p 127.0.0.1:80:8080 &lt;image&gt; &lt;cmd&gt; # Bind TCP port 8080 of the container to a dynamically allocated TCP port on 127.0.0.1 of the host machine. </span><br><span class="line">$ sudo docker run -p 127.0.0.1::8080 &lt;image&gt; &lt;cmd&gt; # Bind TCP port 8080 of the container to TCP port 80 on all available interfaces of the host machine. </span><br><span class="line">$ sudo docker run -p 80:8080 &lt;image&gt; &lt;cmd&gt; # Bind TCP port 8080 of the container to a dynamically allocated TCP port on all available interfaces</span><br><span class="line">$ sudo docker run -p 8080 &lt;image&gt; &lt;cmd&gt;</span><br></pre></td></tr></table></figure><h4 id="绑定-UDP-端口"><a href="#绑定-UDP-端口" class="headerlink" title="绑定 UDP 端口"></a>绑定 UDP 端口</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Bind UDP port 5353 of the container to UDP port 53 on 127.0.0.1 of the host machine. </span><br><span class="line">$ sudo docker run -p 127.0.0.1:53:5353/udp &lt;image&gt; &lt;cmd&gt;</span><br></pre></td></tr></table></figure><h2 id="六、Docker-网络配置"><a href="#六、Docker-网络配置" class="headerlink" title="六、Docker 网络配置"></a>六、Docker 网络配置</h2><p><img src="http://static.open-open.com/lib/uploadImg/20150212/20150212091034_634.png" alt="非常详细的 Docker 学习笔记"></p><p>图: <a href="http://www.slideshare.net/janghoonsim/docker-container-and-lightweight-virtualization" target="_blank" rel="noopener">Docker - container and lightweight virtualization</a></p><p>Dokcer 通过使用 Linux 桥接提供容器之间的通信，docker0 桥接接口的目的就是方便 Docker 管理。当 Docker daemon 启动时需要做以下操作：</p><ul><li>creates the docker0 bridge if not present<ul><li># 如果 docker0 不存在则创建</li></ul></li><li>searches for an IP address range which doesn’t overlap with an existing route<ul><li># 搜索一个与当前路由不冲突的 ip 段</li></ul></li><li>picks an IP in the selected range<ul><li># 在确定的范围中选择 ip</li></ul></li><li>assigns this IP to the docker0 bridge<ul><li># 绑定 ip 到 docker0</li></ul></li></ul><h3 id="6-1-Docker-四种网络模式"><a href="#6-1-Docker-四种网络模式" class="headerlink" title="6.1 Docker 四种网络模式"></a>6.1 Docker 四种网络模式</h3><p>四种网络模式摘自 <a href="http://www.infoq.com/cn/articles/docker-network-and-pipework-open-source-explanation-practice" target="_blank" rel="noopener">Docker 网络详解及 pipework 源码解读与实践</a></p><p>docker run 创建 Docker 容器时，可以用 –net 选项指定容器的网络模式，Docker 有以下 4 种网络模式：</p><ul><li>host 模式，使用 –net=host 指定。</li><li>container 模式，使用 –net=container:NAMEorID 指定。</li><li>none 模式，使用 –net=none 指定。</li><li>bridge 模式，使用 –net=bridge 指定，默认设置。</li></ul><h4 id="host-模式"><a href="#host-模式" class="headerlink" title="host 模式"></a>host 模式</h4><p>如果启动容器的时候使用 host 模式，那么这个容器将不会获得一个独立的 Network Namespace，而是和宿主机共用一个 Network Namespace。容器将不会虚拟出自己的网卡，配置自己的 IP 等，而是使用宿主机的 IP 和端口。</p><p>例如，我们在 10.10.101.105/24 的机器上用 host 模式启动一个含有 web 应用的 Docker 容器，监听 tcp 80 端口。当我们在容器中执行任何类似 ifconfig 命令查看网络环境时，看到的都是宿主机上的信息。而外界访问容器中的应用，则直接使用 10.10.101.105:80 即可，不用任何 NAT 转换，就如直接跑在宿主机中一样。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。</p><h4 id="container-模式"><a href="#container-模式" class="headerlink" title="container 模式"></a>container 模式</h4><p>这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。</p><h4 id="none模式"><a href="#none模式" class="headerlink" title="none模式"></a>none模式</h4><p>这个模式和前两个不同。在这种模式下，Docker 容器拥有自己的 Network Namespace，但是，并不为 Docker容器进行任何网络配置。也就是说，这个 Docker 容器没有网卡、IP、路由等信息。需要我们自己为 Docker 容器添加网卡、配置 IP 等。</p><h4 id="bridge模式"><a href="#bridge模式" class="headerlink" title="bridge模式"></a>bridge模式</h4><p><img src="http://static.open-open.com/lib/uploadImg/20150212/20150212091035_252.png" alt="非常详细的 Docker 学习笔记"></p><p>图:<a href="http://www.wickedawesometech.us/2014/07/the-container-world-part-2-networking.html" target="_blank" rel="noopener">The Container World | Part 2 Networking</a></p><p>bridge 模式是 Docker 默认的网络设置，此模式会为每一个容器分配 Network Namespace、设置 IP 等，并将一个主机上的 Docker 容器连接到一个虚拟网桥上。当 Docker server 启动时，会在主机上创建一个名为 docker0 的虚拟网桥，此主机上启动的 Docker 容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。接下来就要为容器分配 IP 了，Docker 会从 RFC1918 所定义的私有 IP 网段中，选择一个和宿主机不同的IP地址和子网分配给 docker0，连接到 docker0 的容器就从这个子网中选择一个未占用的 IP 使用。如一般 Docker 会使用 172.17.0.0/16 这个网段，并将 172.17.42.1/16 分配给 docker0 网桥（在主机上使用 ifconfig 命令是可以看到 docker0 的，可以认为它是网桥的管理接口，在宿主机上作为一块虚拟网卡使用）</p><h3 id="6-2-列出当前主机网桥"><a href="#6-2-列出当前主机网桥" class="headerlink" title="6.2 列出当前主机网桥"></a>6.2 列出当前主机网桥</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo brctl show # brctl 工具依赖 bridge-utils 软件包 bridge name bridge id STP enabled interfaces</span><br><span class="line">docker0 8000.000000000000 no</span><br></pre></td></tr></table></figure><h3 id="6-3-查看当前-docker0-ip"><a href="#6-3-查看当前-docker0-ip" class="headerlink" title="6.3 查看当前 docker0 ip"></a>6.3 查看当前 docker0 ip</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ifconfig docker0</span><br><span class="line">docker0 Link encap:Ethernet HWaddr xx:xx:xx:xx:xx:xx</span><br><span class="line">inet addr:172.17.42.1 Bcast:0.0.0.0 Mask:255.255.0.0</span><br></pre></td></tr></table></figure><p>在容器运行时，每个容器都会分配一个特定的虚拟机口并桥接到 docker0。每个容器都会配置同 docker0 ip 相同网段的专用 ip 地址，docker0 的 IP 地址被用于所有容器的默认网关。</p><h3 id="6-4-运行一个容器"><a href="#6-4-运行一个容器" class="headerlink" title="6.4 运行一个容器"></a>6.4 运行一个容器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i -d ubuntu /bin/bash</span><br><span class="line">52f811c5d3d69edddefc75aff5a4525fc8ba8bcfa1818132f9dc7d4f7c7e78b4</span><br><span class="line">$ sudo brctl show</span><br><span class="line">bridge name bridge id STP enabled interfaces</span><br><span class="line">docker0 8000.fef213db5a66 no vethQCDY1N</span><br></pre></td></tr></table></figure><p>以上, docker0 扮演着 52f811c5d3d6 container 这个容器的虚拟接口 vethQCDY1N interface 桥接的角色。</p><h4 id="使用特定范围的-IP"><a href="#使用特定范围的-IP" class="headerlink" title="使用特定范围的 IP"></a>使用特定范围的 IP</h4><p>Docker 会尝试寻找没有被主机使用的 ip 段，尽管它适用于大多数情况下，但是它不是万能的，有时候我们还是需要对 ip 进一步规划。Docker 允许你管理 docker0 桥接或者通过-b选项自定义桥接网卡，需要安装bridge-utils软件包。</p><p>基本步骤如下：</p><ul><li><p>ensure Docker is stopped</p><p>​</p><ul><li># 确保 docker 的进程是停止的</li></ul></li><li><p>create your own bridge (bridge0 for example)</p><ul><li># 创建自定义网桥</li></ul></li><li><p>assign a specific IP to this bridge</p><p>​</p><ul><li># 给网桥分配特定的 ip</li></ul></li><li><p>start Docker with the -b=bridge0 parameter</p><ul><li># 以 -b 的方式指定网桥</li></ul></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Stopping Docker and removing docker0 $ sudo service docker stop $ sudo ip link set dev docker0 down $ sudo brctl delbr docker0 # Create our own bridge $ sudo brctl addbr bridge0 $ sudo ip addr add 192.168.5.1/24 dev bridge0 $ sudo ip link set dev bridge0 up # Confirming that our bridge is up and running $ ip addr show bridge0</span><br><span class="line">4: bridge0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state UP group default</span><br><span class="line">    link/ether 66:38:d0:0d:76:18 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.5.1/24 scope global bridge0</span><br><span class="line">       valid_lft forever preferred_lft forever # Tell Docker about it and restart (on Ubuntu) $ echo &apos;DOCKER_OPTS=&quot;-b=bridge0&quot;&apos; &gt;&gt; /etc/default/docker $ sudo service docker start</span><br></pre></td></tr></table></figure><p>参考文档: <a href="https://docs.docker.com/articles/networking/" target="_blank" rel="noopener">Network Configuration</a></p><h3 id="6-5-不同主机间容器通信"><a href="#6-5-不同主机间容器通信" class="headerlink" title="6.5 不同主机间容器通信"></a>6.5 不同主机间容器通信</h3><p>不同容器之间的通信可以借助于 pipework 这个工具：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/jpetazzo/pipework.git</span><br><span class="line">$ sudo cp -rp pipework/pipework /usr/local/bin/</span><br></pre></td></tr></table></figure><h4 id="安装相应依赖软件"><a href="#安装相应依赖软件" class="headerlink" title="安装相应依赖软件"></a>安装相应依赖软件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install iputils-arping bridge-utils -y</span><br></pre></td></tr></table></figure><h4 id="桥接网络"><a href="#桥接网络" class="headerlink" title="桥接网络"></a>桥接网络</h4><p>桥接网络可以参考 <a href="https://github.com/opskumu/Day/blob/master/tips/tips.md" target="_blank" rel="noopener">日常问题处理 Tips</a> 关于桥接的配置说明，这里不再赘述。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># brctl show</span><br><span class="line">bridge name     bridge id               STP enabled     interfaces</span><br><span class="line">br0             8000.000c291412cd       no              eth0</span><br><span class="line">docker0         8000.56847afe9799       no              vetheb48029</span><br></pre></td></tr></table></figure><p>可以删除 docker0，直接把 docker 的桥接指定为 br0。也可以保留使用默认的配置，这样单主机容器之间的通信可以通过 docker0，而跨主机不同容器之间通过 pipework 新建 docker 容器的网卡桥接到 br0，这样跨主机容器之间就可以通信了。</p><ul><li>ubuntu</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo service docker stop</span><br><span class="line">$ sudo ip link set dev docker0 down</span><br><span class="line">$ sudo brctl delbr docker0</span><br><span class="line">$ echo &apos;DOCKER_OPTS=&quot;-b=br0&quot;&apos; &gt;&gt; /etc/default/docker</span><br><span class="line">$ sudo service docker start</span><br></pre></td></tr></table></figure><ul><li>CentOS 7/RHEL 7</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo systemctl stop docker</span><br><span class="line">$ sudo ip link set dev docker0 down</span><br><span class="line">$ sudo brctl delbr docker0</span><br><span class="line">$ cat /etc/sysconfig/docker | grep &apos;OPTIONS=&apos;</span><br><span class="line">OPTIONS=--selinux-enabled -b=br0 -H fd://</span><br><span class="line">$ sudo systemctl start docker</span><br></pre></td></tr></table></figure><h4 id="pipework"><a href="#pipework" class="headerlink" title="pipework"></a>pipework</h4><p><img src="http://static.open-open.com/lib/uploadImg/20150212/20150212091035_900.png" alt="非常详细的 Docker 学习笔记"></p><p>不同容器之间的通信可以借助于 pipework 这个工具给 docker 容器新建虚拟网卡并绑定 IP 桥接到 br0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/jpetazzo/pipework.git</span><br><span class="line">$ sudo cp -rp pipework/pipework /usr/local/bin/</span><br><span class="line">$ pipework </span><br><span class="line">Syntax:</span><br><span class="line">pipework &lt;hostinterface&gt; [-i containerinterface] &lt;guest&gt; &lt;ipaddr&gt;/&lt;subnet&gt;[@default_gateway] [macaddr][@vlan]</span><br><span class="line">pipework &lt;hostinterface&gt; [-i containerinterface] &lt;guest&gt; dhcp [macaddr][@vlan]</span><br><span class="line">pipework --wait [-i containerinterface]</span><br></pre></td></tr></table></figure><p>如果删除了默认的 docker0 桥接，把 docker 默认桥接指定到了 br0，则最好在创建容器的时候加上–net=none，防止自动分配的 IP 在局域网中有冲突。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --rm -ti --net=none ubuntu:14.04 /bin/bash</span><br><span class="line">root@a46657528059:/#</span><br><span class="line">$                  # Ctrl-P + Ctrl-Q 回到宿主机 shell，容器 detach 状态</span><br><span class="line">$ sudo docker  ps</span><br><span class="line">CONTAINER ID    IMAGE          COMMAND       CREATED         STATUS          PORTS      NAMES</span><br><span class="line">a46657528059    ubuntu:14.04   &quot;/bin/bash&quot;   4 minutes ago   Up 4 minutes               hungry_lalande</span><br><span class="line">$ sudo pipework br0 -i eth0 a46657528059 192.168.115.10/24@192.168.115.2 </span><br><span class="line"># 默认不指定网卡设备名，则默认添加为 eth1</span><br><span class="line"># 另外 pipework 不能添加静态路由，如果有需求则可以在 run 的时候加上 --privileged=true 权限在容器中手动添加，</span><br><span class="line"># 但这种安全性有缺陷，可以通过 ip netns 操作</span><br><span class="line">$ sudo docker attach a46657528059</span><br><span class="line">root@a46657528059:/# ifconfig eth0</span><br><span class="line">eth0      Link encap:Ethernet  HWaddr 86:b6:6b:e8:2e:4d  </span><br><span class="line">          inet addr:192.168.115.10  Bcast:0.0.0.0  Mask:255.255.255.0</span><br><span class="line">          inet6 addr: fe80::84b6:6bff:fee8:2e4d/64 Scope:Link</span><br><span class="line">          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1</span><br><span class="line">          RX packets:8 errors:0 dropped:0 overruns:0 frame:0</span><br><span class="line">          TX packets:9 errors:0 dropped:0 overruns:0 carrier:0</span><br><span class="line">          collisions:0 txqueuelen:1000 </span><br><span class="line">          RX bytes:648 (648.0 B)  TX bytes:690 (690.0 B)</span><br><span class="line"></span><br><span class="line">root@a46657528059:/# route -n</span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.115.2   0.0.0.0         UG    0      0        0 eth0</span><br><span class="line">192.168.115.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0</span><br></pre></td></tr></table></figure><p>使用ip netns添加静态路由，避免创建容器使用–privileged=true选项造成一些不必要的安全问题：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker inspect --format=&quot;&#123;&#123; .State.Pid &#125;&#125;&quot; a46657528059 # 获取指定容器 pid</span><br><span class="line">6350</span><br><span class="line">$ sudo ln -s /proc/6350/ns/net /var/run/netns/6350</span><br><span class="line">$ sudo ip netns exec 6350 ip route add 192.168.0.0/16 dev eth0 via 192.168.115.2</span><br><span class="line">$ sudo ip netns exec 6350 ip route    # 添加成功</span><br><span class="line">192.168.0.0/16 via 192.168.115.2 dev eth0 </span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><p>在其它宿主机进行相应的配置，新建容器并使用 pipework 添加虚拟网卡桥接到 br0，测试通信情况即可。</p><p>另外，pipework 可以创建容器的 vlan 网络，这里不作过多的介绍了，官方文档已经写的很清楚了，可以查看以下两篇文章：</p><ul><li><a href="https://github.com/jpetazzo/pipework" target="_blank" rel="noopener">Pipework 官方文档</a></li><li><a href="http://www.infoq.com/cn/articles/docker-network-and-pipework-open-source-explanation-practice" target="_blank" rel="noopener">Docker 网络详解及 pipework 源码解读与实践</a></li></ul><h2 id="七、Dockerfile"><a href="#七、Dockerfile" class="headerlink" title="七、Dockerfile"></a>七、Dockerfile</h2><p>Docker 可以通过 Dockerfile 的内容来自动构建镜像。Dockerfile 是一个包含创建镜像所有命令的文本文件，通过docker build命令可以根据 Dockerfile 的内容构建镜像，在介绍如何构建之前先介绍下 Dockerfile 的基本语法结构。</p><p>Dockerfile 有以下指令选项:</p><ul><li>FROM</li><li>MAINTAINER</li><li>RUN</li><li>CMD</li><li>EXPOSE</li><li>ENV</li><li>ADD</li><li>COPY</li><li>ENTRYPOINT</li><li>VOLUME</li><li>USER</li><li>WORKDIR</li><li>ONBUILD</li></ul><h3 id="7-1-FROM"><a href="#7-1-FROM" class="headerlink" title="7.1 FROM"></a>7.1 FROM</h3><p>用法:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;</span><br></pre></td></tr></table></figure><p>或者</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &lt;image&gt;</span><br></pre></td></tr></table></figure><ul><li>FROM指定构建镜像的基础源镜像，如果本地没有指定的镜像，则会自动从 Docker 的公共库 pull 镜像下来。</li><li>FROM必须是 Dockerfile 中非注释行的第一个指令，即一个 Dockerfile 从FROM语句开始。</li><li>FROM可以在一个 Dockerfile 中出现多次，如果有需求在一个 Dockerfile 中创建多个镜像。</li><li>如果FROM语句没有指定镜像标签，则默认使用latest标签。</li></ul><h3 id="7-2-MAINTAINER"><a href="#7-2-MAINTAINER" class="headerlink" title="7.2 MAINTAINER"></a>7.2 MAINTAINER</h3><p>用法:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MAINTAINER &lt;name&gt;</span><br></pre></td></tr></table></figure><p>指定创建镜像的用户</p><p>RUN 有两种使用方式</p><ul><li>RUN</li><li>RUN <a href="http://opskumu.github.io/exec%20form" target="_blank" rel="noopener">“executable”, “param1”, “param2”</a></li></ul><p>每条RUN指令将在当前镜像基础上执行指定命令，并提交为新的镜像，后续的RUN都在之前RUN提交后的镜像为基础，镜像是分层的，可以通过一个镜像的任何一个历史提交点来创建，类似源码的版本控制。</p><p>exec 方式会被解析为一个 JSON 数组，所以必须使用双引号而不是单引号。exec 方式不会调用一个命令 shell，所以也就不会继承相应的变量，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN [ &quot;echo&quot;, &quot;$HOME&quot; ]</span><br></pre></td></tr></table></figure><p>这种方式是不会达到输出 HOME 变量的，正确的方式应该是这样的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RUN [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo&quot;, &quot;$HOME&quot; ]</span><br></pre></td></tr></table></figure><p>RUN产生的缓存在下一次构建的时候是不会失效的，会被重用，可以使用–no-cache选项，即docker build –no-cache，如此便不会缓存。</p><h3 id="7-3-CMD"><a href="#7-3-CMD" class="headerlink" title="7.3 CMD"></a>7.3 CMD</h3><p>CMD有三种使用方式:</p><ul><li>CMD <a href="http://opskumu.github.io/exec%20form,%20this%20is%20the%20preferred%20form,%20%E4%BC%98%E5%85%88%E9%80%89%E6%8B%A9" target="_blank" rel="noopener">“executable”,”param1”,”param2”</a></li><li>CMD <a href="http://opskumu.github.io/as%20default%20parameters%20to%20%60ENTRYPOINT%60" target="_blank" rel="noopener">“param1”,”param2”</a></li><li>CMD command param1 param2 (shell form)</li></ul><p>CMD指定在 Dockerfile 中只能使用一次，如果有多个，则只有最后一个会生效。</p><p>CMD的目的是为了在启动容器时提供一个默认的命令执行选项。如果用户启动容器时指定了运行的命令，则会覆盖掉CMD指定的命令。</p><blockquote><p>CMD会在启动容器的时候执行，build 时不执行，而RUN只是在构建镜像的时候执行，后续镜像构建完成之后，启动容器就与RUN无关了，这个初学者容易弄混这个概念，这里简单注解一下。</p></blockquote><h3 id="7-4-EXPOSE"><a href="#7-4-EXPOSE" class="headerlink" title="7.4 EXPOSE"></a>7.4 EXPOSE</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE &lt;port&gt; [&lt;port&gt;...]</span><br></pre></td></tr></table></figure><p>告诉 Docker 服务端容器对外映射的本地端口，需要在 docker run 的时候使用-p或者-P选项生效。</p><h3 id="7-5-ENV"><a href="#7-5-ENV" class="headerlink" title="7.5 ENV"></a>7.5 ENV</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV &lt;key&gt; &lt;value&gt;       # 只能设置一个变量</span><br><span class="line">ENV &lt;key&gt;=&lt;value&gt; ...   # 允许一次设置多个变量</span><br></pre></td></tr></table></figure><p>指定一个环节变量，会被后续RUN指令使用，并在容器运行时保留。</p><p>例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV myName=&quot;John Doe&quot; myDog=Rex\ The\ Dog \</span><br><span class="line">    myCat=fluffy</span><br></pre></td></tr></table></figure><p>等同于</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ENV myName John Doe</span><br><span class="line">ENV myDog Rex The Dog</span><br><span class="line">ENV myCat fluffy</span><br></pre></td></tr></table></figure><h3 id="7-6-ADD"><a href="#7-6-ADD" class="headerlink" title="7.6 ADD"></a>7.6 ADD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ADD &lt;src&gt;... &lt;dest&gt;</span><br></pre></td></tr></table></figure><p>ADD复制本地主机文件、目录或者远程文件 URLS 从 并且添加到容器指定路径中 。</p><p>支持通过 GO 的正则模糊匹配，具体规则可参见 <a href="http://golang.org/pkg/path/filepath/#Match" target="_blank" rel="noopener">Go filepath.Match</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ADD hom* /mydir/        # adds all files starting with &quot;hom&quot;</span><br><span class="line">ADD hom?.txt /mydir/    # ? is replaced with any single character</span><br></pre></td></tr></table></figure><ul><li>路径必须是绝对路径，如果 不存在，会自动创建对应目录</li><li>路径必须是 Dockerfile 所在路径的相对路径</li><li>如果是一个目录，只会复制目录下的内容，而目录本身则不会被复制</li></ul><h3 id="7-7-COPY"><a href="#7-7-COPY" class="headerlink" title="7.7 COPY"></a>7.7 COPY</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">COPY &lt;src&gt;... &lt;dest&gt;</span><br></pre></td></tr></table></figure><p>COPY复制新文件或者目录从 并且添加到容器指定路径中 。用法同ADD，唯一的不同是不能指定远程文件 URLS。</p><h3 id="7-8-ENTRYPOINT"><a href="#7-8-ENTRYPOINT" class="headerlink" title="7.8 ENTRYPOINT"></a>7.8 ENTRYPOINT</h3><ul><li>ENTRYPOINT <a href="http://opskumu.github.io/the%20preferred%20exec%20form%EF%BC%8C%E4%BC%98%E5%85%88%E9%80%89%E6%8B%A9" target="_blank" rel="noopener">“executable”, “param1”, “param2”</a></li><li>ENTRYPOINT command param1 param2 (shell form)</li></ul><p>配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，而CMD是可以被覆盖的。如果需要覆盖，则可以使用docker run –entrypoint选项。</p><p>每个 Dockerfile 中只能有一个ENTRYPOINT，当指定多个时，只有最后一个生效。</p><h4 id="Exec-form-ENTRYPOINT-例子"><a href="#Exec-form-ENTRYPOINT-例子" class="headerlink" title="Exec form ENTRYPOINT 例子"></a>Exec form ENTRYPOINT 例子</h4><p>通过ENTRYPOINT使用 exec form 方式设置稳定的默认命令和选项，而使用CMD添加默认之外经常被改动的选项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]</span><br><span class="line">CMD [&quot;-c&quot;]</span><br></pre></td></tr></table></figure><p>通过 Dockerfile 使用ENTRYPOINT展示前台运行 Apache 服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM debian:stable</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y --force-yes apache2</span><br><span class="line">EXPOSE 80 443</span><br><span class="line">VOLUME [&quot;/var/www&quot;, &quot;/var/log/apache2&quot;, &quot;/etc/apache2&quot;]</span><br><span class="line">ENTRYPOINT [&quot;/usr/sbin/apache2ctl&quot;, &quot;-D&quot;, &quot;FOREGROUND&quot;]</span><br></pre></td></tr></table></figure><h4 id="Shell-form-ENTRYPOINT-例子"><a href="#Shell-form-ENTRYPOINT-例子" class="headerlink" title="Shell form ENTRYPOINT 例子"></a>Shell form ENTRYPOINT 例子</h4><p>这种方式会在/bin/sh -c中执行，会忽略任何CMD或者docker run命令行选项，为了确保docker stop能够停止长时间运行ENTRYPOINT的容器，确保执行的时候使用exec选项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT exec top -b</span><br></pre></td></tr></table></figure><p>如果在ENTRYPOINT忘记使用exec选项，则可以使用CMD补上:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT top -b</span><br><span class="line">CMD --ignored-param1 # --ignored-param2 ... --ignored-param3 ... 依此类推</span><br></pre></td></tr></table></figure><h3 id="7-9-VOLUME"><a href="#7-9-VOLUME" class="headerlink" title="7.9 VOLUME"></a>7.9 VOLUME</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VOLUME [&quot;/data&quot;]</span><br></pre></td></tr></table></figure><p>创建一个可以从本地主机或其他容器挂载的挂载点，后续具体介绍。</p><h3 id="7-10-USER"><a href="#7-10-USER" class="headerlink" title="7.10 USER"></a>7.10 USER</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER daemon</span><br></pre></td></tr></table></figure><p>指定运行容器时的用户名或 UID，后续的RUN、CMD、ENTRYPOINT也会使用指定用户。</p><h3 id="7-11-WORKDIR"><a href="#7-11-WORKDIR" class="headerlink" title="7.11 WORKDIR"></a>7.11 WORKDIR</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /path/to/workdir</span><br></pre></td></tr></table></figure><p>为后续的RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR /a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure><p>最终路径是/a/b/c。</p><p>WORKDIR指令可以在ENV设置变量之后调用环境变量:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV DIRPATH /path</span><br><span class="line">WORKDIR $DIRPATH/$DIRNAME</span><br></pre></td></tr></table></figure><p>最终路径则为 /path/$DIRNAME。</p><h3 id="7-12-ONBUILD"><a href="#7-12-ONBUILD" class="headerlink" title="7.12 ONBUILD"></a>7.12 ONBUILD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ONBUILD [INSTRUCTION]</span><br></pre></td></tr></table></figure><p>配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。</p><p>例如，Dockerfile 使用如下的内容创建了镜像 image-A：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line">ONBUILD ADD . /app/src</span><br><span class="line">ONBUILD RUN /usr/local/bin/python-build --dir /app/src</span><br><span class="line">[...]</span><br></pre></td></tr></table></figure><p>如果基于 image-A 创建新的镜像时，新的 Dockerfile 中使用 FROM image-A 指定基础镜像时，会自动执行 ONBUILD 指令内容，等价于在后面添加了两条指令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Automatically run the following</span><br><span class="line">ADD . /app/src</span><br><span class="line">RUN /usr/local/bin/python-build --dir /app/src</span><br></pre></td></tr></table></figure><p>使用ONBUILD指令的镜像，推荐在标签中注明，例如 ruby:1.9-onbuild。</p><h3 id="7-13-Dockerfile-Examples"><a href="#7-13-Dockerfile-Examples" class="headerlink" title="7.13 Dockerfile Examples"></a>7.13 Dockerfile Examples</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"># Nginx</span><br><span class="line">#</span><br><span class="line"># VERSION               0.0.1</span><br><span class="line"></span><br><span class="line">FROM      ubuntu</span><br><span class="line">MAINTAINER Victor Vieux &lt;victor@docker.com&gt;</span><br><span class="line"></span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y inotify-tools nginx apache2 openssh-server</span><br><span class="line"></span><br><span class="line"># Firefox over VNC</span><br><span class="line">#</span><br><span class="line"># VERSION               0.3</span><br><span class="line"></span><br><span class="line">FROM ubuntu</span><br><span class="line"></span><br><span class="line"># Install vnc, xvfb in order to create a &apos;fake&apos; display and firefox</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y x11vnc xvfb firefox</span><br><span class="line">RUN mkdir ~/.vnc</span><br><span class="line"># Setup a password</span><br><span class="line">RUN x11vnc -storepasswd 1234 ~/.vnc/passwd</span><br><span class="line"># Autostart firefox (might not be the best way, but it does the trick)</span><br><span class="line">RUN bash -c &apos;echo &quot;firefox&quot; &gt;&gt; /.bashrc&apos;</span><br><span class="line"></span><br><span class="line">EXPOSE 5900</span><br><span class="line">CMD    [&quot;x11vnc&quot;, &quot;-forever&quot;, &quot;-usepw&quot;, &quot;-create&quot;]</span><br><span class="line"></span><br><span class="line"># Multiple images example</span><br><span class="line">#</span><br><span class="line"># VERSION               0.1</span><br><span class="line"></span><br><span class="line">FROM ubuntu</span><br><span class="line">RUN echo foo &gt; bar</span><br><span class="line"># Will output something like ===&gt; 907ad6c2736f</span><br><span class="line"></span><br><span class="line">FROM ubuntu</span><br><span class="line">RUN echo moo &gt; oink</span><br><span class="line"># Will output something like ===&gt; 695d7793cbe4</span><br><span class="line"></span><br><span class="line"># You᾿ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with</span><br><span class="line"># /oink.</span><br></pre></td></tr></table></figure><h3 id="7-14-docker-build"><a href="#7-14-docker-build" class="headerlink" title="7.14 docker build"></a>7.14 docker build</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ docker build --help</span><br><span class="line"></span><br><span class="line">Usage: docker build [OPTIONS] PATH | URL | -</span><br><span class="line"></span><br><span class="line">Build a new image from the source code at PATH</span><br><span class="line"></span><br><span class="line">  --force-rm=false     Always remove intermediate containers, even after unsuccessful builds # 移除过渡容器，即使构建失败</span><br><span class="line">  --no-cache=false     Do not use cache when building the image                              # 不实用 cache        </span><br><span class="line">  -q, --quiet=false    Suppress the verbose output generated by the containers               </span><br><span class="line">  --rm=true            Remove intermediate containers after a successful build               # 构建成功后移除过渡层容器</span><br><span class="line">  -t, --tag=&quot;&quot;         Repository name (and optionally a tag) to be applied to the resulting image in case of success</span><br></pre></td></tr></table></figure><p>参考文档:<a href="https://docs.docker.com/reference/builder/" target="_blank" rel="noopener">Dockerfile Reference</a></p><h3 id="7-15-dockerfile-最佳实践"><a href="#7-15-dockerfile-最佳实践" class="headerlink" title="7.15 dockerfile 最佳实践"></a>7.15 dockerfile 最佳实践</h3><ul><li>使用.dockerignore文件</li></ul><p>为了在docker build过程中更快上传和更加高效，应该使用一个.dockerignore文件用来排除构建镜像时不需要的文件或目录。例如,除非.git在构建过程中需要用到，否则你应该将它添加到.dockerignore文件中，这样可以节省很多时间。</p><ul><li>避免安装不必要的软件包</li></ul><p>为了降低复杂性、依赖性、文件大小以及构建时间，应该避免安装额外的或不必要的包。例如，不需要在一个数据库镜像中安装一个文本编辑器。</p><ul><li>每个容器都跑一个进程</li></ul><p>在大多数情况下，一个容器应该只单独跑一个程序。解耦应用到多个容器使其更容易横向扩展和重用。如果一个服务依赖另外一个服务，可以参考 <a href="https://docs.docker.com/userguide/dockerlinks/" target="_blank" rel="noopener">Linking Containers Together</a>。</p><ul><li>最小化层</li></ul><p>我们知道每执行一个指令，都会有一次镜像的提交，镜像是分层的结构，对于Dockerfile，应该找到可读性和最小化层之间的平衡。</p><ul><li>多行参数排序</li></ul><p>如果可能，通过字母顺序来排序，这样可以避免安装包的重复并且更容易更新列表，另外可读性也会更强，添加一个空行使用\换行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">  bzr \</span><br><span class="line">  cvs \</span><br><span class="line">  git \</span><br><span class="line">  mercurial \</span><br><span class="line">  subversion</span><br></pre></td></tr></table></figure><ul><li>创建缓存</li></ul><p>镜像构建过程中会按照Dockerfile的顺序依次执行，每执行一次指令 Docker 会寻找是否有存在的镜像缓存可复用，如果没有则创建新的镜像。如果不想使用缓存，则可以在docker build时添加–no-cache=true选项。</p><p>从基础镜像开始就已经在缓存中了，下一个指令会对比所有的子镜像寻找是否执行相同的指令，如果没有则缓存失效。在大多数情况下只对比Dockerfile指令和子镜像就足够了。ADD和COPY指令除外，执行ADD和COPY时存放到镜像的文件也是需要检查的，完成一个文件的校验之后再利用这个校验在缓存中查找，如果检测的文件改变则缓存失效。RUN apt-get -y update命令只检查命令是否匹配，如果匹配就不会再执行更新了。</p><blockquote><p>为了有效地利用缓存，你需要保持你的 Dockerfile 一致，并且尽量在末尾修改。</p></blockquote><h4 id="Dockerfile-指令"><a href="#Dockerfile-指令" class="headerlink" title="Dockerfile 指令"></a>Dockerfile 指令</h4><ul><li>FROM: 只要可能就使用官方镜像库作为基础镜像</li><li>RUN: 为保持可读性、方便理解、可维护性，把长或者复杂的RUN语句使用\分隔符分成多行<ul><li>不建议RUN apt-get update独立成行，否则如果后续包有更新，那么也不会再执行更新</li><li>避免使用RUN apt-get upgrade或者dist-upgrade，很多必要的包在一个非privileged权限的容器里是无法升级的。如果知道某个包更新，使用apt-get install -y xxx</li><li>标准写法<ul><li>RUN apt-get update &amp;&amp; apt-get install -y package-bar package-foo</li></ul></li></ul></li></ul><p>例子:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">RUN apt-get update &amp;&amp; apt-get install -y \</span><br><span class="line">    aufs-tools \</span><br><span class="line">    automake \</span><br><span class="line">    btrfs-tools \</span><br><span class="line">    build-essential \</span><br><span class="line">    curl \</span><br><span class="line">    dpkg-sig \</span><br><span class="line">    git \</span><br><span class="line">    iptables \</span><br><span class="line">    libapparmor-dev \</span><br><span class="line">    libcap-dev \</span><br><span class="line">    libsqlite3-dev \</span><br><span class="line">    lxc=1.0* \</span><br><span class="line">    mercurial \</span><br><span class="line">    parallel \</span><br><span class="line">    reprepro \</span><br><span class="line">    ruby1.9.1 \</span><br><span class="line">    ruby1.9.1-dev \</span><br><span class="line">    s3cmd=1.1.0*</span><br></pre></td></tr></table></figure><ul><li>CMD: 推荐使用CMD [“executable”, “param1”, “param2”…]这种格式，CMD [“param”, “param”]则配合ENTRYPOINT使用</li><li>EXPOSE: Dockerfile 指定要公开的端口，使用docker run时指定映射到宿主机的端口即可</li><li>ENV: 为了使新的软件更容易运行，可以使用ENV更新PATH变量。如ENV PATH /usr/local/nginx/bin:$PATH确保CMD [“nginx”]即可运行</li></ul><p>ENV也可以这样定义变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ENV PG_MAJOR 9.3</span><br><span class="line">ENV PG_VERSION 9.3.4</span><br><span class="line">RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress &amp;&amp; …</span><br><span class="line">ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH</span><br></pre></td></tr></table></figure><ul><li>ADDorCOPY:ADD比COPY多一些特性「tar 文件自动解包和支持远程 URL」，不推荐添加远程 URL</li></ul><p>如不推荐这种方式:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD http://example.com/big.tar.xz /usr/src/things/</span><br><span class="line">RUN tar -xJf /usr/src/things/big.tar.xz -C /usr/src/things</span><br><span class="line">RUN make -C /usr/src/things all</span><br></pre></td></tr></table></figure><p>推荐使用 curl 或者 wget 替换，使用如下方式:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">RUN mkdir -p /usr/src/things \</span><br><span class="line">    &amp;&amp; curl -SL http://example.com/big.tar.gz \</span><br><span class="line">    | tar -xJC /usr/src/things \</span><br><span class="line">    &amp;&amp; make -C /usr/src/things all</span><br></pre></td></tr></table></figure><p>如果不需要添加 tar 文件，推荐使用COPY。</p><p>参考文档:</p><ul><li><a href="https://docs.docker.com/articles/dockerfile_best-practices/" target="_blank" rel="noopener">Best practices for writing Dockerfiles</a></li><li><a href="http://dockerone.com/article/131" target="_blank" rel="noopener">Dockerfile最佳实践（一）</a></li><li><a href="http://dockerone.com/article/132" target="_blank" rel="noopener">Dockerfile最佳实践（二）</a></li></ul><h2 id="八、容器数据管理"><a href="#八、容器数据管理" class="headerlink" title="八、容器数据管理"></a>八、容器数据管理</h2><p>docker管理数据的方式有两种：</p><ul><li>数据卷</li><li>数据卷容器</li></ul><h3 id="8-1-数据卷"><a href="#8-1-数据卷" class="headerlink" title="8.1 数据卷"></a>8.1 数据卷</h3><p>数据卷是一个或多个容器专门指定绕过Union File System的目录，为持续性或共享数据提供一些有用的功能：</p><ul><li>数据卷可以在容器间共享和重用</li><li>数据卷数据改变是直接修改的</li><li>数据卷数据改变不会被包括在容器中</li><li>数据卷是持续性的，直到没有容器使用它们</li></ul><h4 id="添加一个数据卷"><a href="#添加一个数据卷" class="headerlink" title="添加一个数据卷"></a>添加一个数据卷</h4><p>你可以使用-v选项添加一个数据卷，或者可以使用多次-v选项为一个 docker 容器运行挂载多个数据卷。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --name data -v /data -t -i ubuntu:14.04 /bin/bash # 创建数据卷绑定到到新建容器，新建容器中会创建 /data 数据卷 bash-4.1# ls -ld /data/</span><br><span class="line">drwxr-xr-x 2 root root 4096 Jul 23 06:59 /data/</span><br><span class="line">bash-4.1# df -Th</span><br><span class="line">Filesystem    Type    Size  Used Avail Use% Mounted on</span><br><span class="line">... ...</span><br><span class="line">              ext4     91G  4.6G   82G   6% /data</span><br></pre></td></tr></table></figure><p>创建的数据卷可以通过docker inspect获取宿主机对应路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker inspect data</span><br><span class="line">... ... &quot;Volumes&quot;: &#123; &quot;/data&quot;: &quot;/var/lib/docker/vfs/dir/151de401d268226f96d824fdf444e77a4500aed74c495de5980c807a2ffb7ea9&quot; &#125;, # 可以看到创建的数据卷宿主机路径 ... ...</span><br></pre></td></tr></table></figure><p>或者直接指定获取</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker inspect --format=&quot;&#123;&#123; .Volumes &#125;&#125;&quot; data</span><br><span class="line">map[/data: /var/lib/docker/vfs/dir/151de401d268226f96d824fdf444e77a4500aed74c495de5980c807a2ffb7ea9]</span><br></pre></td></tr></table></figure><h4 id="挂载宿主机目录为一个数据卷"><a href="#挂载宿主机目录为一个数据卷" class="headerlink" title="挂载宿主机目录为一个数据卷"></a>挂载宿主机目录为一个数据卷</h4><p>-v选项除了可以创建卷，也可以挂载当前主机的一个目录到容器中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --name web -v /source/:/web -t -i ubuntu:14.04 /bin/bash</span><br><span class="line">bash-4.1# ls -ld /web/</span><br><span class="line">drwxr-xr-x 2 root root 4096 Jul 23 06:59 /web/</span><br><span class="line">bash-4.1# df -Th</span><br><span class="line">... ...</span><br><span class="line">              ext4     91G  4.6G   82G   6% /web</span><br><span class="line">bash-4.1# exit</span><br></pre></td></tr></table></figure><p>默认挂载卷是可读写的，可以在挂载时指定只读</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --rm --name test -v /source/:/test:ro -t -i ubuntu:14.04 /bin/bash</span><br></pre></td></tr></table></figure><h3 id="8-2-创建和挂载一个数据卷容器"><a href="#8-2-创建和挂载一个数据卷容器" class="headerlink" title="8.2 创建和挂载一个数据卷容器"></a>8.2 创建和挂载一个数据卷容器</h3><p>如果你有一些持久性的数据并且想在容器间共享，或者想用在非持久性的容器上，最好的方法是创建一个数据卷容器，然后从此容器上挂载数据。</p><p>创建数据卷容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i -d -v /test --name test ubuntu:14.04 echo hello</span><br></pre></td></tr></table></figure><p>使用–volumes-from选项在另一个容器中挂载 /test 卷。不管 test 容器是否运行，其它容器都可以挂载该容器数据卷，当然如果只是单独的数据卷是没必要运行容器的。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i -d --volumes-from test --name test1 ubuntu:14.04 /bin/bash</span><br></pre></td></tr></table></figure><p>添加另一个容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i -d --volumes-from test --name test2 ubuntu:14.04 /bin/bash</span><br></pre></td></tr></table></figure><p>也可以继承其它挂载有 /test 卷的容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i -d --volumes-from test1 --name test3 ubuntu:14.04 /bin/bash</span><br></pre></td></tr></table></figure><p><img src="http://static.open-open.com/lib/uploadImg/20150212/20150212091035_912.png" alt="非常详细的 Docker 学习笔记"></p><h3 id="8-3-备份、恢复或迁移数据卷"><a href="#8-3-备份、恢复或迁移数据卷" class="headerlink" title="8.3 备份、恢复或迁移数据卷"></a>8.3 备份、恢复或迁移数据卷</h3><h4 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --rm --volumes-from test -v $(pwd):/backup ubuntu:14.04 tar cvf /backup/test.tar /test</span><br><span class="line">tar: Removing leading `/&apos; from member names</span><br><span class="line">/test/</span><br><span class="line">/test/b</span><br><span class="line">/test/d</span><br><span class="line">/test/c</span><br><span class="line">/test/a</span><br></pre></td></tr></table></figure><p>启动一个新的容器并且从test容器中挂载卷，然后挂载当前目录到容器中为 backup，并备份 test 卷中所有的数据为 test.tar，执行完成之后删除容器–rm，此时备份就在当前的目录下，名为test.tar。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls # 宿主机当前目录下产生了 test 卷的备份文件 test.tar test.tar</span><br></pre></td></tr></table></figure><h4 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h4><p>你可以恢复给同一个容器或者另外的容器，新建容器并解压备份文件到新的容器数据卷</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i -d -v /test --name test4 ubuntu:14.04  /bin/bash $ sudo docker run --rm --volumes-from test4 -v $(pwd):/backup ubuntu:14.04 tar xvf /backup/test.tar -C / # 恢复之前的文件到新建卷中，执行完后自动删除容器 test/ test/b test/d test/c test/a</span><br></pre></td></tr></table></figure><h3 id="8-4-删除-Volumes"><a href="#8-4-删除-Volumes" class="headerlink" title="8.4 删除 Volumes"></a>8.4 删除 Volumes</h3><p>Volume 只有在下列情况下才能被删除：</p><ul><li>docker rm -v删除容器时添加了-v选项</li><li>docker run –rm运行容器时添加了–rm选项</li></ul><p>否则，会在/var/lib/docker/vfs/dir目录中遗留很多不明目录。</p><p>参考文档：</p><ul><li><a href="http://docs.docker.com/userguide/dockervolumes/#data-volumes" target="_blank" rel="noopener">Managing Data in Containers</a></li><li><a href="http://dockerone.com/article/128" target="_blank" rel="noopener">深入理解Docker Volume（一）</a></li><li><a href="http://dockerone.com/article/129" target="_blank" rel="noopener">深入理解Docker Volume（二）</a></li></ul><h2 id="九、链接容器"><a href="#九、链接容器" class="headerlink" title="九、链接容器"></a>九、链接容器</h2><p>docker 允许把多个容器连接在一起，相互交互信息。docker 链接会创建一种容器父子级别的关系，其中父容器可以看到其子容器提供的信息。</p><h3 id="9-1-容器命名"><a href="#9-1-容器命名" class="headerlink" title="9.1 容器命名"></a>9.1 容器命名</h3><p>在创建容器时，如果不指定容器的名字，则默认会自动创建一个名字，这里推荐给容器命名：</p><ul><li>1、给容器命名方便记忆，如命名运行 web 应用的容器为 web</li><li>2、为 docker 容器提供一个参考，允许方便其他容器调用，如把容器 web 链接到容器 db</li></ul><p>可以通过–name选项给容器自定义命名：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -d -t -i --name test ubuntu:14.04 bash              </span><br><span class="line">$ sudo docker  inspect --format=&quot;&#123;&#123; .Nmae &#125;&#125;&quot; test</span><br><span class="line">/test</span><br></pre></td></tr></table></figure><blockquote><p>注：容器名称必须唯一，即你只能命名一个叫test的容器。如果你想复用容器名，则必须在创建新的容器前通过docker rm删除旧的容器或者创建容器时添加–rm选项。</p></blockquote><h3 id="9-2-链接容器"><a href="#9-2-链接容器" class="headerlink" title="9.2 链接容器"></a>9.2 链接容器</h3><p>链接允许容器间安全通信，使用–link选项创建链接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -d --name db training/postgres</span><br></pre></td></tr></table></figure><p>基于 training/postgres 镜像创建一个名为 db 的容器，然后下面创建一个叫做 web 的容器，并且将它与 db 相互连接在一起</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -d -P --name web --link db:db training/webapp python app.py</span><br></pre></td></tr></table></figure><p>–link<name or>:alias选项指定链接到的容器。</name></p><p>查看 web 容器的链接关系:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker inspect -f &quot;&#123;&#123; .HostConfig.Links &#125;&#125;&quot; web</span><br><span class="line">[/db:/web/db]</span><br></pre></td></tr></table></figure><p>可以看到 web 容器被链接到 db 容器为/web/db，这允许 web 容器访问 db 容器的信息。</p><p>容器之间的链接实际做了什么？一个链接允许一个源容器提供信息访问给一个接收容器。在本例中，web 容器作为一个接收者，允许访问源容器 db 的相关服务信息。Docker 创建了一个安全隧道而不需要对外公开任何端口给外部容器，因此不需要在创建容器的时候添加-p或-P指定对外公开的端口，这也是链接容器的最大好处，本例为 PostgreSQL 数据库。</p><p>Docker 主要通过以下两个方式提供连接信息给接收容器：</p><ul><li>环境变量</li><li>更新/etc/hosts文件</li></ul><h4 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h4><p>当两个容器链接，Docker 会在目标容器上设置一些环境变量，以获取源容器的相关信息。</p><p>首先，Docker 会在每个通过–link选项指定别名的目标容器上设置一个<alias>_NAME环境变量。如果一个名为 web 的容器通过–link db:webdb被链接到一个名为 db 的数据库容器，那么 web 容器上会设置一个环境变量为WEBDB_NAME=/web/webdb.</alias></p><p>以之前的为例，Docker 还会设置端口变量:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run --rm --name web2 --link db:db training/webapp env</span><br><span class="line">. . .</span><br><span class="line">DB_NAME=/web2/db</span><br><span class="line">DB_PORT=tcp://172.17.0.5:5432           </span><br><span class="line">DB_PORT_5432_TCP=tcp://172.17.0.5:5432  # &lt;name&gt;_PORT_&lt;port&gt;_&lt;protocol&gt; 协议可以是 TCP 或 UDP</span><br><span class="line">DB_PORT_5432_TCP_PROTO=tcp</span><br><span class="line">DB_PORT_5432_TCP_PORT=5432</span><br><span class="line">DB_PORT_5432_TCP_ADDR=172.17.0.5</span><br><span class="line">. . .</span><br></pre></td></tr></table></figure><blockquote><p>注：这些环境变量只设置给容器中的第一个进程，类似一些守护进程 (如 sshd ) 当他们派生 shells 时会清除这些变量</p></blockquote><h4 id="更新-etc-hosts文件"><a href="#更新-etc-hosts文件" class="headerlink" title="更新/etc/hosts文件"></a>更新/etc/hosts文件</h4><p>除了环境变量，Docker 会在目标容器上添加相关主机条目到/etc/hosts中，上例中就是 web 容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ sudo docker run -t -i --rm --link db:db training/webapp /bin/bash</span><br><span class="line">root@aed84ee21bde:/opt/webapp# cat /etc/hosts</span><br><span class="line">172.17.0.7  aed84ee21bde</span><br><span class="line">. . .</span><br><span class="line">172.17.0.5  db</span><br></pre></td></tr></table></figure><blockquote><p>/etc/host文件在源容器被重启之后会自动更新 IP 地址，而环境变量中的 IP 地址则不会自动更新的。</p></blockquote><h2 id="十、构建私有库"><a href="#十、构建私有库" class="headerlink" title="十、构建私有库"></a>十、构建私有库</h2><p>Docker 官方提供了 docker registry 的构建方法 <a href="https://github.com/docker/docker-registry" target="_blank" rel="noopener">docker-registry</a></p><h3 id="10-1-快速构建"><a href="#10-1-快速构建" class="headerlink" title="10.1 快速构建"></a>10.1 快速构建</h3><p>快速构建 docker registry 通过以下两步:</p><ul><li>安装 docker</li><li>运行 registry:docker run -p 5000:5000 registry</li></ul><p>这种方法通过 Docker hub 使用官方镜像 <a href="https://registry.hub.docker.com/_/registry/" target="_blank" rel="noopener">official image from the Docker hub</a></p><h3 id="10-2-不使用容器构建-registry"><a href="#10-2-不使用容器构建-registry" class="headerlink" title="10.2 不使用容器构建 registry"></a>10.2 不使用容器构建 registry</h3><h4 id="安装必要的软件"><a href="#安装必要的软件" class="headerlink" title="安装必要的软件"></a>安装必要的软件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install build-essential python-dev libevent-dev python-pip liblzma-dev</span><br></pre></td></tr></table></figure><h4 id="配置-docker-registry"><a href="#配置-docker-registry" class="headerlink" title="配置 docker-registry"></a>配置 docker-registry</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo pip install docker-registry</span><br></pre></td></tr></table></figure><p>或者 使用 github clone 手动安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/dotcloud/docker-registry.git</span><br><span class="line">$ cd docker-registry/</span><br><span class="line">$ cp config/config_sample.yml config/config.yml</span><br><span class="line">$ mkdir /data/registry -p</span><br><span class="line">$ pip install .</span><br></pre></td></tr></table></figure><h4 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-registry</span><br></pre></td></tr></table></figure><h4 id="高级启动方式-不推荐"><a href="#高级启动方式-不推荐" class="headerlink" title="高级启动方式 [不推荐]"></a>高级启动方式 [不推荐]</h4><p>使用gunicorn控制:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunicorn -c contrib/gunicorn_config.py docker_registry.wsgi:application</span><br></pre></td></tr></table></figure><p>或者对外监听开放</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunicorn --access-logfile - --error-logfile - -k gevent -b 0.0.0.0:5000 -w 4 --max-requests 100 docker_registry.wsgi:application</span><br></pre></td></tr></table></figure><h3 id="10-3-提交指定容器到私有库"><a href="#10-3-提交指定容器到私有库" class="headerlink" title="10.3 提交指定容器到私有库"></a>10.3 提交指定容器到私有库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker tag ubuntu:12.04 私有库IP:5000/ubuntu:12.04</span><br><span class="line">$ docker push 私有库IP:5000/ubuntu</span><br></pre></td></tr></table></figure><h2 id="十一、docker-启动redis"><a href="#十一、docker-启动redis" class="headerlink" title="十一、docker 启动redis"></a>十一、docker 启动redis</h2><p><strong>一.docker运行单个redis</strong></p><ol><li>拉取官方镜像，镜像地址：<a href="https://hub.docker.com/_/redis/" target="_blank" rel="noopener">https://hub.docker.com/_/redis/</a></li><li>拉取镜像：docker pull redis</li><li>执行指令启动Redis</li></ol><p>docker run –name redis -d -p 6379:6379 redis</p><p><strong>二.docker运行单个redis</strong></p><p>1.拉取镜像: <code>docker pull redis</code></p><p>2.运行容器(本地image是:docker.io/redis latest 8f2e175b3bd1 2 weeks ago 106.6 MB):</p><p><code>docker run -d --name my_redis -p 6379:6379 -v /data/redis/data/:/data redis redis-server</code></p><ul><li>-d是后台运行;</li><li>–name是设置别名</li><li>-v /data/redis/data/:/data是将 /data/redis/data/挂载到容器的/data(数据默认存储在VOLUME /data目录下,可以使用$PWD/data代替/data/redis/data/)</li></ul><p>3.运行客户端:</p><p><code>docker run -it --link my_redis --rm docker.io/redis redis-cli -h my_redis -p 6379</code></p><ul><li>-it是交互模式(-i: 以交互模式运行容器,-t: 为容器重新分配一个伪输入终端)</li><li>–link 连接另一个容器,这样就可以使用容器名作为host了</li><li>–rm 自动清理容器,因为这里是测试,属于前台程序</li></ul><p><strong>二.docker运行redis主从复制模式（以两个数据库为例）</strong><br><em>主从复制模式:主数据库(master)可以读写,从数据库(slave)只能读;主数据库的写会同步到从数据库,从数据库主要负责读操作。一个主数据库可以拥有多个从数据库，一个从数据库只能拥有一个主数据库。</em></p><p>1.启动两个服务端:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name redis-master -v /data/redis/data/:/data  redis redis-server</span><br><span class="line">docker run  -d --name redis-slave --link redis-master redis redis-server --port 6380 --slaveof redis-master 637912</span><br></pre></td></tr></table></figure><p>2.启动对应的客户端:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --link redis-master --rm redis redis-cli -h redis-master -p 6379</span><br><span class="line">docker run -it --link redis-slave --rm redis redis-cli -h redis-slave -p 638012</span><br></pre></td></tr></table></figure><p>使用：<code>slaveof no one</code>退出主从关系</p><h2 id="十二、docker-部署zookeeper"><a href="#十二、docker-部署zookeeper" class="headerlink" title="十二、docker 部署zookeeper"></a>十二、docker 部署zookeeper</h2><ol><li>镜像下载</li></ol><p>hub.docker.com 上有不少 ZK 镜像, 不过为了稳定起见, 我们就使用官方的 ZK 镜像吧.<br>首先执行如下命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull zookeeper</span><br></pre></td></tr></table></figure><p>当出现如下结果时, 表示镜像已经下载完成了:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; docker pull zookeeper</span><br><span class="line">Using default tag: latest</span><br><span class="line">latest: Pulling from library/zookeeper</span><br><span class="line"></span><br><span class="line">e110a4a17941: Pull complete</span><br><span class="line">a696cba1f6e8: Pull complete</span><br><span class="line">bc427bd93e95: Pull complete</span><br><span class="line">c72391ae24f6: Pull complete</span><br><span class="line">40ab409b6b34: Pull complete</span><br><span class="line">d4bb8183b85d: Pull complete</span><br><span class="line">0600755f1470: Pull complete</span><br><span class="line">Digest: sha256:12458234bb9f01336df718b7470cabaf5c357052cbcb91f8e80be07635994464</span><br><span class="line">Status: Downloaded newer image for zookeeper:latest</span><br></pre></td></tr></table></figure><p>2.启动 ZK 镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; docker run --name my_zookeeper -d zookeeper:latest</span><br></pre></td></tr></table></figure><p>这个命令会在后台运行一个 zookeeper 容器, 名字是 <strong>my_zookeeper</strong>, 并且它默认会导出 2181 端口.<br>接着我们使用:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs -f my_zookeeper</span><br></pre></td></tr></table></figure><p>这个命令查看 ZK 的运行情况, 输出类似如下内容时, 表示 ZK 已经成功启动了:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; docker logs -f my_zookeeper</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /conf/zoo.cfg</span><br><span class="line">...</span><br><span class="line">2016-09-14 06:40:03,445 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181</span><br></pre></td></tr></table></figure><p>3.使用 ZK 命令行客户端连接 ZK</p><p>因为刚才我们启动的那个 ZK 容器并没有绑定宿主机的端口, 因此我们不能直接访问它. 但是我们可以通过 Docker 的 link 机制来对这个 ZK 容器进行访问. 执行如下命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm --link my_zookeeper:zookeeper zookeeper zkCli.sh -server zookeeper</span><br></pre></td></tr></table></figure><p>如果对 Docker 有过了解的话, 那么对上面的命令一定不会陌生了.<br>这个命令的含义是:</p><ol><li><p>启动一个 zookeeper 镜像, 并运行这个镜像内的 zkCli.sh 命令, 命令参数是 “-server zookeeper”</p></li><li><p>将我们先前启动的名为 my_zookeeper 的容器连接(link) 到我们新建的这个容器上, 并将其主机名命名为 <strong>zookeeper</strong></p></li></ol><p>当我们执行了这个命令后, 就可以像正常使用 ZK 命令行客户端一样操作 ZK 服务了.</p><h2 id="ZK-集群的搭建"><a href="#ZK-集群的搭建" class="headerlink" title="ZK 集群的搭建"></a>ZK 集群的搭建</h2><p>因为一个一个地启动 ZK 太麻烦了, 所以为了方便起见, 我直接使用 docker-compose 来启动 ZK 集群.<br>首先创建一个名为 <strong>docker-compose.yml</strong> 的文件, 其内容如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;2&apos;</span><br><span class="line">services:</span><br><span class="line">    zoo1:</span><br><span class="line">        image: zookeeper</span><br><span class="line">        restart: always</span><br><span class="line">        container_name: zoo1</span><br><span class="line">        ports:</span><br><span class="line">            - &quot;2181:2181&quot;</span><br><span class="line">        environment:</span><br><span class="line">            ZOO_MY_ID: 1</span><br><span class="line">            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888</span><br><span class="line"></span><br><span class="line">    zoo2:</span><br><span class="line">        image: zookeeper</span><br><span class="line">        restart: always</span><br><span class="line">        container_name: zoo2</span><br><span class="line">        ports:</span><br><span class="line">            - &quot;2182:2181&quot;</span><br><span class="line">        environment:</span><br><span class="line">            ZOO_MY_ID: 2</span><br><span class="line">            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888</span><br><span class="line"></span><br><span class="line">    zoo3:</span><br><span class="line">        image: zookeeper</span><br><span class="line">        restart: always</span><br><span class="line">        container_name: zoo3</span><br><span class="line">        ports:</span><br><span class="line">            - &quot;2183:2181&quot;</span><br><span class="line">        environment:</span><br><span class="line">            ZOO_MY_ID: 3</span><br><span class="line">            ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888</span><br></pre></td></tr></table></figure><p>这个配置文件会告诉 Docker 分别运行三个 zookeeper 镜像, 并分别将本地的 2181, 2182, 2183 端口绑定到对应的容器的2181端口上.<br><strong>ZOO_MY_ID</strong> 和 <strong>ZOO_SERVERS</strong> 是搭建 ZK 集群需要设置的两个环境变量, 其中 <strong>ZOO_MY_ID</strong> 表示 ZK 服务的 id, 它是1-255 之间的整数, 必须在集群中唯一. <strong>ZOO_SERVERS</strong> 是ZK 集群的主机列表.</p><p>接着我们在 docker-compose.yml 当前目录下运行:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">COMPOSE_PROJECT_NAME=zk_test docker-compose up</span><br></pre></td></tr></table></figure><p>即可启动 ZK 集群了.<br>执行上述命令成功后, 接着在另一个终端中运行 <strong>docker-compose ps</strong> 命令可以查看启动的 ZK 容器:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; COMPOSE_PROJECT_NAME=zk_test docker-compose ps</span><br><span class="line">Name              Command               State           Ports</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">zoo1   /docker-entrypoint.sh zkSe ...   Up      0.0.0.0:2181-&gt;2181/tcp</span><br><span class="line">zoo2   /docker-entrypoint.sh zkSe ...   Up      0.0.0.0:2182-&gt;2181/tcp</span><br><span class="line">zoo3   /docker-entrypoint.sh zkSe ...   Up      0.0.0.0:2183-&gt;2181/tcp</span><br></pre></td></tr></table></figure><blockquote><p>注意, 我们在 “docker-compose up” 和 “docker-compose ps” 前都添加了 <strong>COMPOSE_PROJECT_NAME=zk_test</strong> 这个环境变量, 这是为我们的 compose 工程起一个名字, 以免与其他的 compose 混淆.</p></blockquote><h3 id="使用-Docker-命令行客户端连接-ZK-集群"><a href="#使用-Docker-命令行客户端连接-ZK-集群" class="headerlink" title="使用 Docker 命令行客户端连接 ZK 集群"></a>使用 Docker 命令行客户端连接 ZK 集群</h3><p>通过 <strong>docker-compose ps</strong> 命令, 我们知道启动的 ZK 集群的三个主机名分别是 zoo1, zoo2, zoo3, 因此我们分别 link 它们即可:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --rm \</span><br><span class="line">        --link zoo1:zk1 \</span><br><span class="line">        --link zoo2:zk2 \</span><br><span class="line">        --link zoo3:zk3 \</span><br><span class="line">        --net zktest_default \</span><br><span class="line">        zookeeper zkCli.sh -server zk1:2181,zk2:2181,zk3:2181</span><br></pre></td></tr></table></figure><h3 id="通过本地主机连接-ZK-集群"><a href="#通过本地主机连接-ZK-集群" class="headerlink" title="通过本地主机连接 ZK 集群"></a>通过本地主机连接 ZK 集群</h3><p>因为我们分别将 zoo1, zoo2, zoo3 的 2181 端口映射到了 本地主机的2181, 2182, 2183 端口上, 因此我们使用如下命令即可连接 ZK 集群了:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkCli.sh -server localhost:2181,localhost:2182,localhost:2183</span><br></pre></td></tr></table></figure><h3 id="查看集群"><a href="#查看集群" class="headerlink" title="查看集群"></a>查看集群</h3><p>我们可以通过 nc 命令连接到指定的 ZK 服务器, 然后发送 stat 可以查看 ZK 服务的状态, 例如:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; echo stat | nc 127.0.0.1 2181</span><br><span class="line">Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMT</span><br><span class="line">Clients:</span><br><span class="line"> /172.18.0.1:49810[0](queued=0,recved=1,sent=0)</span><br><span class="line"></span><br><span class="line">Latency min/avg/max: 5/39/74</span><br><span class="line">Received: 4</span><br><span class="line">Sent: 3</span><br><span class="line">Connections: 1</span><br><span class="line">Outstanding: 0</span><br><span class="line">Zxid: 0x200000002</span><br><span class="line">Mode: follower</span><br><span class="line">Node count: 4</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; echo stat | nc 127.0.0.1 2182</span><br><span class="line">Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMT</span><br><span class="line">Clients:</span><br><span class="line"> /172.18.0.1:50870[0](queued=0,recved=1,sent=0)</span><br><span class="line"></span><br><span class="line">Latency min/avg/max: 0/0/0</span><br><span class="line">Received: 2</span><br><span class="line">Sent: 1</span><br><span class="line">Connections: 1</span><br><span class="line">Outstanding: 0</span><br><span class="line">Zxid: 0x200000002</span><br><span class="line">Mode: follower</span><br><span class="line">Node count: 4</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; echo stat | nc 127.0.0.1 2183</span><br><span class="line">Zookeeper version: 3.4.9-1757313, built on 08/23/2016 06:50 GMT</span><br><span class="line">Clients:</span><br><span class="line"> /172.18.0.1:51820[0](queued=0,recved=1,sent=0)</span><br><span class="line"></span><br><span class="line">Latency min/avg/max: 0/0/0</span><br><span class="line">Received: 2</span><br><span class="line">Sent: 1</span><br><span class="line">Connections: 1</span><br><span class="line">Outstanding: 0</span><br><span class="line">Zxid: 0x200000002</span><br><span class="line">Mode: leader</span><br><span class="line">Node count: 4</span><br></pre></td></tr></table></figure><h2 id="十三、docker-部署-rabbitmq"><a href="#十三、docker-部署-rabbitmq" class="headerlink" title="十三、docker 部署 rabbitmq"></a>十三、docker 部署 rabbitmq</h2><ol><li><p>拉取官方镜像，镜像地址：<a href="https://hub.docker.com/_/rabbitmq/" target="_blank" rel="noopener">https://hub.docker.com/_/rabbitmq/</a></p></li><li><p>拉取镜像：docker pull rabbitmq，如需要管理界面：docker pull rabbitmq:management</p></li><li><p>执行指令启动RabbitMQ</p><p>无管理界面：</p></li></ol><p>docker run –localhost rabbit-host –name my_rabbit -d -p 5672:5672 rabbitmq</p><p>有管理界面：</p><p>docker run –localhost rabbit-host –name my_rabbit -d -p 5672:5672 -p 15672:15672 rabbitmq:management</p><pre><code>账号：guest 密码：guest</code></pre><h2 id="十四-、启动Eureka"><a href="#十四-、启动Eureka" class="headerlink" title="十四 、启动Eureka"></a>十四 、启动Eureka</h2><ol><li><p>拉取官方镜像，镜像地址：<a href="https://hub.docker.com/r/springcloud/eureka/" target="_blank" rel="noopener">https://hub.docker.com/r/springcloud/eureka/</a></p></li><li><p>拉取镜像：docker pull springcloud/eureka</p></li><li><p>执行指令启动Eureka</p><p>docker run –name my_eureka -d -p 8761:8761 springcloud/eureka</p></li></ol><h2 id="十五-、启动Config-Server"><a href="#十五-、启动Config-Server" class="headerlink" title="十五 、启动Config Server"></a>十五 、启动Config Server</h2><ol><li><p>拉取官方镜像，镜像地址：<a href="https://hub.docker.com/r/hyness/spring-cloud-config-server/" target="_blank" rel="noopener">https://hub.docker.com/r/hyness/spring-cloud-config-server/</a></p></li><li><p>拉取镜像：docker pull hyness/spring-cloud-config-server</p></li><li><p>在GitHub上准备配置文件：<a href="https://github.com/ErikXu/.NetCore-Spring-Clould/tree/master/Configs" target="_blank" rel="noopener">https://github.com/ErikXu/.NetCore-Spring-Clould/tree/master/Configs</a></p></li><li><p>准备启动资源文件application.yml:</p><p><code>info:</code></p><p><code>`</code>component: config service`</p></li></ol><p><code>server:</code></p><p><code>`</code>port: 8888`</p><p><code>spring:</code></p><p><code>`</code>application:`</p><p><code>`</code>name: git-config`</p><p><code>`</code>profiles:`</p><p><code>`</code>active: dev`</p><p><code>`</code>cloud:`</p><p><code>`</code>config:`</p><p><code>`</code>server:`</p><p><code>`</code>git:`</p><p><code>`</code>uri: https:<code>//github</code>.com<code>/ErikXu/</code>.NetCore-Spring-Clould`</p><p><code>`</code>searchPaths: Configs`</p><p></p><ol start="5"><li>执行指令启动Config Server，注：该指令前无空格</li></ol><p>docker run –name my_config-server -it -d -p 8888:8888 \<br>-v /home/erikxu/config/application.yml:/config/application.yml \<br>hyness/spring-cloud-config-server</p><h2 id="十六-、启动-mysql"><a href="#十六-、启动-mysql" class="headerlink" title="十六 、启动 mysql"></a>十六 、启动 mysql</h2><ol><li>拉取官方镜像，镜像地址：<a href="https://hub.docker.com/_/mysql/" target="_blank" rel="noopener">https://hub.docker.com/_/mysql/</a></li><li>拉取镜像：docker pull mysql</li><li>准备Mysql数据存放目录，我这里是：/data/mysql</li><li>执行指令启动Mysql</li></ol><p>docker run –name my_mysql -v /data/mysql:/var/lib/mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql:latest</p><h2 id="十七、启动nginx"><a href="#十七、启动nginx" class="headerlink" title="十七、启动nginx"></a>十七、启动nginx</h2><ol><li>拉取官方镜像，镜像地址：<a href="https://hub.docker.com/_/nginx/" target="_blank" rel="noopener">https://hub.docker.com/_/nginx/</a></li><li>拉取镜像：docker pull nginx</li><li>准备配置文件</li></ol><p></p><p>4、执行指令启动Nginx</p><p>docker run –name my_nginx -p 80:80 -v /data/etc/nginx.conf:/etc/nginx/nginx.conf:ro -d nginx</p><p></p><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Tue Jun 11 2019 20:02:47 GMT+0800 (GMT+08:00) --&gt;&lt;h2 id=&quot;一、Docker-简介&quot;&gt;&lt;a href=&quot;#一、Docker-简介&quot; class=&quot;headerlink&quot; title=&quot;一、Doc
      
    
    </summary>
    
    
      <category term="docker" scheme="http://www.liuyong520.cn/tags/docker/"/>
    
  </entry>
  
</feed>
