{"meta":{"title":"跛足的登山者","subtitle":null,"description":null,"author":"xxydliuy","url":"http://www.liuyong520.cn","root":"/"},"pages":[{"title":"toc","date":"2019-04-23T09:31:21.000Z","updated":"2019-04-27T08:01:14.825Z","comments":true,"path":"java.html","permalink":"http://www.liuyong520.cn/java.html","excerpt":"","text":"我媳妇是个老色鬼"},{"title":"分类","date":"2019-04-26T14:57:26.514Z","updated":"2019-04-26T14:57:26.514Z","comments":false,"path":"categories/index.html","permalink":"http://www.liuyong520.cn/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2019-04-26T10:36:36.781Z","updated":"2019-04-26T10:36:36.781Z","comments":false,"path":"about/index.html","permalink":"http://www.liuyong520.cn/about/index.html","excerpt":"","text":"欢迎访问我的博客，我会不定期更新！1234567891011121314151617181920212223242526272829303132/** * _ooOoo_ * o8888888o * 88\" . \"88 * (| -_- |) * O\\ = /O * ____/`---'\\____ * .' \\\\| |// `. * / \\\\||| : |||// \\ * / _||||| -:- |||||- \\ * | | \\\\\\ - /// | | * | \\_| ''\\---/'' | | * \\ .-\\__ `-` ___/-. / * ___`. .' /--.--\\ `. . __ * .\"\" '&lt; `.___\\_&lt;|&gt;_/___.' &gt;'\"\". * | | : `- \\`.;`\\ _ /`;.`/ - ` : | | * \\ \\ `-. \\_ __\\ /__ _/ .-` / / * ======`-.____`-.___\\_____/___.-`____.-'====== * `=---=' * ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ * 佛祖保佑 永无BUG * 佛曰: * 写字楼里写字间，写字间里程序员； * 程序人员写程序，又拿程序换酒钱。 * 酒醒只在网上坐，酒醉还来网下眠； * 酒醉酒醒日复日，网上网下年复年。 * 但愿老死电脑间，不愿鞠躬老板前； * 奔驰宝马贵者趣，公交自行程序员。 * 别人笑我忒疯癫，我笑自己命太贱； * 不见满街漂亮妹，哪个归得程序员？*/"},{"title":"书单","date":"2019-04-26T15:28:00.106Z","updated":"2019-04-26T15:28:00.106Z","comments":false,"path":"books/index.html","permalink":"http://www.liuyong520.cn/books/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-04-26T15:24:46.349Z","updated":"2019-04-26T15:24:46.349Z","comments":false,"path":"tags/index.html","permalink":"http://www.liuyong520.cn/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-04-26T15:44:12.763Z","updated":"2019-04-26T15:44:12.763Z","comments":true,"path":"links/index.html","permalink":"http://www.liuyong520.cn/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-04-26T11:51:41.915Z","updated":"2019-04-26T11:51:41.915Z","comments":false,"path":"repository/index.html","permalink":"http://www.liuyong520.cn/repository/index.html","excerpt":"","text":"qwqwwwwww"}],"posts":[{"title":"Linux下kafka集群搭建","slug":"kafka-install","date":"2019-04-29T02:56:51.000Z","updated":"2019-04-30T02:48:31.425Z","comments":true,"path":"2019/04/29/kafka-install/","link":"","permalink":"http://www.liuyong520.cn/2019/04/29/kafka-install/","excerpt":"","text":"环境准备zookeeper集群环境kafka是依赖于zookeeper注册中心的一款分布式消息对列，所以需要有zookeeper单机或者集群环境。三台服务器：123172.16.18.198 k8s-n1172.16.18.199 k8s-n2172.16.18.200 k8s-n3下载kafka安装包http://kafka.apache.org/downloads 中下载，目前最新版本的kafka已经到2.2.0,我这里之前下载的是kafka_2.11-2.2.0.tgz.安装kafka集群上传压缩包到三台服务器解压缩到/opt/目录下12tar -zxvf kafka_2.11-2.2.0.tgz -C /opt/ls -s kafka_2.11-2.2.0 kafka修改 server.properties123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121############################# Server Basics ############################## The id of the broker. This must be set to a unique integer for each broker.broker.id=0############################# Socket Server Settings ############################## The address the socket server listens on. It will get the value returned from # java.net.InetAddress.getCanonicalHostName() if not configured.# FORMAT:# listeners = listener_name://host_name:port# EXAMPLE:# listeners = PLAINTEXT://your.host.name:9092listeners=PLAINTEXT://k8s-n1:9092# Hostname and port the broker will advertise to producers and consumers. If not set, # it uses the value for &quot;listeners&quot; if configured. Otherwise, it will use the value# returned from java.net.InetAddress.getCanonicalHostName().advertised.listeners=PLAINTEXT://k8s-n1:9092# Maps listener names to security protocols, the default is for them to be the same. See the config documentation for more details#listener.security.protocol.map=PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL# The number of threads that the server uses for receiving requests from the network and sending responses to the networknum.network.threads=3# The number of threads that the server uses for processing requests, which may include disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics ############################## A comma separated list of directories under which to store log fileslog.dirs=/var/applog/kafka/# The default number of log partitions per topic. More partitions allow greater# parallelism for consumption, but this will also result in more files across# the brokers.num.partitions=5# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.# This value is recommended to be increased for installations with data dirs located in RAID array.num.recovery.threads.per.data.dir=1############################# Internal Topic Settings ############################## The replication factor for the group metadata internal topics &quot;__consumer_offsets&quot; and &quot;__transaction_state&quot;# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.offsets.topic.replication.factor=1transaction.state.log.replication.factor=1transaction.state.log.min.isr=1############################# Log Flush Policy ############################## Messages are immediately written to the filesystem but by default we only fsync() to sync# the OS cache lazily. The following configurations control the flush of data to disk.# There are a few important trade-offs here:# 1. Durability: Unflushed data may be lost if you are not using replication.# 2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.# 3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.# The settings below allow one to configure the flush policy to flush data after a period of time or# every N messages (or both). This can be done globally and overridden on a per-topic basis.# The number of messages to accept before forcing a flush of data to disklog.flush.interval.messages=10000# The maximum amount of time a message can sit in a log before we force a flushlog.flush.interval.ms=1000############################# Log Retention Policy ############################## The following configurations control the disposal of log segments. The policy can# be set to delete segments after a period of time, or after a given size has accumulated.# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens# from the end of the log.# The minimum age of a log file to be eligible for deletion due to agelog.retention.hours=24# A size-based retention policy for logs. Segments are pruned from the log unless the remaining# segments drop below log.retention.bytes. Functions independently of log.retention.hours.#log.retention.bytes=1073741824# The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824# The interval at which log segments are checked to see if they can be deleted according# to the retention policieslog.retention.check.interval.ms=300000############################# Zookeeper ############################## Zookeeper connection string (see zookeeper docs for details).# This is a comma separated host:port pairs, each corresponding to a zk# server. e.g. &quot;127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002&quot;.# You can also append an optional chroot string to the urls to specify the# root directory for all kafka znodes.zookeeper.connect=k8s-n1:2181,k8s-n2:2181,k8s-n3:2181# Timeout in ms for connecting to zookeeperzookeeper.connection.timeout.ms=6000############################# Group Coordinator Settings ############################## The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.# The default value for this is 3 seconds.# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.group.initial.rebalance.delay.ms=0delete.topic.enable=true拷贝两份到k8s-n2,k8s-n3123456789[root@k8s-n2 config]# cat server.properties broker.id=1listeners=PLAINTEXT://k8s-n2:9092advertised.listeners=PLAINTEXT://k8s-n2:9092[root@k8s-n3 config]# cat server.propertiesbroker.id=2listeners=PLAINTEXT://k8s-n3:9092advertised.listeners=PLAINTEXT://k8s-n3:9092添加环境变量 在/etc/profile 中添加12export ZOOKEEPER_HOME=/opt/kafka_2.11-2.2.0export PATH=$PATH:$ZOOKEEPER_HOME/binsource /etc/profile 重载生效启动kafka1kafka-server-start.sh config/server.properties &amp;Zookeeper+Kafka集群测试创建topic:1kafka-topics.sh --create --zookeeper k8s-n1:2181, k8s-n2:2181, k8s-n3:2181 --replication-factor 3 --partitions 3 --topic test显示topic1kafka-topics.sh --describe --zookeeper k8s-n1:2181, k8s-n2:2181, k8s-n3:2181 --topic test列出topic12kafka-topics.sh --list --zookeeper k8s-n1:2181, k8s-n2:2181, k8s-n3:2181test创建 producer(生产者);12kafka-console-producer.sh --broker-list k8s-n1:9092 --topic testhello创建 consumer（消费者）12kafka-console-consumer.sh --bootstrap-server k8s-n1:9092 --topic test --from-beginninghello至此，kafka集群搭建就已经完成了。","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.liuyong520.cn/categories/消息队列/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.liuyong520.cn/tags/kafka/"},{"name":"linux","slug":"linux","permalink":"http://www.liuyong520.cn/tags/linux/"}]},{"title":"Linux下zookeeper集群搭建","slug":"zookeeper-install","date":"2019-04-29T02:56:51.000Z","updated":"2019-04-29T10:04:56.654Z","comments":true,"path":"2019/04/29/zookeeper-install/","link":"","permalink":"http://www.liuyong520.cn/2019/04/29/zookeeper-install/","excerpt":"","text":"部署前准备下载zookeeper的安装包http://zookeeper.apache.org/releases.html 我下载的版本是zookeeper-3.4.10。准备三台服务器ip地址为：123172.16.18.198172.16.18.199172.16.18.200检查jdk版本，安装jdk环境，jdk需要1.7以上。安装zookeeper三台服务器分别上传zookeeper安装包，上传到/opt/目录下，然后tar zxvf zookeeper-3.4.10.tar.gz拷贝zoo_sample.cfg 为zoo.cfg 修改/opt/zookeeper-3.4.10/conf/zoo.cfg配置文件，添加如下内容：123server.1=172.16.18.198:2888:3888server.2=172.16.18.199:2888:3888server.3=172.16.18.200:2888:3888修改zookeeper数据文件存放目录1dataDir=/data/zookeeper此时zoo.cfg 配置文件内容为：12345678910111213141516171819202122232425262728293031# The number of milliseconds of each ticktickTime=2000 ##zookeeper单位时间为2ms# The number of ticks that the initial # synchronization phase can takeinitLimit=10 ##对于从节点最初连接到主节点时的超时时间，单位为tick值的倍数。即20ms# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5 ##对于主节点与从节点进行同步操作时的超时时间，单位为tick值的倍数。即10ms# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/data/zookeeper# the port at which the clients will connectclientPort=2181 ##客户端链接端口# the maximum number of client connections.# increase this if you need to handle more clientsmaxClientCnxns=60 ##客户端最大链接数## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1server.1=172.16.18.198:2888:3888 server.2=172.16.18.199:2888:3888server.3=172.16.18.200:2888:3888新建myid文件在三台服务器的数据存放目录下新建myid文件，并写入对应的server.num 中的num数字如：在172.16.18.198上将server.1中1写入myid1echo 1 &gt;/data/zookeeper/myid添加环境变量，方便我们执行脚本命令vi etc/profile 在最后添加如下两个。12export ZOOKEEPER_HOME=/opt/zookeeper-3.4.9export PATH=$PATH:$ZOOKEEPER_HOME/bin:$ZOOKEEPER_HOME/conf保存后重新加载一下：1source /etc/profile修改日志存放目录（可选）vi /opt/zookeeper/bin/zkEnv.sh 找到ZOO_LOG_DIR 和 ZOO_LOG4J_PROP位置1234567891011if [ &quot;x$&#123;ZOO_LOG_DIR&#125;&quot; = &quot;x&quot; ] then #配置zookeeper日志输出存放路径 ZOO_LOG_DIR=&quot;/var/applog/zookeeper&quot; fi if [ &quot;x$&#123;ZOO_LOG4J_PROP&#125;&quot; = &quot;x&quot; ] then #配置日志输出级别,这里把几个级别一并配上 ZOO_LOG4J_PROP=&quot;INFO,CONSOLE,ROLLINGFILE,TRACEFILE&quot; fi编辑conf目录下log4j.properties123456789# Define some default values that can be overridden by system properties zookeeper.root.logger=INFO, CONSOLE, ROLLINGFILE, TRACEFILE zookeeper.console.threshold=INFO zookeeper.log.dir=. zookeeper.log.file=zookeeper.log zookeeper.log.threshold=ERROR zookeeper.tracelog.dir=. zookeeper.tracelog.file=zookeeper_trace.log log4j.rootLogger=$&#123;zookeeper.root.logger&#125;完成log的日志目录的修改。7.启动zookeeper服务zkServer.sh start来启动。zkServer.sh restart (重启)zkServer.sh status (查看状态)zkServer.sh stop (关闭)zkServer.sh start-foreground (以打印日志方式启动)三台服务器分别执行：1zkServer.sh start然后用 status 检查下状态 如果出现 Mode：leader 或者Mode:follower 表示搭建成功。否则前台执行看一下日志。1234$ zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower如出现：123456789102019-04-29 14:04:05,992 [myid:3] - INFO [ListenerThread:QuorumCnxManager$Listener@739] - My election bind port: /172.16.18.200:38882019-04-29 14:04:06,019 [myid:3] - INFO [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:QuorumPeer@865] - LOOKING2019-04-29 14:04:06,025 [myid:3] - INFO [QuorumPeer[myid=3]/0:0:0:0:0:0:0:0:2181:FastLeaderElection@818] - New election. My id = 3, proposed zxid=0x02019-04-29 14:04:06,056 [myid:3] - WARN [WorkerSender[myid=3]:QuorumCnxManager@588] - Cannot open channel to 1 at election address /172.16.18.198:3888java.net.NoRouteToHostException: 没有到主机的路由 at java.net.PlainSocketImpl.socketConnect(Native Method) at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:345) at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)&quot;zookeeper.log&quot; 303L, 35429C报这种异常一般有三种情况：1）：zoo.cfg配置文件中，server.x:2888:3888配置出现错误；2）：myid文件内容和server.x不对应，或者myid不在data目录下；3）：系统防火墙是否在启动。我检查了三种原因后发现是防火墙running。centos7下查看防火墙状态的命令：1firewall-cmd --state关闭防火墙的命令：12systemctl stop firewalld.servicesystemctl disable firewalld.service （禁止开机启动，永久关闭防火墙）关闭防火墙后重启即可。验证是否成功在命令行中输入：zkCli.sh -server 172.16.18.198:2181（由于本人在不同的办公地点在修改该文章，所以ip地址也在变化，知道原理即可）即可连接到其中一台ZooKeeper服务器。其他自动实现同步，客户端只需要和一台保持连接即可。出现如下表示链接成功1234WATCHER::WatchedEvent state:SyncConnected type:None path:null[zk: 172.16.18.198:2181(CONNECTED) 0]","categories":[{"name":"分布式集群","slug":"分布式集群","permalink":"http://www.liuyong520.cn/categories/分布式集群/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuyong520.cn/tags/linux/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"http://www.liuyong520.cn/tags/ZooKeeper/"}]},{"title":"kafka基本介绍","slug":"kafka-intruduce","date":"2019-04-29T02:56:51.000Z","updated":"2019-05-02T11:30:40.781Z","comments":true,"path":"2019/04/29/kafka-intruduce/","link":"","permalink":"http://www.liuyong520.cn/2019/04/29/kafka-intruduce/","excerpt":"","text":"kafka是什么？Kafka是一个分布式流式存储并处理的消息队列。由scale+java语言编写，它提供了类似于JMS的特性，但是在设计实现上又完全不同，因为kafka并不是按照JMS规范实现的。kafka集群由多个broke（Kafka实例称之为broke）组成，在集群里，kafka通过消息订阅和发布将消息以topic的形式发布出来，同时，消息也是存储在topic中的，消息的发送者成为producer，消息接受者成为Consummer。同时，topic 是根据分区partitions，和副本replications来实现的数据的分布式存储，和加强数据的可靠性。何为topic？一个topic可以认为是一类消息，每个topic将被分成多个partitions，每个partition在存储append log的形式存在文件里的。任何发布到partition的消息都会直接被追加到log文件的末尾，每条消息在文件中的位置称之为offset偏移量，offset为一个long型数字，它唯一标识一条消息，kafka并没有提供其他索引来存储offset，因此kafka不支持消息的随机读写。kafka和JMS（Java Message Service）实现(activeMQ)不同的是:即使消息被消费,消息仍然不会被立即删除.日志文件将会根据broker中的配置要求,保留一定的时间之后(默认是7天)删除;比如log文件保留2天,那么两天后,文件会被清除,无论其中的消息是否被消费.kafka通过这种简单的手段,来释放磁盘空间,以及减少消息消费之后对文件内容改动的磁盘IO开支.kafka消息如何消费的？对于consumer而言,它需要保存消费消息的offset,对于offset的保存和使用,有consumer来控制;当consumer正常消费消息时,offset将会”线性”的向前驱动,即消息将依次顺序被消费.事实上consumer可以使用任意顺序消费消息,它只需要将offset重置为任意值..(kafka 老版本中offset将会保存在zookeeper中,1.x之后也会存储在broke集群里,参见下文)kafka 集群里consumer和producer的状态信息是如何保存的？kafka集群几乎不需要维护任何consumer和producer状态信息,这些信息由zookeeper保存;因此producer和consumer的客户端实现非常轻量级,它们可以随意离开,而不会对集群造成额外的影响.kafka为何要引入分区的概念，有何好处？partitions的设计目的有多个.最根本原因是kafka基于文件存储.通过分区,可以将日志内容分散到多个kafka实例上,来避免文件尺寸达到单机磁盘的上限,每个partiton都会被当前server(kafka实例)保存;可以将一个topic切分多任意多个partitions,来消息保存/消费的效率.此外越多的partitions意味着可以容纳更多的consumer,有效提升并发消费的能力.有负载均衡的功效(具体原理参见下文).kakfa数据是如何写入到磁盘的？一个Topic的多个partitions,被分布在kafka集群中的多个server上;每个server(kafka实例)负责partitions中消息的读写操作;此外kafka还可以配置partitions需要备份的个数(replicas),每个partition将会被备份到多台机器上,以提高可用性.基于replicated方案,那么就意味着需要对多个备份进行调度;每个partition都有一个server为”leader”;leader负责所有的读写操作,如果leader失效,那么将会有其他follower来接管(成为新的leader);follower只是单调的和leader跟进,同步消息即可..由此可见作为leader的server承载了全部的请求压力,因此从集群的整体考虑,有多少个partitions就意味着有多少个”leader”,kafka会将”leader”均衡的分散在每个实例上,来确保整体的性能稳定.这和zookeeper的follower是有区别的：zookeeper的follower是可以读到数据的，而kafka的follower是读不到数据的。kafka使用文件存储消息,这就直接决定kafka在性能上严重依赖文件系统的本身特性.且无论任何OS下,对文件系统本身的优化几乎没有可能.文件缓存/直接内存映射等是常用的手段.因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的;同时为了减少磁盘写入的次数,broker会将消息暂时buffer起来,当消息的个数(或尺寸)达到一定阀值时,再flush到磁盘,这样减少了磁盘IO调用的次数.kafka中消费者组如何理解？Producer将消息发布到指定的Topic中,同时Producer也能决定将此消息归属于哪个partition;比如基于”round-robin”方式或者通过其他的一些算法等.本质上kafka只支持Topic.每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费.如果所有的consumer都具有相同的group,这种情况和queue模式很像;消息将会在consumers之间负载均衡.如果所有的consumer都具有不同的group,那这就是”发布-订阅”;消息将会广播给所有的消费者.在kafka中,一个partition中的消息只会被group中的一个consumer消费;每个group中consumer消息消费互相独立;我们可以认为一个group是一个”订阅”者,一个Topic中的每个partions,只会被一个”订阅者”中的一个consumer消费,不过一个consumer可以消费多个partitions中的消息.kafka只能保证一个partition中的消息被某个consumer消费时,消息是顺序的.事实上,从Topic角度来说,消息仍不是有序的. 因为消费者消费消息的时候是按照分区依次读取的，所以无法保证消息的全局顺序性，只能保证在同一个分区内的消息是顺序的。如果想要所有的消息都是顺序的，可以把分区数设置为1.kafka中如何保证数据一段时间内不丢失？kafka 的producer有ACK机制。可以由用户自行设定是否开启确认机制，如果开启确认机制，kafka会等发送消息到kafka集群时，当leader服务器，会返回元数据给producer客户端，ACK机制也在元数据里，这里的ACK有两种，一种就是leader只要接收成功，就返回确认，另外一种就是：要等所有follower都收到了之后才返回确认。producer在接收到确认之后，才会发下一条消息。而所有的消息最终都是存储在磁盘一段时间的，所以一段时间内消息是不会丢失的。kafka 的应用场景主要有哪些？官方介绍是讲可以用作message queue，数据采集，简单流式计算等。用作消息队列message queue有哪些优缺点？对于一些常规的消息系统,kafka是个不错的选择;partitons/replication和容错,可以使kafka具有良好的扩展性和性能优势.不过到目前为止,我们应该很清楚认识到,kafka并没有提供JMS中的”事务性””消息传输担保(消息确认机制)””消息分组”等企业级特性;kafka只能使用作为”常规”的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等)kafka是如何保持高性能的？需要考虑的影响性能点很多,除磁盘IO之外,我们还需要考虑网络IO,这直接关系到kafka的吞吐量问题.kafka并没有提供太多高超的技巧;对于producer端,可以将消息buffer起来,当消息的条数达到一定阀值时,批量发送给broker;对于consumer端也是一样,批量fetch多条消息.不过消息量的大小可以通过配置文件来指定.对于kafka broker端,似乎有个sendfile系统调用可以潜在的提升网络IO的性能:将文件的数据映射到系统内存中,socket直接读取相应的内存区域即可,而无需进程再次copy和交换. 其实对于producer/consumer/broker三者而言,CPU的开支应该都不大,因此启用消息压缩机制是一个良好的策略;压缩需要消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑.可以将任何在网络上传输的消息都经过压缩.kafka支持gzip/snappy等多种压缩方式.kafka在消费者端有哪些异常处理策略？对于JMS实现,消息传输担保非常直接:有且只有一次(exactly once).在kafka中稍有不同:1) at most once: 最多一次,这个和JMS中”非持久化”消息类似.发送一次,无论成败,将不会重发.2) at least once: 消息至少发送一次,如果消息未能接受成功,可能会重发,直到接收成功.3) exactly once: 消息只会发送一次.at most once: 消费者fetch消息,然后保存offset,然后处理消息;当client保存offset之后,但是在消息处理过程中出现了异常,导致部分消息未能继续处理.那么此后”未处理”的消息将不能被fetch到,这就是”at most once”.at least once: 消费者fetch消息,然后处理消息,然后保存offset.如果消息处理成功之后,但是在保存offset阶段zookeeper异常导致保存操作未能执行成功,这就导致接下来再次fetch时可能获得上次已经处理过的消息,这就是”at least once”，原因offset没有及时的提交给zookeeper，zookeeper恢复正常还是之前offset状态.exactly once: kafka中并没有严格的去实现基于2阶段提交,事务),我们认为这种策略在kafka中是没有必要的.通常情况下”at-least-once”是我们搜选.(相比at most once而言,重复接收数据总比丢失数据要好).kafka 工作流程是怎样的？主要结构图：大体可以从三个方面分析：生产者产生消息、消费者消费消息、Broker cluster保存消息。生产者产生消息过程分析写入方式：producer 采用push的方式将消息发送到broker cluster，每条消息都被追加到分区中，属于顺序写磁盘（顺序写磁盘效率比随机写内存效率要高，能提高Kafka吞吐率）而且broker集群并不是每一条消息都及时写磁盘，而是先写buffer，达到一定大小或者每隔一段时间再flush到磁盘上。多个producer可以给同一个topic 发布消息，而且可以指定分区发布。分区Partition每个Topic可以有多个分区，而消息最终是存储在磁盘的文件里的，Partition在磁盘上是文件夹的形式存在的。如12345678cd /var/applog/kafka/ ## 赚到kafka数据目录 即log.dir=配置的目录lscleaner-offset-checkpoint __consumer_offsets-22 __consumer_offsets-4 log-start-offset-checkpoint recovery-point-offset-checkpoint__consumer_offsets-1 __consumer_offsets-25 __consumer_offsets-40 meta.properties replication-offset-checkpoint__consumer_offsets-10 __consumer_offsets-28 __consumer_offsets-43 mytest-0 test-0__consumer_offsets-13 __consumer_offsets-31 __consumer_offsets-46 mytest-1__consumer_offsets-16 __consumer_offsets-34 __consumer_offsets-49 mytest-2__consumer_offsets-19 __consumer_offsets-37 __consumer_offsets-7 mytest-3其中mytest-0 mytest-1 mytest-2 mytest-3 即为分区Partition，里面的文件就是分区里面存放的数据。broker cluster 保存消息broker 收到消息后，首先会去找topic对应分区的leader，找到leader后，先将数据写入buffer，再flush到磁盘。然后zookeeper会协调follower自动同步leader分区的数据，以达到replication备份的目的，同时leader会按照备份完成的先后顺序给follower作一次排序，作为leader发生意外时选举时选举为leader的顺序。消费者消费消息消费者消费消息，同一个分区里的数据不能够被一个消费组里面的多个消费者同时消费，同一个消费组里的消费者只能消费不同分区的数据。不同消费者组可以消费同一个分区里的数据。消费者消费数据时是按照分区的一个一个分区数据进行消费的。zookeeper在kafka中的具体作用是什么？kafka是依赖于zookeeper注册中心的，主要来协调各个broker的分区备份，broker的选举，以及消费者相关状信息的存储。kafka使用zookeeper来存储一些meta信息,并使用了zookeeper watch机制来发现meta信息的变更并作出相应的动作(比如consumer失效,触发负载均衡等)1) Broker node registry: 当一个kafkabroker启动后,首先会向zookeeper注册自己的节点信息(临时znode),同时当broker和zookeeper断开连接时,此znode也会被删除.格式: /broker/ids/[0…N] –&gt;host:port;其中[0..N]表示broker id,每个broker的配置文件中都需要指定一个数字类型的id(全局不可重复),znode的值为此broker的host:port信息.123456789101112131415161718$ zkCli -server k8s-n1:2181$ ls /brokers[ids, topics, seqid]$ ls /brokers/ids[0, 1, 2]$ get /brokers/ids/0&#123;&quot;listener_security_protocol_map&quot;:&#123;&quot;PLAINTEXT&quot;:&quot;PLAINTEXT&quot;&#125;,&quot;endpoints&quot;:[&quot;PLAINTEXT://k8s-n1:9092&quot;],&quot;jmx_port&quot;:-1,&quot;host&quot;:&quot;k8s-n1&quot;,&quot;timestamp&quot;:&quot;1556568752340&quot;,&quot;port&quot;:9092,&quot;version&quot;:4&#125;cZxid = 0xd0000003cctime = Wed Apr 24 16:10:19 CST 2019mZxid = 0xd0000003cmtime = Wed Apr 24 16:10:19 CST 2019pZxid = 0xd0000003ccversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x26a4e173fc40002dataLength = 182numChildren = 02) Broker Topic Registry: 当一个broker启动时,会向zookeeper注册自己持有的topic和partitions信息,仍然是一个临时znode.格式: /broker/topics/[topic]/[0…N] 其中[0..N]表示partition索引号.12$ ls /brokers/topics[test, __consumer_offsets]__consumer_offsets 是消费端的offset12345678910111213141516171819$ ls /brokers/topics/test[partitions] ##test的分区信息$ ls /brokers/topics/test/partitions[0]$ ls /brokers/topics/test/partitions/0[state]$ get /brokers/topics/test/partitions/0/state &#123;&quot;controller_epoch&quot;:19,&quot;leader&quot;:0,&quot;version&quot;:1,&quot;leader_epoch&quot;:3,&quot;isr&quot;:[0]&#125;cZxid = 0x2000000b6ctime = Wed Apr 24 07:53:42 CST 2019mZxid = 0xd00000044mtime = Wed Apr 24 16:10:19 CST 2019pZxid = 0x2000000b6cversion = 0dataVersion = 3aclVersion = 0ephemeralOwner = 0x0dataLength = 73numChildren = 03) Consumer and Consumer group: 每个consumer客户端被创建时,会向zookeeper注册自己的信息;此作用主要是为了”负载均衡”.一个group中的多个consumer可以交错的消费一个topic的所有partitions;简而言之,保证此topic的所有partitions都能被此group所消费,且消费时为了性能考虑,让partition相对均衡的分散到每个consumer上.4) Consumer id Registry: 每个consumer都有一个唯一的ID(host:uuid,可以通过配置文件指定,也可以由系统生成),此id用来标记消费者信息.格式:/consumers/[group_id]/ids/[consumer_id]仍然是一个临时的znode,此节点的值为{“topic_name”:#streams…},即表示此consumer目前所消费的topic + partitions列表.启动消费者：1$ kafka-console-consumer.sh --bootstrap-server k8s-n2:9092 --topic test启动生成者：1kafka-console-producer.sh --broker-list k8s-n1:9092 --topic test查看zookeeper信息：1234$ ls /[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_notification, consumers, log_dir_event_notification, latest_producer_id_block, config]$ ls /consumers[]发现consummer下啥也没有？这是因为新版本的kafka，consumer中offset不是放在这个位置的，而是放在__consumer_offset 这个topic下的。那么该如何验证呢？启动消费者：1$ kafka-console-consumer.sh --bootstrap-server k8s-n2:9092 --topic test启动生成者：1kafka-console-producer.sh --broker-list k8s-n1:9092 --topic test验证消息生产成功12345kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list k8s-n1:9092 --topic mytest --time -1mytest:0:15mytest:1:16mytest:2:16mytest:3:15mytest topic 上 0号分区有15条消息。很好理解。再创建一个消费者组1kafka-console-consumer.sh --bootstrap-server k8s-n1:9092 --topic mytest --from-beginning查询一下消费者组信息123kafka-consumer-groups.sh --bootstrap-server k8s-n1:9092 --listconsole-consumer-24766console-consumer-52794查询一下topic里的内容：1kafka-console-consumer.sh --topic __consumer_offsets --bootstrap-server k8s-n1:9092 --formatter &quot;kafka.coordinator.group.GroupMetadataManager\\$OffsetsMessageFormatter&quot; --consumer.config config/consumer.properties --from-beginning结果：1234567891011 [console-consumer-52794,__consumer_offsets,12]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,45]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,1]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,5]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,26]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,29]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,34]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,10]::OffsetAndMetadata(offset=0, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,32]::OffsetAndMetadata(offset=5, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)[console-consumer-52794,__consumer_offsets,40]::OffsetAndMetadata(offset=3, leaderEpoch=Optional.empty, metadata=, commitTimestamp=1556122524504, expireTimestamp=None)^CProcessed a total of 1674 messages参考了 http://www.cnblogs.com/huxi2b/p/6061110.html这篇blog的作法，但是我的版本是kafka_2.2.0里面并没有找offset的命令。5) Consumer offset Tracking: 用来跟踪每个consumer目前所消费的partition中最大的offset.格式:/consumers/[group_id]/offsets/[topic]/[broker_id-partition_id]–&gt;offset_value此znode为持久节点,可以看出offset跟group_id有关,以表明当group中一个消费者失效,其他consumer可以继续消费.6) Partition Owner registry: 用来标记partition被哪个consumer消费.临时znode格式:/consumers/[group_id]/owners/[topic]/[broker_id-partition_id]–&gt;consumer_node_id当consumer启动时,所触发的操作:A) 首先进行”Consumer id Registry”;B) 然后在”Consumer id Registry”节点下注册一个watch用来监听当前group中其他consumer的”leave”和”join”;只要此znode path下节点列表变更,都会触发此group下consumer的负载均衡.(比如一个consumer失效,那么其他consumer接管partitions).C) 在”Broker id registry”节点下,注册一个watch用来监听broker的存活情况;如果broker列表变更,将会触发所有的groups下的consumer重新balance.","categories":[{"name":"消息队列","slug":"消息队列","permalink":"http://www.liuyong520.cn/categories/消息队列/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://www.liuyong520.cn/tags/kafka/"},{"name":"linux","slug":"linux","permalink":"http://www.liuyong520.cn/tags/linux/"}]},{"title":"hexo博客主题优化","slug":"hexo-promise","date":"2017-08-29T02:56:51.000Z","updated":"2019-04-28T08:58:06.799Z","comments":true,"path":"2017/08/29/hexo-promise/","link":"","permalink":"http://www.liuyong520.cn/2017/08/29/hexo-promise/","excerpt":"","text":"在介绍博客主题优化这个话题之前，我想先介绍hexo主题的大体结构，便于后面将主题优化方面的东西。hexo主题结构我这里选用pure主题为例进行讲解。进入themes/pure文件夹下执行如下命令123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158$ tree.├── LICENSE├── README.cn.md├── README.md├── _config.yml #主题主配置文件├── _config.yml.example #主题配置文件例子├── _source #博客页面例子文件夹│ ├── 404 #博客404页面只要拷贝到站点soure就行│ │ └── index.md│ ├── _data #博客友情链接页面│ │ ├── gallery.yml│ │ └── links.yml│ ├── about #博客关于页面│ │ └── index.md│ ├── books #博客书单页面│ │ └── index.md│ ├── categories #博客分类页面│ │ └── index.md│ ├── links #博客友情链接│ │ └── index.md│ ├── repository #博客仓库模版页面│ │ └── index.md│ └── tags #博客标签页面│ └── index.md├── languages #博客语言切换配置文件夹│ ├── default.yml│ ├── en.yml│ ├── zh-CN.yml│ └── zh-TW.yml├── layout #博客布局文件夹 这里就是生成页面的精华部分了│ ├── _common│ │ ├── footer.ejs│ │ ├── head.ejs│ │ ├── header.ejs│ │ ├── script.ejs│ │ └── social.ejs│ ├── _partial│ │ ├── archive-book.ejs│ │ ├── archive-category.ejs│ │ ├── archive-link.ejs│ │ ├── archive-list.ejs│ │ ├── archive-post.ejs│ │ ├── archive-repository.ejs│ │ ├── archive-tag.ejs│ │ ├── archive.ejs│ │ ├── article-about.ejs│ │ ├── article.ejs│ │ ├── item-post.ejs│ │ ├── pagination.ejs│ │ ├── post│ │ │ ├── category.ejs│ │ │ ├── comment.ejs│ │ │ ├── copyright.ejs│ │ │ ├── date.ejs│ │ │ ├── donate.ejs│ │ │ ├── gallery.ejs│ │ │ ├── nav.ejs│ │ │ ├── pv.ejs│ │ │ ├── tag.ejs│ │ │ ├── thumbnail.ejs│ │ │ ├── title.ejs│ │ │ └── wordcount.ejs│ │ ├── sidebar-about.ejs│ │ ├── sidebar-toc.ejs│ │ └── sidebar.ejs│ ├── _script│ │ ├── _analytics│ │ │ ├── baidu-analytics.ejs│ │ │ ├── google-analytics.ejs│ │ │ └── tencent-analytics.ejs│ │ ├── _comment│ │ │ ├── disqus.ejs│ │ │ ├── gitalk.ejs│ │ │ ├── gitment.ejs│ │ │ ├── livere.ejs│ │ │ ├── valine.ejs│ │ │ └── youyan.ejs│ │ ├── _search│ │ │ ├── baidu.ejs│ │ │ └── insight.ejs│ │ ├── analytics.ejs│ │ ├── comment.ejs│ │ ├── douban.ejs│ │ ├── fancybox.ejs│ │ ├── mathjax.ejs│ │ ├── pv.ejs│ │ ├── repository.ejs│ │ └── search.ejs│ ├── _search│ │ ├── baidu.ejs│ │ ├── index-mobile.ejs│ │ ├── index.ejs│ │ ├── insight.ejs│ │ └── swiftype.ejs│ ├── _widget│ │ ├── archive.ejs│ │ ├── board.ejs│ │ ├── category.ejs│ │ ├── recent_posts.ejs│ │ ├── tag.ejs│ │ └── tagcloud.ejs│ ├── about.ejs│ ├── archive.ejs│ ├── books.ejs│ ├── categories.ejs│ ├── category.ejs│ ├── index.ejs│ ├── layout.ejs│ ├── links.ejs│ ├── page.ejs│ ├── post.ejs│ ├── repository.ejs│ ├── tag.ejs│ └── tags.ejs├── package.json├── screenshot #主题颜色切换背景│ ├── pure-theme-black.png│ ├── pure-theme-blue.png│ ├── pure-theme-green.png│ ├── pure-theme-purple.png│ ├── pure.png│ └── pure.psd├── scripts│ └── thumbnail.js└── source #主题静态资源文件目录 ├── css │ ├── style.css │ └── style.min.css ├── favicon.png ├── fonts │ ├── README.md │ ├── iconfont.eot │ ├── iconfont.svg │ ├── iconfont.ttf │ └── iconfont.woff ├── images │ ├── avatar.jpg │ ├── avatar.jpg1 │ ├── donate │ │ ├── alipayimg.png │ │ └── wechatpayimg.png │ ├── favatar │ │ ├── SzsFox-logo.png │ │ ├── chuangzaoshi-logo.png │ │ └── idesign-logo.png │ ├── thumb-default.png │ └── xingqiu-qrcode.jpg └── js ├── application.js ├── application.min.js ├── insight.js ├── jquery.min.js ├── plugin.js ├── plugin.js.map └── plugin.min.js29 directories, 125 fileslayout里面的文件使用ejs （js模版语言）ejs官网实现的，里面把整个页面通过js抽取各个小的模块模版文件，同时数据和标签页面是分离的，所以在页面里面可以加载config.yml 里面的配置。整个页面入口文件就是layout.js12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html&lt;%= config.language ? &quot; lang=&quot; + config.language.substring(0, 2) : &quot;&quot;%&gt;&gt;&lt;%- partial(&apos;_common/head&apos;, &#123;post: page&#125;) %&gt;##这里会判断是否启用layout配置&lt;% var bodyClass = &apos;main-center&apos;; if (theme.config.layout) &#123; bodyClass = theme.config.layout; &#125; if (theme.config.skin) &#123; bodyClass += &apos; &apos; + theme.config.skin; &#125; bodyClass = page.sidebar === &apos;none&apos; ? (bodyClass + &apos; no-sidebar&apos;) : bodyClass;%&gt;&lt;body class=&quot;&lt;%= bodyClass %&gt;&quot; itemscope itemtype=&quot;http://schema.org/WebPage&quot;&gt; &lt;%- partial(&apos;_common/header&apos;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;% if (theme.sidebar &amp;&amp; (page.sidebar!=&apos;none&apos; || page.sidebar!=&apos;custom&apos;))&#123; %&gt; &lt;% if (theme.config.toc &amp;&amp; page.toc)&#123; %&gt; &lt;%- partial(&apos;_partial/sidebar-toc&apos;, &#123;post: page&#125;) %&gt; &lt;% &#125;else&#123; %&gt; &lt;%- partial(&apos;_partial/sidebar&apos;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;%- body %&gt; &lt;%- partial(&apos;_common/footer&apos;, null, &#123;cache: !config.relative_link&#125;) %&gt; &lt;%- partial(&apos;_common/script&apos;, &#123;post: page&#125;) %&gt;&lt;/body&gt;&lt;/html&gt;其中&lt;%- partial(‘_common/footer’, null, {cache: !config.relative_link}) %&gt; 表示引入子模块_common/footer.ejs文件，{cache: !config.relative_link}表示参数我们的创建的博客文章都会加载这个布局文件。我们新创建的博客文章有如下的配置：123456789title: 文章标题categories: - 文章分类tags: - 文章标签toc: true # 是否启用内容索引comment:true #是否启用评论layout:模版文件，如果没有默认不加载任何模版sidebar: none # 是否启用sidebar侧边栏，none：不启用，不配置默认启动以上配置属于page 域的配置文件属于单个页面的，而config.language 这种是全局配置文件（也就是站点配置文件config.yml），每个页面都能使用。theme.config 加载的就是主题的配置文件config.yml 文件。主题配置文件config.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236 # menumenu: Home: . Archives: archives # 归档 Categories: categories # 分类 Tags: tags # 标签 Repository: repository # github repositories Books: books # 豆瓣书单 Links: links # 友链 About: about # 关于# Enable/Disable menu iconsmenu_icons: enable: true # 是否启用导航菜单图标 home: icon-home-fill archives: icon-archives-fill categories: icon-folder tags: icon-tags repository: icon-project books: icon-book-fill links: icon-friendship about: icon-cup-fill# rssrss: /atom.xml# Sitesite: logo: enabled: true width: 40 height: 40 url: ../images/logo.png title: Hexo # 页面title favicon: /favicon.png board: &lt;p&gt;欢迎交流与分享经验!&lt;/p&gt; # 站点公告 copyright: false # 底部版权信息# configconfig: skin: theme-black # 主题颜色 theme-black theme-blue theme-green theme-purple layout: main-center # 布局方式 main-left main-center main-right toc: true # 是否开启文章章节目录导航 menu_highlight: false # 是否开启当前菜单高亮显示 thumbnail: false # enable posts thumbnail, options: true, false excerpt_link: Read More# Pagination 分页pagination: number: false #是否开启数字 prev: alwayShow: true next: alwayShow: true# Sidebarsidebar: rightwidgets: - board - category - tag - tagcloud - archive - recent_posts# display widgets at the bottom of index pages (pagination == 2)index_widgets:# - category# - tagcloud# - archive # widget behaviorarchive_type: &apos;monthly&apos;show_count: true# Fancyboxfancybox: false# Searchsearch: insight: true # you need to install `hexo-generator-json-content` before using Insight Search baidu: false # you need to disable other search engines to use Baidu search, options: true, false# Donatedonate: enable: true # 微信打赏 wechatpay: qrcode: images/donate/wechatpayimg.png title: 微信支付 # 支付宝打赏 alipay: qrcode: images/donate/alipayimg.png title: 支付宝# Share# weibo,qq,qzone,wechat,tencent,douban,diandian,facebook,twitter,google,linkedinshare: enable: true # 是否启用分享 sites: weibo,qq,wechat,facebook,twitter # PC端显示的分享图标 mobile_sites: weibo,qq,qzone # 移动端显示的分享图标# Githubgithub: username: ***# Comment# Gitment# Introduction: https://imsun.net/posts/gitment-introduction/comment: type: youyan disqus: # enter disqus shortname here youyan: uid: 1783844 # enter youyan uid livere: uid: # enter youyan uid gitment: githubID: repo: ClientID: ClientSecret: lazy: false gitalk: # gitalk. https://gitalk.github.io/ owner: #必须. GitHub repository 所有者，可以是个人或者组织。 admin: #必须. GitHub repository 的所有者和合作者 (对这个 repository 有写权限的用户)。 repo: #必须. GitHub repository. ClientID: #必须. GitHub Application Client ID. ClientSecret: #必须. GitHub Application Client Secret. valine: # Valine. https://valine.js.org appid: # your leancloud application appid appkey: # your leancloud application appkey notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: Just go go # comment box placeholder avatar: mm # gravatar style meta: nick,mail,link # custom comment header pageSize: 10 # pagination size visitor: false # Article reading statistic https://valine.js.org/visitor.html# douban 豆瓣书单# Api： # https://developers.douban.com/wiki/?title=book_v2 图书 # https://developers.douban.com/wiki/?title=movie_v2 电影# books： # https://api.douban.com/v2/book/user/:name/collections?start=0&amp;count=100 个人书单列表# movies: # https://api.douban.com/v2/movie/in_theaters 正在上映的电影 # https://api.douban.com/v2/movie/coming_soon 即将上映的电影 # https://api.douban.com/v2/movie/subject/:id 单个电影信息 # https://api.douban.com/v2/movie/search?q=&#123;text&#125; 电影搜索douban: user: # 豆瓣用户名 start: 0 # 从哪一条记录开始 count: 100 # 获取豆瓣书单数据条数 # PVpv: busuanzi: enable: false # 不蒜子统计 leancloud: enable: false # leancloud统计 app_id: # leancloud &lt;AppID&gt; app_key: # leancloud &lt;AppKey&gt; # wordcountpostCount: enable: false wordcount: true # 文章字数统计 min2read: true # 阅读时长预计 # Pluginsplugins: google_analytics: # enter the tracking ID for your Google Analytics google_site_verification: # enter Google site verification code baidu_analytics: # enter Baidu Analytics hash key tencent_analytics: # Miscellaneoustwitter:google_plus:fb_admins:fb_app_id: # profileprofile: enabled: true # Whether to show profile bar avatar: images/avatar.jpg gravatar: # Gravatar email address, if you enable Gravatar, your avatar config will be overriden author: 昵称 author_title: Web Developer &amp; Designer author_description: 个人简介。 location: Shenzhen, China follow: https://github.com/cofess # Social Links social: links: github: https://github.com/cofess weibo: http://weibo.com/cofess twitter: https://twitter.com/iwebued # facebook: / # dribbble: / behance: https://www.behance.net/cofess rss: atom.xml link_tooltip: true # enable the social link tooltip, options: true, false # My Skills skills: Git: ★★★☆☆ Gulp: ★★★☆☆ Javascript: ★★★☆☆ HTML+CSS: ★★★☆☆ Bootstrap: ★★★☆☆ ThinkPHP: ★★★☆☆ 平面设计: ★★★☆☆ # My Personal Links links: Github: https://github.com/cofess Blog: http://blog.cofess.com 微博: http://weibo.com/cofess 花瓣: http://huaban.com/cofess Behance: https://www.behance.net/cofess # My Personal Labels labels: - 前端 - 前端开发 - 前端重构 - Web前端 - 网页重构 # My Personal Works works: name: link: http://www.example.com date: 2016 # My Personal Projects projects: cofess/gulp-startpro: https://github.com/cofess/gulp-startpro cofess/hexo-theme-pure: https://github.com/cofess/hexo-theme-pure基本上每个配置做什么用的，配置文件里面基本写了注解。也很容易理解。如果还不是很能理解配置项。可以查看https://github.com/cofess/hexo-theme-pure/blob/master/README.cn.md 文件。至此，hexo模版的大体结构已经清楚了。主题优化修改主题在config.yml 文件中修改1234 # Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: pure修改语言在config.yml 文件中修改12# Sitelanguage: zh-CN #修改成中文添加Rss订阅安装feed插件1npm install hexo-generator-feed --save在config.yml添加12345 # Extensions## Plugins: https://hexo.io/plugins/#RSS订阅plugin:- hexo-generator-feed设置feed插件参数12345 #Feed Atomfeed: type: atom path: atom.xml limit: 20生成预览12hexo ghexo d预览下就是如下添加站点地图站点地图是一种文件，您可以通过该文件列出您网站上的网页，从而将您网站内容的组织架构告知Google和其他搜索引擎。Googlebot等搜索引擎网页抓取工具会读取此文件，以便更加智能地抓取您的网站分别安装百度和google插件12npm install hexo-generator-sitemap --savenpm install hexo-generator-baidu-sitemap --save在博客目录的_config.yml中添加如下代码12345# 自动生成sitemapsitemap:path: sitemap.xmlbaidusitemap:path: baidusitemap.xml编译你的博客12hexo ghexo s如果你在你的博客根目录的public下面发现生成了sitemap.xml以及baidusitemap.xml就表示成功了,在本地访问 http://127.0.0.4000/sitemap.xml 和 http://127.0.0.4000/baidusitemap.xml 就能正确的展示出两个sitemap 文件了。注册百度站长平台4.1 访问：https://ziyuan.baidu.com/linksubmit/index4.2 提交链接提交链接方式有主动推送、自动推送、sitemap、手动上传等。4.3主动推送安装对应提交插件1npm install hexo-baidu-url-submit --save修改配置：123456789101112131415##配置插件plugin:- hexo-generator-baidu-sitemap- hexo-generator-sitemap- hexo-baidu-url-submitbaidu_url_submit: ## 比如3，代表提交最新的三个链接 count: 3 # 在百度站长平台中注册的域名 host: www.liuyong520.cn ## 请注意这是您的秘钥， 请不要发布在公众仓库里! token: upR0BjzCYxTC2CPq ## 文本文档的地址， 新链接会保存在此文本文档里 path: baidu_urls.txt编译博客12hexo ghexo d如果出现下图即表示成功了4.4 自动推送将如下代码添加到head.ejs中即可生效1234567891011121314&lt;script&gt; (function()&#123; var bp = document.createElement(&apos;script&apos;); var curProtocol = window.location.protocol.split(&apos;:&apos;)[0]; if (curProtocol === &apos;https&apos;) &#123; bp.src = &apos;https://zz.bdstatic.com/linksubmit/push.js&apos;; &#125; else &#123; bp.src = &apos;http://push.zhanzhang.baidu.com/push.js&apos;; &#125; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(bp, s); &#125;)(); &lt;/script&gt;4.5 sitemap 提交方式打开百度站长平台，点击sitemap，填入我们的sitemap文件路径：&lt;域名&gt;/&lt;sitemap名字&gt;如下提交即可.但是此时你的域名其实并没有被百度站长所收录：百度依然检索不到你的网站，需要10多个工作日之后才能审核通过。绑定站点到熊掌ID，这样熊掌ID站点管理里面就能看到相关站点数据了登录站长平台，注册熊掌ID，提交审核过后点击站点收录：静态资源压缩hexo 的文章是通过md格式的文件经过swig转换成的html，生成的html会有很多空格，而且自己写的js以及css中会有很多的空格和注释。js和java不一样，注释也会影响一部分的性能，空格同样是的。静态资源压缩也有多种手段：有gulp插件和hexo自带的neat插件。1.hexo-neat 插件：安装hexo-neat插件1npm install hexo-neat --save修改站点配置文件_config.yml：12345678910111213141516171819202122 # hexo-neat# 博文压缩neat_enable: true# 压缩htmlneat_html: enable: true exclude:# 压缩css neat_css: enable: true exclude: - &apos;**/*.min.css&apos;# 压缩jsneat_js: enable: true mangle: true output: compress: exclude: - &apos;**/*.min.js&apos; - &apos;**/jquery.fancybox.pack.js&apos; - &apos;**/index.js&apos;编译博客12hexo g hexo dgulp插件方式安装gulp及相关插件123456npm install gulp -gnpm install gulp-minify-css --savenpm install gulp-uglify --savenpm install gulp-htmlmin --savenpm install gulp-htmlclean --savenpm install gulp-imagemin --save在 Hexo 站点下新建 gulpfile.js文件，文件内容如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445var gulp = require(&apos;gulp&apos;);var minifycss = require(&apos;gulp-minify-css&apos;);var uglify = require(&apos;gulp-uglify&apos;);var htmlmin = require(&apos;gulp-htmlmin&apos;);var htmlclean = require(&apos;gulp-htmlclean&apos;);var imagemin = require(&apos;gulp-imagemin&apos;);// 压缩css文件gulp.task(&apos;minify-css&apos;, function() &#123; return gulp.src(&apos;./public/**/*.css&apos;) .pipe(minifycss()) .pipe(gulp.dest(&apos;./public&apos;));&#125;);// 压缩html文件gulp.task(&apos;minify-html&apos;, function() &#123; return gulp.src(&apos;./public/**/*.html&apos;) .pipe(htmlclean()) .pipe(htmlmin(&#123; removeComments: true, minifyJS: true, minifyCSS: true, minifyURLs: true, &#125;)) .pipe(gulp.dest(&apos;./public&apos;))&#125;);// 压缩js文件gulp.task(&apos;minify-js&apos;, function() &#123; return gulp.src([&apos;./public/**/.js&apos;,&apos;!./public/js/**/*min.js&apos;]) .pipe(uglify()) .pipe(gulp.dest(&apos;./public&apos;));&#125;);// 压缩 public/demo 目录内图片gulp.task(&apos;minify-images&apos;, function() &#123; gulp.src(&apos;./public/demo/**/*.*&apos;) .pipe(imagemin(&#123; optimizationLevel: 5, //类型：Number 默认：3 取值范围：0-7（优化等级） progressive: true, //类型：Boolean 默认：false 无损压缩jpg图片 interlaced: false, //类型：Boolean 默认：false 隔行扫描gif进行渲染 multipass: false, //类型：Boolean 默认：false 多次优化svg直到完全优化 &#125;)) .pipe(gulp.dest(&apos;./public/uploads&apos;));&#125;);// 默认任务gulp.task(&apos;default&apos;, [ &apos;minify-html&apos;,&apos;minify-css&apos;,&apos;minify-js&apos;,&apos;minify-images&apos;]);只需要每次在执行 generate 命令后执行 gulp 就可以实现对静态资源的压缩，压缩完成后执行 deploy 命令同步到服务器：123hexo ggulphexo d修改访问URL路径默认情况下访问URL路径为：domain/2018/10/18/关于本站,修改为 domain/About/关于本站。 编辑 Hexo 站点下的 _config.yml 文件，修改其中的 permalink字段：1permalink: :category/:title/博文置顶安装插件12npm uninstall hexo-generator-index --savenpm install hexo-generator-index-pin-top --save然后在需要置顶的文章的Front-matter中加上top即可：12345--title: 2018date: 2018-10-25 16:10:03top: 10---设置置顶标志打开：/themes/*/layout/_macro/post.swig，定位到12345&#123;% if post.top %&#125; &lt;i class=&quot;fa fa-thumb-tack&quot;&gt;&lt;/i&gt; &lt;font color=7D26CD&gt;置顶&lt;/font&gt; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% endif %&#125;","categories":[{"name":"hexo","slug":"hexo","permalink":"http://www.liuyong520.cn/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.liuyong520.cn/tags/hexo/"}]},{"title":"Hexo之环境搭建","slug":"hexo-install","date":"2017-08-27T02:56:51.000Z","updated":"2019-04-27T12:11:10.273Z","comments":true,"path":"2017/08/27/hexo-install/","link":"","permalink":"http://www.liuyong520.cn/2017/08/27/hexo-install/","excerpt":"","text":"如果你和我一样是小白，那么恭喜你！看完这篇文章，你也可以拥有一个这样的博客啦！前言在以前我们要维护一个专属于自己的blog，是比较麻烦的，要购买服务器，部署博客程序到服务器，还要维护相关数据和网络。这一类blog最为典型的例子就是WordPress。而今天我们要介绍的是如何基于Hexo博客快速的搭建我们自己服务器系列。hexo介绍Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。hexo安装hexo 是基于node.js环境的，所以安装前，您必须检查电脑中是否已安装下列应用程序：node.js如果您的电脑中已经安装上述必备程序，那么恭喜您！接下来只需要使用 npm 即可完成 Hexo 的安装。1$ npm install -g hexo-cli如果您的电脑中未安装Node，那么就需要安装Node.js详细安装步骤参考：http://www.liuyong520.cn/2017/08/26/nodejs-install/再安装Hexo，在命令行（即Git Bash）运行以下命令：1npm install -g hexo-cli至此Hexo的环境就搭建好了，下一步验证一下hexo123456789101112131415161718MacBook-Pro:_posts xxydliuyss$ hexo versionhexo: 3.8.0hexo-cli: 1.1.0os: Darwin 18.5.0 darwin x64http_parser: 2.8.0node: 10.15.3v8: 6.8.275.32-node.51uv: 1.23.2zlib: 1.2.11ares: 1.15.0modules: 64nghttp2: 1.34.0napi: 3openssl: 1.1.0jicu: 62.1unicode: 11.0cldr: 33.1tz: 2018e这样hexo就安装完成了hexo命令介绍官网已经介绍的比较详细了这里就不再赘述了详情请看官方命令地址：https://hexo.io/zh-cn/docs/commandshexo快速新建博客初始化Hexo，在命令行（即Git Bash）依次运行以下命令即可：以下，即存放Hexo初始化文件的路径， 即站点目录。123$ hexo init myproject$ cd myproject$ npm install新建完成后，在路径下，会产生这些文件和文件夹：123456789$ tree.├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes目录名或者文件名详情介绍_config.ymlhexo 全局配置文件package.jsonnodejs 包配置文件scaffoldshexo模版文件夹hexo new filename 会对应根据模版文件生成文件source项目源代码文件目录_drafts为草稿原文件目录_posts项目发布文件目录 项目最终会根据这个目录下的文件生成htmlthemes博客主题存放目录注：hexo相关命令均在站点目录下，用Git Bash运行。站点配置文件：站点目录下的_config.yml。​ 路径为_config.yml主题配置文件：站点目录下的themes文件夹下的，主题文件夹下的_config.yml。​ 路径为\\themes\\&lt;主题文件夹&gt;_config.yml启动服务器。在路径下，命令行（即Git Bash）输入以下命令，运行即可：1hexo server浏览器访问网址： http://localhost:4000/ 就可以预览博客了下一篇 我将介绍如何搭建自己的blog","categories":[{"name":"hexo","slug":"hexo","permalink":"http://www.liuyong520.cn/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.liuyong520.cn/tags/hexo/"}]},{"title":"利用hexo搭建博客","slug":"creatblog","date":"2017-08-27T02:56:51.000Z","updated":"2019-04-27T16:22:09.846Z","comments":true,"path":"2017/08/27/creatblog/","link":"","permalink":"http://www.liuyong520.cn/2017/08/27/creatblog/","excerpt":"","text":"如果你和我一样是小白，那么恭喜你！看完这篇文章，你也可以拥有一个这样的博客前面已经介绍过如何搭建hexo环境，现在我将介绍如何用hexo搭建自己的blog博客搭建实施方案方案一：GithubPages创建Github账号创建仓库 ，仓库名为：&lt;Github账号名称&gt;.github.io点击settings往下翻就能看到githubPages，我这里是已经配置过了的，没有配置可以是select themes ，点击能够选择SkyII主题。（SkyII主题也是和hexo类似的blog的框架，这里不与介绍）将本地Hexo博客推送到GithubPages3.1. 安装hexo-deployer-git插件。在命令行（即Git Bash）运行以下命令即可：1$ npm install hexo-deployer-git --save3.2. 添加SSH key。创建一个 SSH key 。在命令行（即Git Bash）输入以下命令， 回车三下即可：1$ ssh-keygen -t rsa -C &quot;邮箱地址&quot;添加到 github。 复制密钥文件内容（路径形如C:\\Users\\Administrator.ssh\\id_rsa.pub），粘贴到New SSH Key即可。测试是否添加成功。在命令行（即Git Bash）依次输入以下命令，返回“You’ve successfully authenticated”即成功：1ssh -T git@github.com3.3. 修改_config.yml（在站点目录下）。文件末尾修改为：123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:&lt;Github账号名称&gt;/&lt;Github账号名称&gt;.github.io.git branch: master注意：上面仓库地址写ssh地址，不写http地址。3.4. 推送到GithubPages。在命令行（即Git Bash）依次输入以下命令， 返回INFO Deploy done: git即成功推送：12$ hexo g$ hexo d等待1分钟左右，浏览器访问网址： https://&lt;Github账号名称&gt;.github.io至此，您的Hexo博客已经搭建在GithubPages, 域名为https://&lt;Github账号名称&gt;.github.io。方案二：GithubPages + 域名在方案一的基础上，添加自定义域名（您购买的域名）。我的是从阿里云购买的。域名解析类型选择为 CNAME；主机记录即域名前缀，填写为www；记录值填写为&lt;Github账号名称&gt;.github.io；解析线路，TTL 默认即可点击 liuyong520.cn仓库设置。2.1. 打开博客仓库设置：https://github.com/&lt;Github账号名称&gt;/&lt;Github账号名称&gt;.github.io/settings2.2. 在Custom domain下，填写自定义域名，点击save。2.3. 在站点目录的source文件夹下，创建并打开CNAME.txt，写入你的域名（如www.liuyong520.cn），保存，并重命名为CNAME。如图等待10分钟左右。浏览器访问自定义域名。http://www.liuyong520.cn至此，您的Hexo博客已经解析到自定义域名，https://&lt;Github账号名称&gt;.github.io依然可用。方案三：GithubPages + CodingPages + 域名GithubPages 在国内较慢，百度不收录，而CodingPages 在国外较快。所以在方案二的基础上，添加CodingPages 。创建Coding账号创建仓库， 仓库名为：&lt;Coding账号名称&gt;进入项目里『代码』页面，点击『一键开启静态 Pages』，稍等片刻CodingPages即可部署成功。将本地Hexo博客推送到CodingPages4.1. 鉴于创建GithubPages 时，已经生成过公钥。可直接复制密钥文件内容（路径形如C:\\Users\\Administrator.ssh\\id_rsa.pub）， 粘贴到新增公钥。4.2. 测试是否添加成功。在命令行（即Git Bash）依次输入以下命令，返回“You’ve successfully authenticated”即成功：12$ ssh -T git@git.coding.net$ yes4.3. 修改_config.yml（在存放Hexo初始化文件的路径下）。文件末尾修改为：123456789# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:- type: git repo: git@github.com:&lt;Github账号名称&gt;/&lt;Github账号名称&gt;.github.io.git branch: master- type: git repo: git@git.dev.tencent.com:&lt;Coding账号名称&gt;/&lt;Coding账号名称&gt;.git branch: master4.4. 推送到GithubPages。在命令行（即Git Bash）依次输入以下命令， 返回INFO Deploy done: git即成功推送：12$ hexo g$ hexo d域名解析添加 CNAME 记录指向 &lt;Coding账号名称&gt;.coding.me类型选择为 CNAME；主机记录即域名前缀，填写为www；记录值填写为&lt;Github账号名称&gt;.coding.me；解析线路，TTL 默认即可。添加 两条A 记录指向 192.30.252.153和192.30.252.154类型选择为 A；主机记录即域名前缀，填写为@；记录值填写为192.30.252.153和192.30.252.154；解析线路，境外或谷歌。在『Pages 服务』设置页（https://dev.tencent.com/u/&lt;Coding账号名称&gt;/p/&lt;Coding账号名称&gt;/git/pages/settings）中绑定自定义域名至此，您的Hexo博客已经解析到自定义域名，https://&lt;Github账号名称&gt;.github.io和https://&lt;Coding账号名称&gt;.coding.me依然可用。切换主题选择主题hexo主题是非常多的，默认的主题是landscape，您可以自主的在hexo官方网站上挑选自己喜欢的主题，网站：https://hexo.io/themes/推荐以下主题：snippetHieroJsimpleBlueLakePureNextHueman我这里选择的是Pure。1git clone https://github.com/cofess/hexo-theme-pure.git themes/pure此时会在themes 目录下生成 pure目录应用主题更改站点配置_config.yml 修改成1234# Extensions## Plugins: https://hexo.io/plugins/## Themes: https://hexo.io/themes/theme: &lt;主题文件夹的名称&gt;主题优化以上主题都有比较详细的说明文档，本节主要解决主题优化的常见问题。主题优化一般包括：设置「RSS」添加「标签」页面添加「分类」页面设置「字体」设置「代码高亮主题」侧边栏社交链接开启打赏功能设置友情链接腾讯公益404页面站点建立时间订阅微信公众号设置「动画效果」设置「背景动画」下一次我将针对Pure进行主题方面的相关配置，以及讲解一下hexo主题的的实现原理的。这样你们针对不同的主题也就都能配置了。","categories":[{"name":"hexo","slug":"hexo","permalink":"http://www.liuyong520.cn/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://www.liuyong520.cn/tags/hexo/"}]},{"title":"node.js环境搭建","slug":"nodejs-install","date":"2017-08-26T01:56:51.000Z","updated":"2019-04-27T09:42:47.606Z","comments":true,"path":"2017/08/26/nodejs-install/","link":"","permalink":"http://www.liuyong520.cn/2017/08/26/nodejs-install/","excerpt":"","text":"安装node.js登录官网下载对应的exe安装包。下载地址为：你可以根据不同平台系统选择你需要的Node.js安装包。Node.js 历史版本下载地址：https://nodejs.org/dist/注意：Linux上安装Node.js需要安装Python 2.6 或 2.7 ，不建议安装Python 3.0以上版本。windows 上安装 node.js你可以采用以下两种方式来安装。1、Windows 安装包(.msi)32 位安装包下载地址 : https://nodejs.org/dist/v4.4.3/node-v4.4.3-x86.msi64 位安装包下载地址 : https://nodejs.org/dist/v4.4.3/node-v4.4.3-x64.msi本文实例以 v0.10.26 版本为例，其他版本类似， 安装步骤：步骤 1 : 双击下载后的安装包 v0.10.26，如下所示：步骤 2: 点击以上的Run(运行)，将出现如下界面：步骤 3 : 勾选接受协议选项，点击 next（下一步） 按钮 :步骤 4 : Node.js默认安装目录为 “C:\\Program Files\\nodejs\\” , 你可以修改目录，并点击 next（下一步）：步骤 5 : 点击树形图标来选择你需要的安装模式 , 然后点击下一步 next（下一步）步骤 6 :点击 Install（安装） 开始安装Node.js。你也可以点击 Back（返回）来修改先前的配置。 然后并点击 next（下一步）：点击 Finish（完成）按钮退出安装向导。检测PATH环境变量是否配置了Node.js，点击开始=》运行=》输入”cmd” =&gt; 输入命令”path”，输出如下结果：12345PATH=C:\\oraclexe\\app\\oracle\\product\\10.2.0\\server\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;c:\\python32\\python;C:\\MinGW\\bin;C:\\Program Files\\GTK2-Runtime\\lib;C:\\Program Files\\MySQL\\MySQL Server 5.5\\bin;C:\\Program Files\\nodejs\\;C:\\Users\\rg\\AppData\\Roaming\\npm我们可以看到环境变量中已经包含了C:\\Program Files\\nodejs\\检查Node.js版本12E:\\&gt; node --versionv0.10.262、Windows 二进制文件 (.exe)安装32 位安装包下载地址 : http://nodejs.org/dist/v0.10.26/node.exe64 位安装包下载地址 : http://nodejs.org/dist/v0.10.26/x64/node.exe安装步骤步骤 1 : 双击下载的安装包 Node.exe ，将出现如下界面 :点击 Run（运行）按钮将出现命令行窗口：版本测试进入 node.exe 所在的目录，如下所示如果你获得以上输出结果，说明你已经成功安装了Node.js。linux安装node.js直接使用已编译好的包Node 官网已经把 linux 下载版本更改为已编译好的版本了，我们可以直接下载解压后使用：12345# wget https://nodejs.org/dist/v10.9.0/node-v10.9.0-linux-x64.tar.xz // 下载# tar xf node-v10.9.0-linux-x64.tar.xz // 解压# cd node-v10.9.0-linux-x64/ // 进入解压目录# ./bin/node -v // 执行node命令 查看版本v10.9.0解压文件的 bin 目录底下包含了 node、npm 等命令，我们可以使用 ln 命令来设置软连接12ln -s /usr/software/nodejs/bin/npm /usr/local/bin/ ln -s /usr/software/nodejs/bin/node /usr/local/bin/Ubuntu 源码安装 Node.js以下部分我们将介绍在 Ubuntu Linux 下使用源码安装 Node.js 。 其他的 Linux 系统，如 Centos 等类似如下安装步骤。在 Github 上获取 Node.js 源码：12$ sudo git clone https://github.com/nodejs/node.gitCloning into &apos;node&apos;...修改目录权限：1$ sudo chmod -R 755 node使用 ./configure 创建编译文件，并按照：1234$ cd node$ sudo ./configure$ sudo make$ sudo make install查看 node 版本：12$ node --versionv0.10.25Ubuntu apt-get命令安装命令格式如下：12sudo apt-get install nodejssudo apt-get install npmCentOS 下源码安装 Node.js1、下载源码，你需要在https://nodejs.org/en/download/ 下载最新的Nodejs版本，本文以v0.10.24为例:12cd /usr/local/src/wget http://nodejs.org/dist/v0.10.24/node-v0.10.24.tar.gz2、解压源码1tar zxvf node-v0.10.24.tar.gz3、 编译安装1234cd node-v0.10.24./configure --prefix=/usr/local/node/0.10.24makemake install4、 配置NODE_HOME，进入profile编辑环境变量1vim /etc/profile设置nodejs环境变量，在 export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL 一行的上面添加如下内容:123#set for nodejsexport NODE_HOME=/usr/local/node/0.10.24export PATH=$NODE_HOME/bin:$PATH:wq保存并退出，编译/etc/profile 使配置生效1source /etc/profile验证是否安装配置成功1node -v输出 v0.10.24 表示配置成功npm模块安装路径:1/usr/local/node/0.10.24/lib/node_modules/注：Nodejs 官网提供了编译好的Linux二进制包，你也可以下载下来直接应用。Mac OS 上安装你可以通过以下两种方式在 Mac OS 上来安装 node：1、在官方下载网站下载 pkg 安装包，直接点击安装即可。2、使用 brew 命令来安装：1brew install node","categories":[{"name":"node","slug":"node","permalink":"http://www.liuyong520.cn/categories/node/"}],"tags":[{"name":"node","slug":"node","permalink":"http://www.liuyong520.cn/tags/node/"}]},{"title":"xsync 同步命令脚本和xcall远程执行命令脚本","slug":"xsync","date":"2017-03-28T16:18:32.000Z","updated":"2019-04-28T16:40:15.580Z","comments":true,"path":"2017/03/29/xsync/","link":"","permalink":"http://www.liuyong520.cn/2017/03/29/xsync/","excerpt":"","text":"缘由在linux服务器集群上，有时我们需要将数据从主服务器同步到所有的从服务器上，或者在集群里需要执行一条或者多条命令，如果们一次次的拷贝，或者每个服务器一条条的执行，会造成重复的工作。所以就写两个脚本解决这方面的问题。xsync命令的编写安装 sync命令1yum install -y sync编写脚本 environment.sh12345#! /usr/bin/bash# 集群 IP 数组export NODE_IPS=(172.16.18.198 172.16.18.199 172.16.18.200)# 集群各 IP 对应的 主机名数组export NODE_NAMES=(k8s-n1 k8s-n2 k8s-n3)编写xsyncj考本1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/bin/bash# 获取输出参数，如果没有参数则直接返回pcount=$#if [ $pcount -eq 0 ]then echo &quot;no parameter find !&quot;; exit;fi# 获取传输文件名p1=$1filename=`basename $p1`echo &quot;load file $p1 success !&quot;# 获取文件的绝对路径pdir=`cd -P $(dirname $p1); pwd`echo &quot;file path is $pdir&quot;# 获取当前用户（如果想使用root用户权限拷贝文件，在命令后加入-root参数即可）user=$2case &quot;$user&quot; in&quot;-root&quot;) user=&quot;root&quot;;;&quot;&quot;) user=`whoami`;;*) echo &quot;illegal parameter $user&quot; esacecho $user# 拷贝文件到从机(这里注意主机的host需要根据你的实际情况配置，要与你具体的主机名对应)source /opt/user/environment.shindex=0for node_ip in $&#123;NODE_IPS[@]&#125;do echo &quot;================current host is $&#123;NODE_NAMES[$index]&#125; ip is $&#123;node_ip&#125;=================&quot; rsync -rvl $pdir/$filename $user@$&#123;node_ip&#125;:$pdir index=`expr $index + 1`doneecho &quot;complete !&quot;xcall脚本的编写利用ssh命令远程执行脚本命令。脚本如下：12345678910111213141516171819202122232425#!/bin/bash# 获取控制台指令cmd=$*# 判断指令是否为空if (( #$cmd -eq # ))then echo &quot;command can not be null !&quot; exitfi# 获取当前登录用户user=`whoami`source /opt/user/environment.sh# 在从机执行指令,这里需要根据你具体的集群情况配置，host与具体主机名一致for node_ip in $&#123;NODE_IPS[@]&#125;do echo &quot;================current host is $&#123;node_ip&#125;=================&quot; echo &quot;--&gt; excute command \\&quot;$cmd\\&quot;&quot; ssh $user@$&#123;node_ip&#125; $cmddoneecho &quot;excute successfully !&quot;这两个脚本仅仅只是一个简单的脚本，欢迎大家修改和使用。","categories":[{"name":"linux shell","slug":"linux-shell","permalink":"http://www.liuyong520.cn/categories/linux-shell/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://www.liuyong520.cn/tags/linux/"},{"name":"shell","slug":"shell","permalink":"http://www.liuyong520.cn/tags/shell/"}]}]}